{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/agent/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "from dotenv import load_dotenv\n",
    "from langchain_community.graphs import Neo4jGraph\n",
    "from langchain.chains import GraphCypherQAChain\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_community.llms import HuggingFaceHub\n",
    "from langchain.chains import GraphCypherQAChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "load_dotenv(dotenv_path=\".env\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract the year and clean the title\n",
    "def separate_title_and_year(title):\n",
    "    # Use regex to find the year in parentheses\n",
    "    year_match = re.search(r'\\((\\d{4})\\)$', title)\n",
    "    \n",
    "    # If a match is found, extract the year and clean the title\n",
    "    if year_match:\n",
    "        year = year_match.group(1)\n",
    "        # Remove the year from the title\n",
    "        cleaned_title = re.sub(r'\\(\\d{4}\\)$', '', title).strip()\n",
    "    else:\n",
    "        year = None\n",
    "        cleaned_title = title\n",
    "    \n",
    "    return cleaned_title, year\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Sense and Sensibility</td>\n",
       "      <td>Drama|Romance</td>\n",
       "      <td>1995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Leaving Las Vegas</td>\n",
       "      <td>Drama|Romance</td>\n",
       "      <td>1995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "      <td>2.0</td>\n",
       "      <td>City of Lost Children, The (Cité des enfants p...</td>\n",
       "      <td>Adventure|Drama|Fantasy|Mystery|Sci-Fi</td>\n",
       "      <td>1995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Shanghai Triad (Yao a yao yao dao waipo qiao)</td>\n",
       "      <td>Crime|Drama</td>\n",
       "      <td>1995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Twelve Monkeys (a.k.a. 12 Monkeys)</td>\n",
       "      <td>Mystery|Sci-Fi|Thriller</td>\n",
       "      <td>1995</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  movieId  rating                                              title  \\\n",
       "0       1       17     4.0                              Sense and Sensibility   \n",
       "1       1       25     1.0                                  Leaving Las Vegas   \n",
       "2       1       29     2.0  City of Lost Children, The (Cité des enfants p...   \n",
       "3       1       30     5.0      Shanghai Triad (Yao a yao yao dao waipo qiao)   \n",
       "4       1       32     5.0                 Twelve Monkeys (a.k.a. 12 Monkeys)   \n",
       "\n",
       "                                   genres  year  \n",
       "0                           Drama|Romance  1995  \n",
       "1                           Drama|Romance  1995  \n",
       "2  Adventure|Drama|Fantasy|Mystery|Sci-Fi  1995  \n",
       "3                             Crime|Drama  1995  \n",
       "4                 Mystery|Sci-Fi|Thriller  1995  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the first 500 rows of each dataset\n",
    "ratings = pd.read_csv('../ml-32m/ratings.csv', usecols=['userId', 'movieId', 'rating'], nrows=500)\n",
    "movies = pd.read_csv('../ml-32m/movies.csv', nrows=500)\n",
    "tags = pd.read_csv('../ml-32m/tags.csv', usecols=['userId', 'movieId', 'tag'], nrows=500)  # Optional\n",
    "\n",
    "movies['title'], movies['year'] = zip(*movies['title'].apply(separate_title_and_year))\n",
    "\n",
    "# Merge ratings with movies based on 'movieId'\n",
    "df = pd.merge(ratings, movies, on='movieId', how='inner')\n",
    "\n",
    "# Optional: Merge tags if needed (without timestamps)\n",
    "# df = pd.merge(merged_data, tags, on=['userId', 'movieId'], how='left')\n",
    "\n",
    "# Now you have the merged dataset for recommendation (limited to 500 rows)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['genres_list'] = df['genres'].str.split('|')\n",
    "\n",
    "# Step 2: Explode the list into multiple rows (one genre per row per movie)\n",
    "movies_exploded = df.explode('genres_list').reset_index(drop=True)\n",
    "movies_exploded[\"genres\"] = movies_exploded[\"genres_list\"]\n",
    "movies_exploded.drop([\"genres_list\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Sense and Sensibility</td>\n",
       "      <td>Drama</td>\n",
       "      <td>1995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Sense and Sensibility</td>\n",
       "      <td>Romance</td>\n",
       "      <td>1995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Leaving Las Vegas</td>\n",
       "      <td>Drama</td>\n",
       "      <td>1995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Leaving Las Vegas</td>\n",
       "      <td>Romance</td>\n",
       "      <td>1995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "      <td>2.0</td>\n",
       "      <td>City of Lost Children, The (Cité des enfants p...</td>\n",
       "      <td>Adventure</td>\n",
       "      <td>1995</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  movieId  rating                                              title  \\\n",
       "0       1       17     4.0                              Sense and Sensibility   \n",
       "1       1       17     4.0                              Sense and Sensibility   \n",
       "2       1       25     1.0                                  Leaving Las Vegas   \n",
       "3       1       25     1.0                                  Leaving Las Vegas   \n",
       "4       1       29     2.0  City of Lost Children, The (Cité des enfants p...   \n",
       "\n",
       "      genres  year  \n",
       "0      Drama  1995  \n",
       "1    Romance  1995  \n",
       "2      Drama  1995  \n",
       "3    Romance  1995  \n",
       "4  Adventure  1995  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies_exploded.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "gemini_api = os.getenv(\"GOOGLE_API_KEY\")\n",
    "neo4j_url = os.getenv(\"NEO4J_CONNECTION_URL\")\n",
    "neo4j_user = os.getenv(\"NEO4J_USER\")\n",
    "neo4j_password = os.getenv(\"NEO4J_PASSWORD\")\n",
    "neo4j_db = os.getenv(\"NEO4J_MOVIE\")\n",
    "\n",
    "graph = Neo4jGraph(neo4j_url,neo4j_user,neo4j_password)\n",
    "graph = Neo4jGraph(neo4j_url, neo4j_user, neo4j_password, database=neo4j_db)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Create Movie Nodes\n",
    "for index, row in movies_exploded.iterrows():\n",
    "    query = \"\"\"\n",
    "    MERGE (m:Movie {movieId: $movieId, title: $title, year: $year})\n",
    "    \"\"\"\n",
    "    parameters = {\n",
    "        'movieId': int(row['movieId']),\n",
    "        'title': row['title'],\n",
    "        'year': int(row['year'])\n",
    "    }\n",
    "    # run_query(query, parameters)\n",
    "    graph.query(query, parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Create Genre Nodes and HAS_GENRE Relationships\n",
    "for index, row in movies_exploded.iterrows():\n",
    "    genre = row['genres']\n",
    "    # Create Genre node\n",
    "    query = \"\"\"\n",
    "    MERGE (g:Genre {name: $genre})\n",
    "    \"\"\"\n",
    "    # run_query(query, {'genre': genre})\n",
    "    parameters = {\n",
    "        'genre': genre\n",
    "    }\n",
    "    graph.query(query, parameters)\n",
    "\n",
    "    # Create HAS_GENRE relationship\n",
    "    query = \"\"\"\n",
    "    MATCH (m:Movie {movieId: $movieId})\n",
    "    MATCH (g:Genre {name: $genre})\n",
    "    MERGE (m)-[:HAS_GENRE]->(g)\n",
    "    \"\"\"\n",
    "    parameters = {\n",
    "        'movieId': int(row['movieId']),\n",
    "        'genre': genre\n",
    "    }\n",
    "    # run_query(query, parameters)\n",
    "    graph.query(query, parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Create User Nodes and RATED Relationships\n",
    "for index, row in movies_exploded.iterrows():\n",
    "    # Create User node\n",
    "    query = \"\"\"\n",
    "    MERGE (u:User {userId: $userId})\n",
    "    \"\"\"\n",
    "    # run_query(query, {'userId': int(row['userId'])})\n",
    "    parameters = {\n",
    "        'userId': int(row['userId'])\n",
    "    }\n",
    "    graph.query(query, parameters)\n",
    "\n",
    "    # Create RATED relationship\n",
    "    query = \"\"\"\n",
    "    MATCH (u:User {userId: $userId})\n",
    "    MATCH (m:Movie {movieId: $movieId})\n",
    "    MERGE (u)-[:RATED {rating: $rating}]->(m)\n",
    "    \"\"\"\n",
    "    parameters = {\n",
    "        'userId': int(row['userId']),\n",
    "        'movieId': int(row['movieId']),\n",
    "        'rating': float(row['rating'])\n",
    "    }\n",
    "    # run_query(query, parameters)\n",
    "    graph.query(query, parameters)\n",
    "\n",
    "# Close the Neo4j driver\n",
    "# driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node properties:\n",
      "Movie {movieId: INTEGER, title: STRING, year: INTEGER}\n",
      "Genre {name: STRING}\n",
      "User {userId: INTEGER}\n",
      "Relationship properties:\n",
      "RATED {rating: FLOAT}\n",
      "The relationships:\n",
      "(:Movie)-[:HAS_GENRE]->(:Genre)\n",
      "(:User)-[:RATED]->(:Movie)\n"
     ]
    }
   ],
   "source": [
    "graph.refresh_schema()\n",
    "print(graph.schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "example = [\n",
    "    {\n",
    "        \"question\": \"Give me 10 movies similar to 'Forrest Gump' released in 1990 or later.\",\n",
    "        \"query\": \"MATCH (m:Movie {title: 'Forrest Gump'})-[:HAS_GENRE]->(g:Genre)<-[:HAS_GENRE] -(similar:Movie) WHERE m <> similar AND similar.year >= 1990 RETURN similar.title AS SimilarMovies, COUNT(g) AS SharedGenres ORDER BY SharedGenres DESC LIMIT 10\",\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"What are the ratings for 'Forrest Gump'?\",\n",
    "        \"query\": \"MATCH (m:Movie {title: 'Forrest Gump'})<-[r:RATED]-(u:User) RETURN u.userId AS UserId, r.rating AS Rating\",\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"What is the average rating for 'Forrest Gump'?\",\n",
    "        \"query\": \"MATCH (m:Movie {title: 'Forrest Gump'})<-[r:RATED]-(u:User) RETURN AVG(r.rating) AS AverageRating\",\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"Find all movies released in 1995.\",\n",
    "        \"query\": \"MATCH (m:Movie) WHERE m.year = 1995RETURN m.title AS MoviesReleasedIn1995\",\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"What are the genres of 'Pocahontas'?\",\n",
    "        \"query\": \"MATCH (m:Movie {title: 'Pocahontas'})-[:HAS_GENRE]->(g:Genre) RETURN g.name AS Genres\",\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"How many movies are in the 'Comedy' genre?\",\n",
    "        \"query\": \"MATCH (m:Movie)-[:HAS_GENRE]->(g:Genre {name: 'Comedy'}) RETURN COUNT(m) AS ComedyMovieCount\",\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"List all users who rated movies in the 'Drama' genre.\",\n",
    "        \"query\": \"MATCH (m:Movie)-[:HAS_GENRE]->(g:Genre {name: 'Drama'})<-[:RATED]-(u:User)RETURN DISTINCT u.userId AS UsersWhoRatedDrama\",\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"Find all movies rated above 4.0.\",\n",
    "        \"query\": \"MATCH (m:Movie)<-[r:RATED]-(u:User) WHERE r.rating > 4.0 RETURN m.title AS HighRatedMovies, AVG(r.rating) AS AverageRating\",\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"Find movies with 'City' in the title.\",\n",
    "        \"query\": \" MATCH (m:Movie) WHERE m.title CONTAINS 'City' RETURN m.title AS MoviesWithCityInTitle\",\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"What companies do workers named John work in?\",\n",
    "        \"query\": \"MATCH (p:Person {name: 'John'})-[:WORKS_IN]->(c:Company) RETURN c.name\",\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"What are the ratings for 'Eat Drink Man Woman (Yin shi nan nu)'?\",\n",
    "        \"query\": \"MATCH (m:Movie {title: 'Eat Drink Man Woman (Yin shi nan nu)'})<-[r:RATED]-(u:User) RETURN u.userId AS UserId, r.rating AS Rating\",\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"Which movies have the most shared genres with 'While You Were Sleeping'?\",\n",
    "        \"query\": \"MATCH (m:Movie {title: 'While You Were Sleeping'})-[:HAS_GENRE]->(g:Genre)<-[:HAS_GENRE]-(similar:Movie) WHERE m <> similar RETURN similar.title AS SimilarMovies, COUNT(g) AS SharedGenres ORDER BY SharedGenres DESC LIMIT 10\",\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"What is the highest rated movie?\",\n",
    "        \"query\": \"MATCH (m:Movie)<-[r:RATED]-(u:User) RETURN m.title AS HighestRatedMovie, AVG(r.rating) AS AverageRating ORDER BY AverageRating DESC LIMIT 1\",\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"Find all movies that are both 'Comedy' and 'Romance'.\",\n",
    "        \"query\": \"MATCH (m:Movie)-[:HAS_GENRE]->(g:Genre) WHERE g.name IN ['Comedy', 'Romance'] RETURN m.title AS MoviesThatAreComedyAndRomance\",\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"How many users rated 'French Kiss'?\",\n",
    "        \"query\": \"MATCH (m:Movie {title: 'French Kiss'})<-[:RATED]-(u:User) RETURN COUNT(u) AS NumberOfUsersWhoRatedFrenchKiss\",\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"What movies did user 1 rate?\",\n",
    "        \"query\": \"MATCH (u:User {userId: 1})-[r:RATED]->(m:Movie) RETURN m.title AS MoviesRatedByUser1\",\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"Find all movies in the 'True Lies' genre.\",\n",
    "        \"query\": \"MATCH (m:Movie)-[:HAS_GENRE]->(g:Genre {name: 'True Lies'}) RETURN m.title AS MoviesInTrueLiesGenre\",\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"List users who rated movies released in 1995.\",\n",
    "        \"query\": \"MATCH (m:Movie)<-[r:RATED]-(u:User) WHERE m.year = 1995 RETURN DISTINCT u.userId AS UsersWhoRatedMoviesIn1995\",\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"How many movies has each user rated?\",\n",
    "        \"query\": \"MATCH (u:User)-[r:RATED]->(m:Movie) RETURN u.userId AS UserId, COUNT(r) AS RatedMoviesCount\",\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"What are the genres of 'Hot Shots! Part Deux'?\",\n",
    "        \"query\": \" MATCH (m:Movie {title: 'Hot Shots! Part Deux'})-[:HAS_GENRE]->(g:Genre) RETURN g.name AS Genres\",\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"I like the movie 'True Lies'. give me 5 movie similar to this one with their genres\",\n",
    "        \"query\": \"MATCH (m:Movie {title: 'True Lies'})-[:HAS_GENRE]->(g:Genre) WITH g MATCH (other:Movie)-[:HAS_GENRE]->(g) WHERE other.title <> 'True Lies' WITH other, collect(g.name) as genres, COUNT(g) as genreCount ORDER BY genreCount DESC RETURN other.title as Movie, genres as Genres LIMIT 5\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"I liked the movie 'Braveheart'. What are 5 similar movies I should watch?\",\n",
    "        \"query\": \"MATCH (m:Movie {title: 'Braveheart'})-[:HAS_GENRE]->(g:Genre) WITH g MATCH (other:Movie)-[:HAS_GENRE]->(g) WHERE other.title <> 'Braveheart' WITH other, COLLECT(g.name) as genres, COUNT(g) as genreCount ORDER BY genreCount DESC RETURN other.title as SimilarMovie, genres LIMIT 5\",\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"I like 'Drama' and 'Romance'. I have watched 'Sense and Sensibility' and 'Leaving Las Vegas'. What should I watch next?\",\n",
    "        \"query\": \"MATCH (x:Movie {title: 'Sense and Sensibility'})-[:HAS_GENRE]->(g1:Genre), (z:Movie {title: 'Leaving Las Vegas'})-[:HAS_GENRE]->(g2:Genre) WITH g1, g2 MATCH (other:Movie)-[:HAS_GENRE]->(g)  WHERE (g = g1 OR g = g2) AND other.title <> 'Sense and Sensibility' AND other.title <> 'Leaving Las Vegas' RETURN DISTINCT other.title AS RecommendedMovie LIMIT 5\",\n",
    "    }\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Cypher query prompt template\n",
    "cypher_generation_prompt = PromptTemplate(\n",
    "    template=\"\"\"Based on the schema, write a Cypher query to answer the question.\n",
    "    \n",
    "    The question may ask about:\n",
    "    - Similar movies based on genre\n",
    "    - Movies a user has rated\n",
    "    - Recommendations based on genres the user likes\n",
    "\n",
    "    Schema:\n",
    "    {schema}\n",
    "\n",
    "    Example questions and queries:\n",
    "    {example}\n",
    "\n",
    "    **Important**:\n",
    "    - Always identify movies based on their **titles**.\n",
    "    - Use the exact movie titles provided in the question for any matching logic.\n",
    "    - Do not reference `userId` or `movieId`; focus solely on the titles of movies and their genres.\n",
    "    - Assume that if a user has rated a movie, they have watched it.\n",
    "\n",
    "    Question: {question}\n",
    "    Query:\"\"\",\n",
    "    input_variables=[\"schema\", \"question\", \"example\"],\n",
    ")\n",
    "\n",
    "# Define the answer generation prompt template\n",
    "qa_prompt = PromptTemplate(\n",
    "    template=\"\"\"Based on the Cypher query results, answer the question.\n",
    "    Question: {question}\n",
    "    Results: {context}\n",
    "    Give a clear, direct but human-friendly answer using the data from the results. \n",
    "    If it's a list, combine all items.\n",
    "    Answer:\"\"\",\n",
    "    input_variables=[\"question\", \"context\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the LLM (Google Generative AI)\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-pro\", google_api_key=gemini_api, temperature=0)\n",
    "\n",
    "ALLOW_DANGEROUS_REQUEST = True\n",
    "\n",
    "# Define the chain\n",
    "chain = GraphCypherQAChain.from_llm(\n",
    "    llm=llm,\n",
    "    graph=graph,  # Your Neo4j graph object\n",
    "    verbose=True,\n",
    "    cypher_generation_prompt=cypher_generation_prompt,\n",
    "    qa_prompt=qa_prompt,\n",
    "    allow_dangerous_requests=ALLOW_DANGEROUS_REQUEST,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node properties:\n",
      "Movie {movieId: INTEGER, title: STRING, year: INTEGER}\n",
      "Genre {name: STRING}\n",
      "User {userId: INTEGER}\n",
      "Relationship properties:\n",
      "RATED {rating: FLOAT}\n",
      "The relationships:\n",
      "(:Movie)-[:HAS_GENRE]->(:Genre)\n",
      "(:User)-[:RATED]->(:Movie)\n"
     ]
    }
   ],
   "source": [
    "graph.refresh_schema()\n",
    "print(graph.schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Test query function\n",
    "# def test_query(question):\n",
    "#     try:\n",
    "#         # Explicitly generate the Cypher query first using the prompt\n",
    "#         generated_query = cypher_generation_prompt.format(\n",
    "#             schema=graph.schema,  # Ensure dynamic schema usage\n",
    "#             question=question,\n",
    "#             example=example\n",
    "#         )\n",
    "\n",
    "#         # Run the chain with the generated query\n",
    "#         result = chain.run(query=generated_query, question=question)\n",
    "        \n",
    "#         print(f\"Q: {question}\")\n",
    "#         print(f\"A: {result}\\n\")\n",
    "#     except Exception as e:\n",
    "#         print(f\"Error: {str(e)}\")\n",
    "#     return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import sys\n",
    "import re\n",
    "\n",
    "def clean_ansi(text):\n",
    "    # Remove ANSI escape codes\n",
    "    ansi_escape = re.compile(r'\\x1B(?:[@-Z\\\\-_]|\\[[0-?]*[ -/]*[@-~])')\n",
    "    return ansi_escape.sub('', text).strip()\n",
    "\n",
    "def test_query(question):\n",
    "    try:\n",
    "        # Create a string buffer to capture the output\n",
    "        output_buffer = io.StringIO()\n",
    "        original_stdout = sys.stdout\n",
    "        # sys.stdout = output_buffer\n",
    "\n",
    "        # Explicitly generate the Cypher query first using the prompt\n",
    "        generated_query = cypher_generation_prompt.format(\n",
    "            schema=graph.schema,  # Ensure dynamic schema usage\n",
    "            question=question,\n",
    "            example=example\n",
    "        )\n",
    "\n",
    "        # Run the chain with the generated query\n",
    "        result = chain.run(query=generated_query, question=question)\n",
    "        \n",
    "        # Restore original stdout and get the captured output\n",
    "        sys.stdout = original_stdout\n",
    "        output = output_buffer.getvalue()\n",
    "        \n",
    "        # Extract Cypher query and context from the captured output\n",
    "        cypher_query = None\n",
    "        full_context = None\n",
    "        \n",
    "        if 'Generated Cypher:' in output:\n",
    "            cypher_query = output.split('Generated Cypher:')[1].split('Full Context:')[0].strip()\n",
    "            cypher_query = clean_ansi(cypher_query)\n",
    "        \n",
    "        if 'Full Context:' in output:\n",
    "            full_context = output.split('Full Context:')[1].split('>')[0].strip()\n",
    "            full_context = clean_ansi(full_context)\n",
    "        \n",
    "        print(f\"Q: {question}\")\n",
    "        print(f\"A: {result}\\n\")\n",
    "        \n",
    "        return {\n",
    "            'result': result,\n",
    "            'cypher_query': cypher_query,\n",
    "            'full_context': full_context\n",
    "        }\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {str(e)}\")\n",
    "        return {\n",
    "            'result': None,\n",
    "            'cypher_query': None,\n",
    "            'full_context': None,\n",
    "            'error': str(e)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new GraphCypherQAChain chain...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/hc/dq1y9hzx51s30kq78z6v4jsm0000gp/T/ipykernel_9133/3942578154.py:25: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  result = chain.run(query=generated_query, question=question)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Cypher:\n",
      "\u001b[32;1m\u001b[1;3mMATCH (m:Movie {title: 'Jungle Book, The'})<-[r:RATED]-(:User)\n",
      "RETURN count(r)\n",
      "\u001b[0m\n",
      "Full Context:\n",
      "\u001b[32;1m\u001b[1;3m[{'count(r)': 24}]\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Q: How many users rated 'Jungle Book, The'?\n",
      "A: 24 users rated 'Jungle Book, The'.\n",
      "\n",
      "\n",
      "Cypher Query: None\n",
      "Full Context: None\n",
      "Result: 24 users rated 'Jungle Book, The'.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "response = test_query(\"How many users rated 'Jungle Book, The'?\")\n",
    "print(f\"Cypher Query: {response['cypher_query']}\")\n",
    "print(f\"Full Context: {response['full_context']}\")\n",
    "print(f\"Result: {response['result']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new GraphCypherQAChain chain...\u001b[0m\n",
      "Generated Cypher:\n",
      "\u001b[32;1m\u001b[1;3mMATCH (m:Movie {title: 'True Lies'})-[:HAS_GENRE]->(g:Genre) RETURN g.name\n",
      "\u001b[0m\n",
      "Full Context:\n",
      "\u001b[32;1m\u001b[1;3m[{'g.name': 'Romance'}, {'g.name': 'Adventure'}, {'g.name': 'Thriller'}, {'g.name': 'Action'}, {'g.name': 'Comedy'}]\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Q: What are the genres of 'True Lies'?\n",
      "A: The genres of 'True Lies' are Romance, Adventure, Thriller, Action, and Comedy.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new GraphCypherQAChain chain...\u001b[0m\n",
      "Generated Cypher:\n",
      "\u001b[32;1m\u001b[1;3mMATCH (m:Movie {title: 'Pocahontas'})<-[r:RATED]-(:User)\n",
      "RETURN count(r)\n",
      "\u001b[0m\n",
      "Full Context:\n",
      "\u001b[32;1m\u001b[1;3m[{'count(r)': 29}]\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Q: How many users rated 'Pocahontas'?\n",
      "A: 29 users rated 'Pocahontas'.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new GraphCypherQAChain chain...\u001b[0m\n",
      "Generated Cypher:\n",
      "\u001b[32;1m\u001b[1;3mMATCH (m:Movie {title: 'Dead Man Walking'})-[:HAS_GENRE]->(g:Genre)<-[:HAS_GENRE]-(similar:Movie)\n",
      "WHERE m <> similar\n",
      "WITH similar, COLLECT(g.name) AS genres\n",
      "RETURN similar.title, similar.year, genres\n",
      "LIMIT 5\n",
      "\u001b[0m\n",
      "Full Context:\n",
      "\u001b[32;1m\u001b[1;3m[{'similar.title': 'Sense and Sensibility', 'similar.year': 1995, 'genres': ['Drama']}, {'similar.title': 'Leaving Las Vegas', 'similar.year': 1995, 'genres': ['Drama']}, {'similar.title': 'City of Lost Children, The (Cité des enfants perdus, La)', 'similar.year': 1995, 'genres': ['Drama']}, {'similar.title': 'Shanghai Triad (Yao a yao yao dao waipo qiao)', 'similar.year': 1995, 'genres': ['Drama', 'Crime']}, {'similar.title': 'Babe', 'similar.year': 1995, 'genres': ['Drama']}]\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Q: I like the movie 'Dead Man Walking'. give me 5 movie similar to this one with their genres\n",
      "A: Here are five movies similar to \"Dead Man Walking\": \"Sense and Sensibility\" (Drama), \"Leaving Las Vegas\" (Drama), \"City of Lost Children, The (Cité des enfants perdus, La)\" (Drama), \"Shanghai Triad (Yao a yao yao dao waipo qiao)\" (Drama, Crime), and \"Babe\" (Drama).\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new GraphCypherQAChain chain...\u001b[0m\n",
      "Generated Cypher:\n",
      "\u001b[32;1m\u001b[1;3mMATCH (g:Genre)<-[:HAS_GENRE]-(m:Movie)\n",
      "WHERE g.name IN ['Drama', 'Romance']\n",
      "AND NOT m.title IN ['Babe', 'Dead Man Walking']\n",
      "RETURN m\n",
      "LIMIT 10\n",
      "\u001b[0m\n",
      "Full Context:\n",
      "\u001b[32;1m\u001b[1;3m[{'m': {'year': 1995, 'movieId': 17, 'title': 'Sense and Sensibility'}}, {'m': {'year': 1995, 'movieId': 25, 'title': 'Leaving Las Vegas'}}, {'m': {'year': 1995, 'movieId': 29, 'title': 'City of Lost Children, The (Cité des enfants perdus, La)'}}, {'m': {'year': 1995, 'movieId': 30, 'title': 'Shanghai Triad (Yao a yao yao dao waipo qiao)'}}, {'m': {'year': 1995, 'movieId': 80, 'title': 'White Balloon, The (Badkonake sefid)'}}, {'m': {'year': 1995, 'movieId': 110, 'title': 'Braveheart'}}, {'m': {'year': 1976, 'movieId': 111, 'title': 'Taxi Driver'}}, {'m': {'year': 1995, 'movieId': 161, 'title': 'Crimson Tide'}}, {'m': {'year': 1995, 'movieId': 166, 'title': 'Doom Generation, The'}}, {'m': {'year': 1994, 'movieId': 232, 'title': 'Eat Drink Man Woman (Yin shi nan nu)'}}]\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Q: I like 'Drama' and 'Romance'. I have watched 'Babe' and 'Dead Man Walking'. What should I watch next?\n",
      "A: Sense and Sensibility, Leaving Las Vegas, City of Lost Children, The (Cité des enfants perdus, La), Shanghai Triad (Yao a yao yao dao waipo qiao), White Balloon, The (Badkonake sefid), Braveheart, Taxi Driver, Crimson Tide, Doom Generation, The, and Eat Drink Man Woman (Yin shi nan nu)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'result': 'Sense and Sensibility, Leaving Las Vegas, City of Lost Children, The (Cité des enfants perdus, La), Shanghai Triad (Yao a yao yao dao waipo qiao), White Balloon, The (Badkonake sefid), Braveheart, Taxi Driver, Crimson Tide, Doom Generation, The, and Eat Drink Man Woman (Yin shi nan nu)\\n',\n",
       " 'cypher_query': None,\n",
       " 'full_context': None}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_query(\"What are the genres of 'True Lies'?\")\n",
    "test_query(\"How many users rated 'Pocahontas'?\")\n",
    "test_query(\"I like the movie 'Dead Man Walking'. give me 5 movie similar to this one with their genres\")\n",
    "test_query(\"I like 'Drama' and 'Romance'. I have watched 'Babe' and 'Dead Man Walking'. What should I watch next?\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Action', 'Adventure', 'Comedy', 'Romance', 'Thriller'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies_exploded[movies_exploded['title'] == 'True Lies'].genres.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_SET = [\n",
    "    {\n",
    "        \"question\": \"What are the genres of 'Star Wars: Episode IV - A New Hope'?\",\n",
    "        \"query\": \"MATCH (m:Movie {title: 'Star Wars: Episode IV - A New Hope'})-[:HAS_GENRE]->(g:Genre) RETURN g.name AS Genres\",\n",
    "        \"answer\": \"The genres of 'Star Wars: Episode IV - A New Hope' are 'Sci-Fi', 'Action', and 'Adventure'.\",\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"How many users rated 'Jungle Book, The'?\",\n",
    "        \"query\": \"MATCH (m:Movie {title: 'Jungle Book, The'})<-[:RATED]-(u:User) RETURN COUNT(u) AS NumberOfUsersWhoRatedJungleBook\",\n",
    "        \"answer\": \"2 users rated 'Jungle Book, The'.\",\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"I like the movie 'Dumb & Dumber (Dumb and Dumber)'. Give me 5 movies similar to this one with their genres.\",\n",
    "        \"query\": \"MATCH (m:Movie {title: 'Dumb & Dumber (Dumb and Dumber)'})-[:HAS_GENRE]->(g:Genre) WITH g MATCH (other:Movie)-[:HAS_GENRE]->(g) WHERE other.title <> 'InceptDumb & Dumber (Dumb and Dumber)ion' WITH other, COLLECT(g.name) AS genres, COUNT(g) AS genreCount ORDER BY genreCount DESC RETURN other.title AS Movie, genres AS Genres LIMIT 5\",\n",
    "        \"answer\": \"Based on your preference for 'Dumb & Dumber (Dumb and Dumber)', here are 5 similar movies you might enjoy: 'Batman Forever', 'True Lies', 'City Slickers II: The Legend of Curly's Gold', 'Coneheads', and 'Bullets Over Broadway'. These movies share the genres of Comedy and Adventure.\",\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"What are the ratings for 'Taxi Driver'?\",\n",
    "        \"query\": \"MATCH (m:Movie {title: 'Taxi Driver'})<-[r:RATED]-(u:User) RETURN  r.rating AS Rating\",\n",
    "        \"answer\": \"The ratings for 'Taxi Driver' are 5.0.\",\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"Find all movies released in 1993.\",\n",
    "        \"query\": \"MATCH (m:Movie) WHERE m.year = 1993 RETURN m.title AS MoviesReleasedIn1993\",\n",
    "        \"answer\": \"The movies released in 1993 are 'Three Colors: Blue (Trois couleurs: Bleu)', 'Firm, The', 'Fugitive, The', 'Hot Shots! Part Deux', 'Mrs. Doubtfire', 'Whats Eating Gilbert Grape', 'Cliffhanger', 'Demolition Man', 'Jurassic Park', 'Addams Family Values', 'Coneheads', and 'Dave'\",\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"What is the average rating for 'Pulp Fiction'?\",\n",
    "        \"query\": \"MATCH (m:Movie {title: 'Pulp Fiction'})<-[r:RATED]-(u:User) RETURN AVG(r.rating) AS AverageRating\",\n",
    "        \"answer\": \"The average rating for 'Pulp Fiction' is 2.875.\",\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"Find all movies that are both 'Action' and 'Thriller'.\",\n",
    "        \"query\": \"MATCH (m:Movie)-[:HAS_GENRE]->(g:Genre) WHERE g.name IN ['Action', 'Thriller'] WITH m, COLLECT(g.name) AS genres WHERE 'Action' IN genres AND 'Thriller' IN genres RETURN m.title AS MoviesThatAreActionAndThriller\",\n",
    "        \"answer\": \"The movies which are both Action and Thriller are 'Outbreak', 'Natural Born Killers', 'Die Hard: With a Vengeance', 'Jurassic Park', 'Cliffhanger', 'GoldenEye', 'True Lies', 'Speed', 'Clear and Present Danger'  and 'Net, The'.\",\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"List all users who rated movies in the 'Horror' genre.\",\n",
    "        \"query\": \"MATCH (m:Movie)-[:HAS_GENRE]->(g:Genre {name: 'Horror'}) OPTIONAL MATCH (u:User)-[:RATED]->(m) RETURN DISTINCT u.userId as users LIMIT 10\",\n",
    "        \"answer\": \"User 2 and 5 rated Horror movies.\",\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"What is the highest rated movie released before 2000?\",\n",
    "        \"query\": \"MATCH (m:Movie)<-[r:RATED]-(u:User) WHERE m.year < 2000 RETURN m.title AS HighestRatedMovie, AVG(r.rating) AS AverageRating ORDER BY AverageRating DESC LIMIT 1\",\n",
    "        \"answer\": \"Height rated movie resleased before 2000 is Shanghai Triad (Yao a yao yao dao waipo qiao).\",\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"Find movies with 'Love' in the title.\",\n",
    "        \"query\": \"MATCH (m:Movie) WHERE m.title CONTAINS 'Love' RETURN m.title AS MoviesWithLoveInTitle\",\n",
    "        \"answer\": \"The movie that have love in title is 'When a Man Loves a Woman'.\",\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"How many movies are in the 'Fantasy' genre?\",\n",
    "        \"query\": \"MATCH (m:Movie)-[:HAS_GENRE]->(g:Genre {name: 'Fantasy'}) RETURN COUNT(m) AS FantasyMovieCount\",\n",
    "        \"answer\": \"There are 5 movies in the 'Fantasy' genre.\",\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"What movies did user 2 rate?\",\n",
    "        \"query\": \"MATCH (u:User {userId: 2})-[r:RATED]->(m:Movie) RETURN m.title AS MoviesRatedByUser2\",\n",
    "        \"answer\": \"User 2 rated 'Mrs. Doubtfire','Hot Shots! Part Deux','Fugitive, The','Firm, The','When a Man Loves a Woman','True Lies','Speed','Lion King, The','Jungle Book, The','Four Weddings and a Funeral','Forrest Gump','Client, The','Clear and Present Danger','Ace Ventura: Pet Detective','While You Were Sleeping','Shawshank Redemption, The','Ready to Wear (Pret-A-Porter)','Pulp Fiction','Nell','Milk Money','Interview with the Vampire: The Vampire Chronicles','Forget Paris','French Kiss','Dumb & Dumber (Dumb and Dumber)','Disclosure','Circle of Friends','Boys on the Side','Billy Madison','Walk in the Clouds, A','Showgirls','Nine Months','Net, The','Batman Forever','Pocahontas','Clueless','Babe' and 'Dangerous Minds'.\",\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"List users who rated movies released in 1994.\",\n",
    "        \"query\": \"MATCH (m:Movie)<-[r:RATED]-(u:User) WHERE m.year = 1994 RETURN DISTINCT u.userId AS UsersWhoRatedMoviesIn1994\",\n",
    "        \"answer\": \"Users who rated movies released in 1994 include User 1, User 2, User 3, User 4, User 5, User 7 and User 8.\",\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"What are the genres of 'The Lion King'?\",\n",
    "        \"query\": \"MATCH (m:Movie {title: 'Lion King, The'})-[:HAS_GENRE]->(g:Genre) RETURN g.name AS Genres\",\n",
    "        \"answer\": \"'Lion King, The' is a movie in the 'Adventure', 'Animation', 'Children', 'Drama', 'Musical' and 'IMAX' genres.\",\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"I liked the movie 'French Kiss'. What are 5 similar movies I should watch?\",\n",
    "        \"query\": \"MATCH (m:Movie {title: 'French Kiss'})-[:HAS_GENRE]->(g:Genre) WITH g MATCH (other:Movie)-[:HAS_GENRE]->(g) WHERE other.title <> 'French Kiss' WITH other, collect(g.name) as genres, COUNT(g) as genreCount ORDER BY genreCount DESC RETURN other.title as Movie, genres as Genres LIMIT 5\",\n",
    "        \"answer\": \"Based on your preference for 'Dead Man Walking', here are 5 similar movies you might enjoy: 'True Lies','Englishman Who Went Up a Hill But Came Down a Mountain, The','First Knight','Rob Roy','Dave'.\",\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"What movies have the most shared genres with 'Milk Money'?\",\n",
    "        \"query\": \"MATCH (m:Movie {title: 'Milk Money'})-[:HAS_GENRE]->(g:Genre)<-[:HAS_GENRE]-(similar:Movie) WHERE m <> similar RETURN similar.title AS SimilarMovies, COUNT(g) AS SharedGenres ORDER BY SharedGenres DESC LIMIT 5\",\n",
    "        \"answer\": \"Five movies that have the same genres as 'Milk Money' are 'Englishman Who Went Up a Hill But Came Down a Mountain, The','Dave','Like Water for Chocolate (Como agua para chocolate)','First Knight', and 'Rob Roy'.\",\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"Find all movies rated above 4 and rated by atlead 2 user.\",\n",
    "        \"query\": \"MATCH (m:Movie)<-[r:RATED]-(u:User) WHERE r.rating = 4 WITH m, COUNT(r) AS ratingCount, AVG(r.rating) AS averageRating WHERE ratingCount > 2 RETURN m.title AS HighRatedMovies, averageRating\",\n",
    "        \"answer\": \"The movie that has rating above 4 and rated by at least 2 users are 'Firm, The', 'Four Weddings and a Funeral' and 'Clear and Present Danger'.\",\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"How many users rated 'Dangerous Minds'?\",\n",
    "        \"query\": \"MATCH (m:Movie {title: 'Dangerous Minds'})<-[:RATED]-(u:User) RETURN COUNT(u) AS NumberOfUsersWhoRatedDarkKnight\",\n",
    "        \"answer\": \"1 users rated 'Dangerous Minds'\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"I like 'Adventure' and 'Fantasy' genres. What movies should I watch next?\",\n",
    "        \"query\": \"MATCH (m:Movie)-[:HAS_GENRE]->(g:Genre) WHERE g.name IN ['Adventure', 'Fantasy'] RETURN DISTINCT m.title AS RecommendedMovies LIMIT 5\",\n",
    "        \"answer\": \"Based on your preferences for 'Adventure' and 'Fantasy', you might enjoy watching 'City Slickers II: The Legend of Curly's Gold', 'Jurassic Park', 'Demolition Man', 'Cliffhanger' and 'Star Trek: Generations'.\"\n",
    "    },\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(TEST_SET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for test_data in TEST_SET:\n",
    "    question = test_data[\"question\"]\n",
    "    query = test_data[\"query\"]\n",
    "    answer = test_data[\"answer\"]\n",
    "    test_query(question)\n",
    "    print(f\"Answer: {answer}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/agent/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/tmp/ipykernel_51457/1666884692.py:8: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embed_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n"
     ]
    }
   ],
   "source": [
    "import evaluate\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import pprint\n",
    "import json\n",
    "from langchain.embeddings.huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "\n",
    "embed_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "# Load evaluation metrics\n",
    "rouge = evaluate.load(\"rouge\")\n",
    "bleu = evaluate.load(\"bleu\")\n",
    "\n",
    "# Load the JSON file\n",
    "with open('Q_A_LLM_Gemini.json', 'r') as f:\n",
    "    evaluation_data = json.load(f)\n",
    "\n",
    "# Accumulate results\n",
    "rouge_scores = []\n",
    "bleu_scores = []\n",
    "cosine_similarities = []\n",
    "\n",
    "for data in evaluation_data:\n",
    "    question = data[\"question\"]\n",
    "    expected_answer = data[\"answer\"]\n",
    "    generated_answer = data[\"LLM\"]  # Use the generated answer from the JSON data\n",
    "    \n",
    "    # Compute evaluation metrics\n",
    "    rouge_result = rouge.compute(predictions=[generated_answer], references=[expected_answer])\n",
    "    bleu_result = bleu.compute(predictions=[generated_answer], references=[[expected_answer]])\n",
    "\n",
    "    # Compute cosine similarity between embeddings\n",
    "    reference_embedding = embed_model.embed_query(expected_answer)  # Replace with your embedding method\n",
    "    generated_embedding = embed_model.embed_query(generated_answer)  # Replace with your embedding method\n",
    "    cosine_sim = cosine_similarity([reference_embedding], [generated_embedding])[0][0]\n",
    "\n",
    "    # Store the results\n",
    "    rouge_scores.append(rouge_result)\n",
    "    bleu_scores.append(bleu_result)\n",
    "    cosine_similarities.append(cosine_sim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average ROUGE-1: 0.6469750661635828\n",
      "Average ROUGE-2: 0.5199681153084947\n",
      "Average ROUGE-L: 0.6259056789898153\n",
      "Average BLEU: 0.3437022313376515\n",
      "Average Cosine Similarity: 0.7482198944391015\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "# Compute the average ROUGE score\n",
    "avg_rouge1 = np.mean([score['rouge1'] for score in rouge_scores])\n",
    "avg_rouge2 = np.mean([score['rouge2'] for score in rouge_scores])\n",
    "avg_rougeL = np.mean([score['rougeL'] for score in rouge_scores])\n",
    "\n",
    "# Compute the average BLEU score\n",
    "avg_bleu = np.mean([score['bleu'] for score in bleu_scores])\n",
    "\n",
    "# Compute the average Cosine Similarity\n",
    "avg_cosine_similarity = np.mean(cosine_similarities)\n",
    "\n",
    "# Print the average scores\n",
    "print(f\"Average ROUGE-1: {avg_rouge1}\")\n",
    "print(f\"Average ROUGE-2: {avg_rouge2}\")\n",
    "print(f\"Average ROUGE-L: {avg_rougeL}\")\n",
    "print(f\"Average BLEU: {avg_bleu}\")\n",
    "print(f\"Average Cosine Similarity: {avg_cosine_similarity}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accumulate results\n",
    "results = []\n",
    "\n",
    "for data in evaluation_data:\n",
    "    question = data[\"question\"]\n",
    "    expected_answer = data[\"answer\"]\n",
    "\n",
    "    # Query the system\n",
    "    generated_answer = data[\"LLM\"]  # Using the LLM's response as generated answer\n",
    "    \n",
    "    # Check for specific phrases in the generated answer\n",
    "    if \"User Mistake.\" in generated_answer or \"ERROR: SAFETY Issue.\" in generated_answer:\n",
    "        # Skip score calculation for these responses\n",
    "        continue\n",
    "\n",
    "    # Compute evaluation metrics\n",
    "    rouge_result = rouge.compute(predictions=[generated_answer], references=[expected_answer])\n",
    "    bleu_result = bleu.compute(predictions=[generated_answer], references=[[expected_answer]])\n",
    "\n",
    "    # Compute cosine similarity between embeddings\n",
    "    reference_embedding = embed_model.embed_query(expected_answer)\n",
    "    generated_embedding = embed_model.embed_query(generated_answer)\n",
    "    cosine_sim = cosine_similarity([reference_embedding], [generated_embedding])[0][0]\n",
    "\n",
    "    # Append the result as a dictionary\n",
    "    results.append({\n",
    "        \"Question\": question,\n",
    "        \"Generated Answer\": generated_answer,\n",
    "        \"Expected Answer\": expected_answer,\n",
    "        \"Cosine Similarity\": cosine_sim,\n",
    "        # Separate ROUGE metrics\n",
    "        \"ROUGE-1\": rouge_result['rouge1'],\n",
    "        \"ROUGE-2\": rouge_result['rouge2'],\n",
    "        \"ROUGE-L\": rouge_result['rougeL'],\n",
    "        \"ROUGE-Lsum\": rouge_result['rougeLsum'],\n",
    "        # Separate BLEU metrics\n",
    "        \"BLEU\": bleu_result['bleu'],\n",
    "        \"Precision_1\": bleu_result['precisions'][0] if len(bleu_result['precisions']) > 0 else None,\n",
    "        \"Precision_2\": bleu_result['precisions'][1] if len(bleu_result['precisions']) > 1 else None,\n",
    "        \"Precision_3\": bleu_result['precisions'][2] if len(bleu_result['precisions']) > 2 else None,\n",
    "        \"Precision_4\": bleu_result['precisions'][3] if len(bleu_result['precisions']) > 3 else None,\n",
    "        \"Brevity Penalty\": bleu_result['brevity_penalty'],\n",
    "        \"Length Ratio\": bleu_result['length_ratio'],\n",
    "        \"Translation Length\": bleu_result['translation_length'],\n",
    "        \"Reference Length\": bleu_result['reference_length'],\n",
    "    })\n",
    "\n",
    "# Create a DataFrame for tabular results\n",
    "df = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Question</th>\n",
       "      <th>Generated Answer</th>\n",
       "      <th>Expected Answer</th>\n",
       "      <th>Cosine Similarity</th>\n",
       "      <th>ROUGE-1</th>\n",
       "      <th>ROUGE-2</th>\n",
       "      <th>ROUGE-L</th>\n",
       "      <th>ROUGE-Lsum</th>\n",
       "      <th>BLEU</th>\n",
       "      <th>Precision_1</th>\n",
       "      <th>Precision_2</th>\n",
       "      <th>Precision_3</th>\n",
       "      <th>Precision_4</th>\n",
       "      <th>Brevity Penalty</th>\n",
       "      <th>Length Ratio</th>\n",
       "      <th>Translation Length</th>\n",
       "      <th>Reference Length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What are the genres of 'Star Wars: Episode IV ...</td>\n",
       "      <td>The genres of 'Star Wars: Episode IV - A New H...</td>\n",
       "      <td>The genres of 'Star Wars: Episode IV - A New H...</td>\n",
       "      <td>0.986958</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.676192</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>0.588235</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>How many users rated 'Jungle Book, The'?</td>\n",
       "      <td>1 user rated 'Jungle Book, The'</td>\n",
       "      <td>1 users rated 'Jungle Book, The'.</td>\n",
       "      <td>0.975744</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.557800</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.866878</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I like the movie 'Dumb &amp; Dumber (Dumb and Dumb...</td>\n",
       "      <td>Based on the genres of the movie 'Dumb &amp; Dumbe...</td>\n",
       "      <td>Based on your preference for 'Dumb &amp; Dumber (D...</td>\n",
       "      <td>0.982890</td>\n",
       "      <td>0.867470</td>\n",
       "      <td>0.814815</td>\n",
       "      <td>0.795181</td>\n",
       "      <td>0.795181</td>\n",
       "      <td>0.762731</td>\n",
       "      <td>0.959184</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.872340</td>\n",
       "      <td>0.847826</td>\n",
       "      <td>0.849366</td>\n",
       "      <td>0.859649</td>\n",
       "      <td>49</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What are the ratings for 'Taxi Driver'?</td>\n",
       "      <td>User 1 rated 'Taxi Driver' with a rating of 5.0</td>\n",
       "      <td>The ratings for 'Taxi Driver' are 5.0.</td>\n",
       "      <td>0.881614</td>\n",
       "      <td>0.421053</td>\n",
       "      <td>0.235294</td>\n",
       "      <td>0.421053</td>\n",
       "      <td>0.421053</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.250000</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Find all movies released in 1993.</td>\n",
       "      <td>The movies released in 1993 are: Three Colors:...</td>\n",
       "      <td>The movies released in 1993 are 'Three Colors:...</td>\n",
       "      <td>0.941492</td>\n",
       "      <td>0.931507</td>\n",
       "      <td>0.760563</td>\n",
       "      <td>0.876712</td>\n",
       "      <td>0.876712</td>\n",
       "      <td>0.280099</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.240000</td>\n",
       "      <td>0.183673</td>\n",
       "      <td>0.908324</td>\n",
       "      <td>0.912281</td>\n",
       "      <td>52</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Question  \\\n",
       "0  What are the genres of 'Star Wars: Episode IV ...   \n",
       "1           How many users rated 'Jungle Book, The'?   \n",
       "2  I like the movie 'Dumb & Dumber (Dumb and Dumb...   \n",
       "3            What are the ratings for 'Taxi Driver'?   \n",
       "4                  Find all movies released in 1993.   \n",
       "\n",
       "                                    Generated Answer  \\\n",
       "0  The genres of 'Star Wars: Episode IV - A New H...   \n",
       "1                    1 user rated 'Jungle Book, The'   \n",
       "2  Based on the genres of the movie 'Dumb & Dumbe...   \n",
       "3    User 1 rated 'Taxi Driver' with a rating of 5.0   \n",
       "4  The movies released in 1993 are: Three Colors:...   \n",
       "\n",
       "                                     Expected Answer  Cosine Similarity  \\\n",
       "0  The genres of 'Star Wars: Episode IV - A New H...           0.986958   \n",
       "1                  1 users rated 'Jungle Book, The'.           0.975744   \n",
       "2  Based on your preference for 'Dumb & Dumber (D...           0.982890   \n",
       "3             The ratings for 'Taxi Driver' are 5.0.           0.881614   \n",
       "4  The movies released in 1993 are 'Three Colors:...           0.941492   \n",
       "\n",
       "    ROUGE-1   ROUGE-2   ROUGE-L  ROUGE-Lsum      BLEU  Precision_1  \\\n",
       "0  1.000000  0.800000  0.875000    0.875000  0.676192     0.850000   \n",
       "1  0.833333  0.600000  0.833333    0.833333  0.557800     0.857143   \n",
       "2  0.867470  0.814815  0.795181    0.795181  0.762731     0.959184   \n",
       "3  0.421053  0.235294  0.421053    0.421053  0.000000     0.300000   \n",
       "4  0.931507  0.760563  0.876712    0.876712  0.280099     0.615385   \n",
       "\n",
       "   Precision_2  Precision_3  Precision_4  Brevity Penalty  Length Ratio  \\\n",
       "0     0.684211     0.611111     0.588235         1.000000      1.000000   \n",
       "1     0.666667     0.600000     0.500000         0.866878      0.875000   \n",
       "2     0.916667     0.872340     0.847826         0.849366      0.859649   \n",
       "3     0.111111     0.000000     0.000000         1.000000      1.250000   \n",
       "4     0.333333     0.240000     0.183673         0.908324      0.912281   \n",
       "\n",
       "   Translation Length  Reference Length  \n",
       "0                  20                20  \n",
       "1                   7                 8  \n",
       "2                  49                57  \n",
       "3                  10                 8  \n",
       "4                  52                57  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average ROUGE-1: 0.7230897798298865\n",
      "Average ROUGE-2: 0.5811408347565529\n",
      "Average ROUGE-L: 0.6995416412239113\n",
      "Average ROUGE-L: 0.6995416412239113\n",
      "Average BLEU: 0.3841377879656104\n",
      "Average Cosine Similarity: 0.830061561491707\n"
     ]
    }
   ],
   "source": [
    "# Print the average scores\n",
    "print(f\"Average ROUGE-1: {df['ROUGE-1'].mean()}\")\n",
    "print(f\"Average ROUGE-2: {df['ROUGE-2'].mean()}\")\n",
    "print(f\"Average ROUGE-L: {df['ROUGE-L'].mean()}\")\n",
    "print(f\"Average ROUGE-L: {df['ROUGE-Lsum'].mean()}\")\n",
    "print(f\"Average BLEU: {df['BLEU'].mean()}\")\n",
    "print(f\"Average Cosine Similarity: {df['Cosine Similarity'].mean()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def calculate_ndcg(relevant_items, generated_items, k):\n",
    "    # Get relevance scores for the generated items\n",
    "    relevance_scores = [1 if item in relevant_items else 0 for item in generated_items[:k]]\n",
    "    \n",
    "    # Calculate DCG\n",
    "    dcg = sum(relevance_scores[i] / np.log2(i + 2) for i in range(len(relevance_scores)))\n",
    "    \n",
    "    # Calculate IDCG\n",
    "    sorted_relevance_scores = sorted(relevance_scores, reverse=True)\n",
    "    idcg = sum(sorted_relevance_scores[i] / np.log2(i + 2) for i in range(len(sorted_relevance_scores)))\n",
    "\n",
    "    # Handle the case where IDCG is zero to avoid division by zero\n",
    "    if idcg == 0:\n",
    "        return 0.0\n",
    "    \n",
    "    # Calculate NDCG\n",
    "    ndcg = dcg / idcg\n",
    "    return ndcg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/agent/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [1, 3]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 43\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ndcg_scores, precision_scores, recall_scores, f1_scores\n\u001b[1;32m     42\u001b[0m \u001b[38;5;66;03m# Example of using the function\u001b[39;00m\n\u001b[0;32m---> 43\u001b[0m ndcg_scores, precision_scores, recall_scores, f1_scores \u001b[38;5;241m=\u001b[39m \u001b[43mcalculate_metrics\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluation_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[7], line 33\u001b[0m, in \u001b[0;36mcalculate_metrics\u001b[0;34m(evaluation_data, k)\u001b[0m\n\u001b[1;32m     30\u001b[0m precision_scores\u001b[38;5;241m.\u001b[39mappend(precision)\n\u001b[1;32m     32\u001b[0m \u001b[38;5;66;03m# Calculate Recall@k\u001b[39;00m\n\u001b[0;32m---> 33\u001b[0m recall \u001b[38;5;241m=\u001b[39m \u001b[43mrecall_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mrelevant_items\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     34\u001b[0m recall_scores\u001b[38;5;241m.\u001b[39mappend(recall)\n\u001b[1;32m     36\u001b[0m \u001b[38;5;66;03m# Calculate F1@k\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/agent/lib/python3.11/site-packages/sklearn/utils/_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    211\u001b[0m         )\n\u001b[1;32m    212\u001b[0m     ):\n\u001b[0;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    223\u001b[0m     )\n",
      "File \u001b[0;32m/opt/anaconda3/envs/agent/lib/python3.11/site-packages/sklearn/metrics/_classification.py:2385\u001b[0m, in \u001b[0;36mrecall_score\u001b[0;34m(y_true, y_pred, labels, pos_label, average, sample_weight, zero_division)\u001b[0m\n\u001b[1;32m   2217\u001b[0m \u001b[38;5;129m@validate_params\u001b[39m(\n\u001b[1;32m   2218\u001b[0m     {\n\u001b[1;32m   2219\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_true\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray-like\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msparse matrix\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2244\u001b[0m     zero_division\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwarn\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   2245\u001b[0m ):\n\u001b[1;32m   2246\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Compute the recall.\u001b[39;00m\n\u001b[1;32m   2247\u001b[0m \n\u001b[1;32m   2248\u001b[0m \u001b[38;5;124;03m    The recall is the ratio ``tp / (tp + fn)`` where ``tp`` is the number of\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2383\u001b[0m \u001b[38;5;124;03m    array([1. , 1. , 0.5])\u001b[39;00m\n\u001b[1;32m   2384\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 2385\u001b[0m     _, r, _, _ \u001b[38;5;241m=\u001b[39m \u001b[43mprecision_recall_fscore_support\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2386\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2387\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2388\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2389\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpos_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpos_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2390\u001b[0m \u001b[43m        \u001b[49m\u001b[43maverage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maverage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2391\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwarn_for\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrecall\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2392\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2393\u001b[0m \u001b[43m        \u001b[49m\u001b[43mzero_division\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mzero_division\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2394\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2395\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m r\n",
      "File \u001b[0;32m/opt/anaconda3/envs/agent/lib/python3.11/site-packages/sklearn/utils/_param_validation.py:186\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    184\u001b[0m global_skip_validation \u001b[38;5;241m=\u001b[39m get_config()[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mskip_parameter_validation\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    185\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m global_skip_validation:\n\u001b[0;32m--> 186\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    188\u001b[0m func_sig \u001b[38;5;241m=\u001b[39m signature(func)\n\u001b[1;32m    190\u001b[0m \u001b[38;5;66;03m# Map *args/**kwargs to the function signature\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/agent/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1789\u001b[0m, in \u001b[0;36mprecision_recall_fscore_support\u001b[0;34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight, zero_division)\u001b[0m\n\u001b[1;32m   1626\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Compute precision, recall, F-measure and support for each class.\u001b[39;00m\n\u001b[1;32m   1627\u001b[0m \n\u001b[1;32m   1628\u001b[0m \u001b[38;5;124;03mThe precision is the ratio ``tp / (tp + fp)`` where ``tp`` is the number of\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1786\u001b[0m \u001b[38;5;124;03m array([2, 2, 2]))\u001b[39;00m\n\u001b[1;32m   1787\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1788\u001b[0m _check_zero_division(zero_division)\n\u001b[0;32m-> 1789\u001b[0m labels \u001b[38;5;241m=\u001b[39m \u001b[43m_check_set_wise_labels\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maverage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpos_label\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1791\u001b[0m \u001b[38;5;66;03m# Calculate tp_sum, pred_sum, true_sum ###\u001b[39;00m\n\u001b[1;32m   1792\u001b[0m samplewise \u001b[38;5;241m=\u001b[39m average \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msamples\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/agent/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561\u001b[0m, in \u001b[0;36m_check_set_wise_labels\u001b[0;34m(y_true, y_pred, average, labels, pos_label)\u001b[0m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m average \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m average_options \u001b[38;5;129;01mand\u001b[39;00m average \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m   1559\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maverage has to be one of \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(average_options))\n\u001b[0;32m-> 1561\u001b[0m y_type, y_true, y_pred \u001b[38;5;241m=\u001b[39m \u001b[43m_check_targets\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1562\u001b[0m \u001b[38;5;66;03m# Convert to Python primitive type to avoid NumPy type / Python str\u001b[39;00m\n\u001b[1;32m   1563\u001b[0m \u001b[38;5;66;03m# comparison. See https://github.com/numpy/numpy/issues/6784\u001b[39;00m\n\u001b[1;32m   1564\u001b[0m present_labels \u001b[38;5;241m=\u001b[39m unique_labels(y_true, y_pred)\u001b[38;5;241m.\u001b[39mtolist()\n",
      "File \u001b[0;32m/opt/anaconda3/envs/agent/lib/python3.11/site-packages/sklearn/metrics/_classification.py:103\u001b[0m, in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Check that y_true and y_pred belong to the same classification task.\u001b[39;00m\n\u001b[1;32m     77\u001b[0m \n\u001b[1;32m     78\u001b[0m \u001b[38;5;124;03mThis converts multiclass or binary types to a common shape, and raises a\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[38;5;124;03my_pred : array or indicator matrix\u001b[39;00m\n\u001b[1;32m    101\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    102\u001b[0m xp, _ \u001b[38;5;241m=\u001b[39m get_namespace(y_true, y_pred)\n\u001b[0;32m--> 103\u001b[0m \u001b[43mcheck_consistent_length\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    104\u001b[0m type_true \u001b[38;5;241m=\u001b[39m type_of_target(y_true, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_true\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    105\u001b[0m type_pred \u001b[38;5;241m=\u001b[39m type_of_target(y_pred, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_pred\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/agent/lib/python3.11/site-packages/sklearn/utils/validation.py:457\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    455\u001b[0m uniques \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(lengths)\n\u001b[1;32m    456\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(uniques) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 457\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    458\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    459\u001b[0m         \u001b[38;5;241m%\u001b[39m [\u001b[38;5;28mint\u001b[39m(l) \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m lengths]\n\u001b[1;32m    460\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [1, 3]"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "import numpy as np\n",
    "\n",
    "def calculate_metrics(evaluation_data, k):\n",
    "    ndcg_scores = []\n",
    "    precision_scores = []\n",
    "    recall_scores = []\n",
    "    f1_scores = []\n",
    "\n",
    "    for data in evaluation_data:\n",
    "        question = data[\"question\"]\n",
    "        expected_answer = data[\"answer\"]\n",
    "        generated_answer = data[\"LLM\"]\n",
    "\n",
    "        if \"User Mistaake.\" in generated_answer or \"ERROR: SAFETY Issue.\" in generated_answer:\n",
    "            continue  # Skip this entry if there's an error message\n",
    "        \n",
    "        # Assume the expected answer is the only relevant item for simplicity\n",
    "        relevant_items = [expected_answer]\n",
    "        generated_items = generated_answer.split(\", \")  # Assuming comma-separated answers\n",
    "\n",
    "        # Calculate NDCG@k\n",
    "        # You can implement the NDCG function according to your relevance scoring\n",
    "        ndcg_score = calculate_ndcg(relevant_items, generated_items, k)  # Implement this function\n",
    "        ndcg_scores.append(ndcg_score)\n",
    "\n",
    "        # Calculate Precision@k\n",
    "        y_true = [1 if answer in relevant_items else 0 for answer in generated_items[:k]]\n",
    "        precision = precision_score([1] * len(y_true), y_true)\n",
    "        precision_scores.append(precision)\n",
    "\n",
    "        # Calculate Recall@k\n",
    "        recall = recall_score([1] * len(relevant_items), y_true)\n",
    "        recall_scores.append(recall)\n",
    "\n",
    "        # Calculate F1@k\n",
    "        f1 = f1_score([1] * len(relevant_items), y_true)\n",
    "        f1_scores.append(f1)\n",
    "\n",
    "    return ndcg_scores, precision_scores, recall_scores, f1_scores\n",
    "\n",
    "# Example of using the function\n",
    "ndcg_scores, precision_scores, recall_scores, f1_scores = calculate_metrics(evaluation_data, k=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agent",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
