{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/agent/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv() ## load all the environment variables from .env\n",
    "import glob\n",
    "# import streamlit as st\n",
    "import os\n",
    "from PIL import Image\n",
    "import google.generativeai as genai\n",
    "from IPython.display import display\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import textwrap\n",
    "from typing import List, Dict, Tuple, Optional # For type hinting\n",
    "import time\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genai.configure(api_key=os.getenv(\"GOOGLE_API_KEY\"))\n",
    "\n",
    "## Load Gemini model\n",
    "model=genai.GenerativeModel('gemini-2.0-flash-thinking-exp-01-21')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gemini_response(input,image,user_prompt):\n",
    "    response=model.generate_content([input,image[0],user_prompt])\n",
    "    return response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading files in 2022...\n",
      "Reading files in 2024...\n",
      "Reading files in 2023...\n",
      "Reading files in 2021...\n",
      "Reading files in 2020...\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "data_directory = 'data/ranking_data/'\n",
    "records = []\n",
    "\n",
    "def safe_get(data, keys, default=None):\n",
    "    \"\"\"\n",
    "    Safely get a nested key from a dictionary using a list of keys.\n",
    "    Returns default if any key is missing.\n",
    "    \"\"\"\n",
    "    for key in keys:\n",
    "        if isinstance(data, dict) and key in data:\n",
    "            data = data[key]\n",
    "        else:\n",
    "            return default\n",
    "    return data\n",
    "\n",
    "for sub_dir in os.listdir(data_directory):\n",
    "    print(f\"Reading files in {sub_dir}...\")\n",
    "    sub_directory = os.path.join(data_directory, sub_dir)\n",
    "    for filename in os.listdir(sub_directory):\n",
    "        if filename.endswith('.json'):\n",
    "            filepath = os.path.join(sub_directory, filename)\n",
    "            try:\n",
    "                with open(filepath, 'r') as file:\n",
    "                    data = json.load(file)\n",
    "            except Exception as e:\n",
    "                print(f\"Error reading {filepath}: {e}\")\n",
    "                continue\n",
    "\n",
    "            # Extract award-level context information safely\n",
    "            award_type = data.get(\"awd_istr_txt\")\n",
    "            award_title = data.get(\"awd_titl_txt\")\n",
    "            abstract = data.get(\"abst_narr_txt\")\n",
    "            org_name = data.get(\"org_long_name\")\n",
    "            org_name2 = data.get(\"org_long_name2\")\n",
    "            perf_inst_name = safe_get(data, [\"perf_inst\", \"perf_inst_name\"])\n",
    "            \n",
    "            # Extract program element and reference safely (checking if list exists)\n",
    "            pgm_ele_list = data.get(\"pgm_ele\")\n",
    "            if isinstance(pgm_ele_list, list) and len(pgm_ele_list) > 0:\n",
    "                program_element = pgm_ele_list[0].get(\"pgm_ele_long_name\")\n",
    "            else:\n",
    "                program_element = None\n",
    "\n",
    "            pgm_ref_list = data.get(\"pgm_ref\")\n",
    "            if isinstance(pgm_ref_list, list) and len(pgm_ref_list) > 0:\n",
    "                program_reference = pgm_ref_list[0].get(\"pgm_ref_long_name\")\n",
    "            else:\n",
    "                program_reference = None\n",
    "\n",
    "            # Get investigator information, ensuring it's a list\n",
    "            pi_list = data.get(\"pi\")\n",
    "            if not isinstance(pi_list, list):\n",
    "                continue\n",
    "\n",
    "            # Loop through each investigator in the file\n",
    "            for pi in pi_list:\n",
    "                record = {\n",
    "                    \"award_type\": award_type,\n",
    "                    \"award_title\": award_title,\n",
    "                    \"abstract\": abstract,\n",
    "                    \"org_name\": org_name,\n",
    "                    \"org_name2\": org_name2,\n",
    "                    \"perf_inst_name\": perf_inst_name,\n",
    "                    \"program_element\": program_element,\n",
    "                    \"program_reference\": program_reference,\n",
    "                    \"pi_id\": pi.get(\"pi_id\"),\n",
    "                    \"pi_full_name\": pi.get(\"pi_full_name\", \"\").strip() if pi.get(\"pi_full_name\") else None,\n",
    "                    \"role\": pi.get(\"proj_role_code2\", \"\").strip() if pi.get(\"proj_role_code2\") else None,\n",
    "                    \"department\": pi.get(\"pi_dept_name\"),\n",
    "                    \"email\": pi.get(\"pi_email_addr\"),\n",
    "                    \"start_date\": pi.get(\"start_date\")\n",
    "                }\n",
    "                records.append(record)\n",
    "\n",
    "# Create a DataFrame from the records\n",
    "df = pd.DataFrame(records)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>award_type</th>\n",
       "      <th>award_title</th>\n",
       "      <th>abstract</th>\n",
       "      <th>org_name</th>\n",
       "      <th>org_name2</th>\n",
       "      <th>perf_inst_name</th>\n",
       "      <th>program_element</th>\n",
       "      <th>program_reference</th>\n",
       "      <th>pi_id</th>\n",
       "      <th>pi_full_name</th>\n",
       "      <th>role</th>\n",
       "      <th>department</th>\n",
       "      <th>email</th>\n",
       "      <th>start_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Standard Grant</td>\n",
       "      <td>MRI: Acquisition of a High-Performance Computa...</td>\n",
       "      <td>This project will acquire and deploy a high-pe...</td>\n",
       "      <td>Directorate for Computer and Information Scien...</td>\n",
       "      <td>Office of Advanced Cyberinfrastructure (OAC)</td>\n",
       "      <td>Oklahoma State University</td>\n",
       "      <td>Major Research Instrumentation</td>\n",
       "      <td>WOMEN, MINORITY, DISABLED, NEC</td>\n",
       "      <td>269967889</td>\n",
       "      <td>Terrance   Figy</td>\n",
       "      <td>Co-Principal Investigator</td>\n",
       "      <td>Mathematics, Statistics, and Physics</td>\n",
       "      <td>Terrance.Figy@wichita.edu</td>\n",
       "      <td>2024-08-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Standard Grant</td>\n",
       "      <td>MRI: Acquisition of a High-Performance Computa...</td>\n",
       "      <td>This project will acquire and deploy a high-pe...</td>\n",
       "      <td>Directorate for Computer and Information Scien...</td>\n",
       "      <td>Office of Advanced Cyberinfrastructure (OAC)</td>\n",
       "      <td>Oklahoma State University</td>\n",
       "      <td>Major Research Instrumentation</td>\n",
       "      <td>WOMEN, MINORITY, DISABLED, NEC</td>\n",
       "      <td>269758255</td>\n",
       "      <td>Pratul K Agarwal</td>\n",
       "      <td>Principal Investigator</td>\n",
       "      <td></td>\n",
       "      <td>pratul.agarwal@okstate.edu</td>\n",
       "      <td>2022-08-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Standard Grant</td>\n",
       "      <td>MRI: Acquisition of a High-Performance Computa...</td>\n",
       "      <td>This project will acquire and deploy a high-pe...</td>\n",
       "      <td>Directorate for Computer and Information Scien...</td>\n",
       "      <td>Office of Advanced Cyberinfrastructure (OAC)</td>\n",
       "      <td>Oklahoma State University</td>\n",
       "      <td>Major Research Instrumentation</td>\n",
       "      <td>WOMEN, MINORITY, DISABLED, NEC</td>\n",
       "      <td>000224099</td>\n",
       "      <td>Mickey   Slimp</td>\n",
       "      <td>Co-Principal Investigator</td>\n",
       "      <td>Department of Chemistry</td>\n",
       "      <td></td>\n",
       "      <td>2024-08-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Standard Grant</td>\n",
       "      <td>MRI: Acquisition of a High-Performance Computa...</td>\n",
       "      <td>This project will acquire and deploy a high-pe...</td>\n",
       "      <td>Directorate for Computer and Information Scien...</td>\n",
       "      <td>Office of Advanced Cyberinfrastructure (OAC)</td>\n",
       "      <td>Oklahoma State University</td>\n",
       "      <td>Major Research Instrumentation</td>\n",
       "      <td>WOMEN, MINORITY, DISABLED, NEC</td>\n",
       "      <td>269666332</td>\n",
       "      <td>William H Hsu</td>\n",
       "      <td>Co-Principal Investigator</td>\n",
       "      <td>Computer Science</td>\n",
       "      <td>bhsu@ksu.edu</td>\n",
       "      <td>2022-08-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Standard Grant</td>\n",
       "      <td>MRI: Acquisition of a High-Performance Computa...</td>\n",
       "      <td>This project will acquire and deploy a high-pe...</td>\n",
       "      <td>Directorate for Computer and Information Scien...</td>\n",
       "      <td>Office of Advanced Cyberinfrastructure (OAC)</td>\n",
       "      <td>Oklahoma State University</td>\n",
       "      <td>Major Research Instrumentation</td>\n",
       "      <td>WOMEN, MINORITY, DISABLED, NEC</td>\n",
       "      <td>270046494</td>\n",
       "      <td>Robert   Fleming</td>\n",
       "      <td>Co-Principal Investigator</td>\n",
       "      <td>Engineering</td>\n",
       "      <td>rofleming@AState.edu</td>\n",
       "      <td>2024-08-29</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       award_type                                        award_title  \\\n",
       "0  Standard Grant  MRI: Acquisition of a High-Performance Computa...   \n",
       "1  Standard Grant  MRI: Acquisition of a High-Performance Computa...   \n",
       "2  Standard Grant  MRI: Acquisition of a High-Performance Computa...   \n",
       "4  Standard Grant  MRI: Acquisition of a High-Performance Computa...   \n",
       "7  Standard Grant  MRI: Acquisition of a High-Performance Computa...   \n",
       "\n",
       "                                            abstract  \\\n",
       "0  This project will acquire and deploy a high-pe...   \n",
       "1  This project will acquire and deploy a high-pe...   \n",
       "2  This project will acquire and deploy a high-pe...   \n",
       "4  This project will acquire and deploy a high-pe...   \n",
       "7  This project will acquire and deploy a high-pe...   \n",
       "\n",
       "                                            org_name  \\\n",
       "0  Directorate for Computer and Information Scien...   \n",
       "1  Directorate for Computer and Information Scien...   \n",
       "2  Directorate for Computer and Information Scien...   \n",
       "4  Directorate for Computer and Information Scien...   \n",
       "7  Directorate for Computer and Information Scien...   \n",
       "\n",
       "                                      org_name2             perf_inst_name  \\\n",
       "0  Office of Advanced Cyberinfrastructure (OAC)  Oklahoma State University   \n",
       "1  Office of Advanced Cyberinfrastructure (OAC)  Oklahoma State University   \n",
       "2  Office of Advanced Cyberinfrastructure (OAC)  Oklahoma State University   \n",
       "4  Office of Advanced Cyberinfrastructure (OAC)  Oklahoma State University   \n",
       "7  Office of Advanced Cyberinfrastructure (OAC)  Oklahoma State University   \n",
       "\n",
       "                  program_element               program_reference      pi_id  \\\n",
       "0  Major Research Instrumentation  WOMEN, MINORITY, DISABLED, NEC  269967889   \n",
       "1  Major Research Instrumentation  WOMEN, MINORITY, DISABLED, NEC  269758255   \n",
       "2  Major Research Instrumentation  WOMEN, MINORITY, DISABLED, NEC  000224099   \n",
       "4  Major Research Instrumentation  WOMEN, MINORITY, DISABLED, NEC  269666332   \n",
       "7  Major Research Instrumentation  WOMEN, MINORITY, DISABLED, NEC  270046494   \n",
       "\n",
       "       pi_full_name                       role  \\\n",
       "0   Terrance   Figy  Co-Principal Investigator   \n",
       "1  Pratul K Agarwal     Principal Investigator   \n",
       "2    Mickey   Slimp  Co-Principal Investigator   \n",
       "4     William H Hsu  Co-Principal Investigator   \n",
       "7  Robert   Fleming  Co-Principal Investigator   \n",
       "\n",
       "                             department                       email  \\\n",
       "0  Mathematics, Statistics, and Physics   Terrance.Figy@wichita.edu   \n",
       "1                                        pratul.agarwal@okstate.edu   \n",
       "2               Department of Chemistry                               \n",
       "4                      Computer Science                bhsu@ksu.edu   \n",
       "7                           Engineering        rofleming@AState.edu   \n",
       "\n",
       "   start_date  \n",
       "0  2024-08-29  \n",
       "1  2022-08-03  \n",
       "2  2024-08-29  \n",
       "4  2022-08-03  \n",
       "7  2024-08-29  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[df['role'].isin(['Co-Principal Investigator', 'Principal Investigator'])]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import google.generativeai as genai # Assuming you use this library\n",
    "# import time\n",
    "# import textwrap # Useful for formatting text nicely\n",
    "\n",
    "# # --- Input Parameters ---\n",
    "# pi_ids_to_analyze = ['000025017', '000025762', '000030655']\n",
    "# research_topic = 'STATISTICS'\n",
    "\n",
    "# # --- 1. Filter DataFrame ---\n",
    "# # Select rows where 'pi_id' is in our list of interest\n",
    "# filtered_df = df[df['pi_id'].isin(pi_ids_to_analyze)].copy() # Use .copy() to avoid potential SettingWithCopyWarning\n",
    "\n",
    "# # --- 2. Format Data for the Prompt ---\n",
    "# formatted_pi_data = \"\"\n",
    "# pi_names = {} # Dictionary to store PI names for easier reference\n",
    "\n",
    "# if filtered_df.empty:\n",
    "#     print(f\"Warning: No data found in the DataFrame for the provided PI IDs: {pi_ids_to_analyze}\")\n",
    "#     # Decide how to proceed - perhaps exit or send a prompt indicating no data\n",
    "#     formatted_pi_data = \"No data could be retrieved for the specified potential collaborators.\"\n",
    "#     # If you still want to query the model, it needs to know data is missing.\n",
    "#     # Or you might skip the API call entirely.\n",
    "# else:\n",
    "#     # Group data by PI to present it coherently\n",
    "#     for pi_id in pi_ids_to_analyze:\n",
    "#         pi_specific_data = filtered_df[filtered_df['pi_id'] == pi_id]\n",
    "\n",
    "#         if not pi_specific_data.empty:\n",
    "#             # Try to get a consistent name and department\n",
    "#             # Taking the first entry assuming it's representative for name/dept\n",
    "#             full_name = pi_specific_data['pi_full_name'].iloc[0]\n",
    "#             department = pi_specific_data['department'].iloc[0]\n",
    "#             pi_names[pi_id] = full_name # Store for later use in prompt\n",
    "\n",
    "#             formatted_pi_data += f\"--- Researcher: {full_name} (ID: {pi_id}) ---\\n\"\n",
    "#             formatted_pi_data += f\"Department: {department}\\n\"\n",
    "#             formatted_pi_data += \"Relevant Roles & Awards Found:\\n\"\n",
    "\n",
    "#             # Iterate through each award/entry for this PI\n",
    "#             for index, row in pi_specific_data.iterrows():\n",
    "#                 formatted_pi_data += f\"- Role: {row.get('role', 'N/A')}\\n\" # Use .get for safety if column might be missing\n",
    "#                 formatted_pi_data += f\"  Award Title: {row.get('award_title', 'N/A')}\\n\"\n",
    "#                 formatted_pi_data += f\"  Start Date: {row.get('start_date', 'N/A')}\\n\"\n",
    "#                 # Shorten abstract to keep context concise\n",
    "#                 abstract_preview = textwrap.shorten(row.get('abstract', 'N/A'), width=200, placeholder=\"...\")\n",
    "#                 formatted_pi_data += f\"  Abstract Snippet: {abstract_preview}\\n\"\n",
    "#                 formatted_pi_data += f\"  Program Element/Reference: {row.get('program_element', 'N/A')} / {row.get('program_reference', 'N/A')}\\n\\n\" # Add space between awards\n",
    "\n",
    "#         else:\n",
    "#             # Handle case where a PI ID from the list was not found in the df\n",
    "#              formatted_pi_data += f\"--- Researcher ID: {pi_id} ---\\n\"\n",
    "#              formatted_pi_data += \"No award data found in the provided dataset for this PI.\\n\\n\"\n",
    "#              pi_names[pi_id] = f\"PI ID {pi_id}\" # Placeholder name\n",
    "\n",
    "# # --- 3. Construct the Prompt ---\n",
    "# # Get a comma-separated list of names for the prompt text\n",
    "# collaborator_names_list = \", \".join(pi_names.values())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# collaborator_names_list\n",
    "# print(formatted_pi_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# full_prompt = f\"\"\"\n",
    "# Context:\n",
    "# The following researchers ({collaborator_names_list}) are considering collaborating on a new research project focused on the topic '{research_topic}'. Below is information extracted from a database about their previous grants and roles:\n",
    "\n",
    "# {formatted_pi_data}\n",
    "\n",
    "# Task:\n",
    "# Based *only* on the information provided above, please analyze the qualifications, experience, and relevance of past work for each researcher ({collaborator_names_list}). Recommend which of these individuals would be the most suitable Principal Investigator (PI) to lead this new collaborative project on '{research_topic}'.\n",
    "\n",
    "# Provide a detailed explanation for your recommendation. Consider factors apparent from the data, such as:\n",
    "# - Direct relevance of their past research (award titles, abstracts, program elements) to the topic '{research_topic}'.\n",
    "# - Demonstrated experience (e.g., number of awards listed, roles held like 'Principal Investigator').\n",
    "# - Any indicators of leadership or seniority (e.g., award types like 'Career Award' if present, consistent PI roles).\n",
    "\n",
    "# Please identify the suggested PI clearly by name and justify your choice thoroughly using specific evidence from the provided context. If the data is insufficient to make a strong recommendation for any particular candidate, please state that clearly as well.\n",
    "# \"\"\"\n",
    "\n",
    "# print(\"--- Sending Request to Gemini ---\")\n",
    "\n",
    "# start_time = time.time()\n",
    "\n",
    "# contents = [full_prompt] # Pass the combined prompt as a single text part\n",
    "\n",
    "# try:\n",
    "#     # *** Ensure 'model' is your loaded and configured Gemini model object ***\n",
    "#     responses = model.generate_content(contents, stream=True)\n",
    "\n",
    "#     # --- 5. Process and Print the Response ---\n",
    "#     print(\"\\n-------Response--------\")\n",
    "#     full_response_text = \"\"\n",
    "#     for response in responses:\n",
    "#         print(response.text, end=\"\")\n",
    "#         full_response_text += response.text # Accumulate the full response if needed later\n",
    "#     print(\"\\n-----------------------\")\n",
    "\n",
    "#     response_time = time.time() - start_time\n",
    "#     print(f\"\\nResponse generated in {response_time:.2f} seconds.\")\n",
    "\n",
    "# except AttributeError:\n",
    "#      print(\"\\nError: 'model' object not found or not configured correctly.\")\n",
    "#      print(\"Please ensure the 'model' variable holds your loaded Gemini model.\")\n",
    "# except Exception as e:\n",
    "#     print(f\"\\nAn error occurred during the API call: {e}\")\n",
    "#     response_time = time.time() - start_time # Measure time even if error occurs\n",
    "#     print(f\"Attempt failed after {response_time:.2f} seconds.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(83112, 14)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_data_by_pi(df: pd.DataFrame, pi_ids: List[str]) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Filters the DataFrame to include only rows matching the provided PI IDs.\n",
    "\n",
    "    Args:\n",
    "        df: The input DataFrame.\n",
    "        pi_ids: A list of PI IDs (strings) to filter by.\n",
    "\n",
    "    Returns:\n",
    "        A DataFrame containing only the rows for the specified PI IDs.\n",
    "    \"\"\"\n",
    "    print(f\"Filtering DataFrame for PI IDs: {pi_ids}...\")\n",
    "    filtered = df[df['pi_id'].isin(pi_ids)].copy()\n",
    "    print(f\"Found {len(filtered)} relevant entries.\")\n",
    "    return filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_pi_data_for_prompt(filtered_df: pd.DataFrame, pi_ids_to_format: List[str]) -> Tuple[str, Dict[str, str]]:\n",
    "    \"\"\"\n",
    "    Formats the filtered PI data into a string suitable for the prompt context.\n",
    "\n",
    "    Args:\n",
    "        filtered_df: The DataFrame already filtered for relevant PIs.\n",
    "        pi_ids_to_format: The original list of PI IDs requested, to ensure all are mentioned.\n",
    "\n",
    "\n",
    "    Returns:\n",
    "        A tuple containing:\n",
    "            - formatted_data_string: A string with formatted details for each PI.\n",
    "            - pi_names_dict: A dictionary mapping PI ID to PI full name.\n",
    "    \"\"\"\n",
    "    print(\"Formatting data for prompt...\")\n",
    "    formatted_data = \"\"\n",
    "    pi_names = {} # Dictionary to store PI names\n",
    "\n",
    "    if filtered_df.empty:\n",
    "        print(\"Warning: Filtered DataFrame is empty. Formatting 'no data' message.\")\n",
    "        formatted_data = \"No data could be retrieved for the specified potential collaborators.\\n\"\n",
    "        for pi_id in pi_ids_to_format:\n",
    "             pi_names[pi_id] = f\"PI ID {pi_id}\" # Use ID as placeholder name\n",
    "        return formatted_data, pi_names\n",
    "\n",
    "    # Iterate through the original list to ensure all requested PIs are accounted for\n",
    "    for pi_id in pi_ids_to_format:\n",
    "        pi_specific_data = filtered_df[filtered_df['pi_id'] == pi_id]\n",
    "\n",
    "        if not pi_specific_data.empty:\n",
    "            # Get consistent name and department from the first entry\n",
    "            full_name = pi_specific_data['pi_full_name'].iloc[0]\n",
    "            department = pi_specific_data['department'].iloc[0]\n",
    "            pi_names[pi_id] = full_name\n",
    "\n",
    "            formatted_data += f\"--- Researcher: {full_name} (ID: {pi_id}) ---\\n\"\n",
    "            formatted_data += f\"Department: {department}\\n\"\n",
    "            formatted_data += \"Relevant Roles & Awards Found:\\n\"\n",
    "\n",
    "            for index, row in pi_specific_data.iterrows():\n",
    "                formatted_data += f\"- Role: {row.get('role', 'N/A')}\\n\"\n",
    "                formatted_data += f\"  Award Title: {row.get('award_title', 'N/A')}\\n\"\n",
    "                formatted_data += f\"  Start Date: {row.get('start_date', 'N/A')}\\n\"\n",
    "                abstract_preview = textwrap.shorten(row.get('abstract', 'N/A'), width=200, placeholder=\"...\")\n",
    "                formatted_data += f\"  Abstract Snippet: {abstract_preview}\\n\"\n",
    "                formatted_data += f\"  Program Element/Reference: {row.get('program_element', 'N/A')} / {row.get('program_reference', 'N/A')}\\n\\n\"\n",
    "        else:\n",
    "            # Handle case where a specific PI ID from the list had no data in the filtered df\n",
    "            formatted_data += f\"--- Researcher ID: {pi_id} ---\\n\"\n",
    "            formatted_data += \"No award data found in the provided dataset for this PI.\\n\\n\"\n",
    "            pi_names[pi_id] = f\"PI ID {pi_id}\" # Use ID as placeholder name\n",
    "\n",
    "    print(\"Data formatting complete.\")\n",
    "    return formatted_data, pi_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_recommendation_prompt(formatted_data_string: str, pi_names_dict: Dict[str, str], research_topic: str) -> str:\n",
    "    \"\"\"\n",
    "    Generates the full prompt string for the Gemini model.\n",
    "\n",
    "    Args:\n",
    "        formatted_data_string: The formatted string containing PI details.\n",
    "        pi_names_dict: A dictionary mapping PI ID to PI name.\n",
    "        research_topic: The research topic for collaboration.\n",
    "\n",
    "    Returns:\n",
    "        The complete prompt string.\n",
    "    \"\"\"\n",
    "    print(\"Generating prompt...\")\n",
    "    collaborator_names_list = \", \".join(pi_names_dict.values())\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "        Context:\n",
    "        The following researchers ({collaborator_names_list}) are considering collaborating on a new research project focused on the topic '{research_topic}'. Below is information extracted from a database about their previous grants and roles:\n",
    "\n",
    "        {formatted_data_string}\n",
    "\n",
    "        Task:\n",
    "        Based *only* on the information provided above, please analyze the qualifications, experience, and relevance of past work for each researcher ({collaborator_names_list}). Recommend which of these individuals would be the most suitable Principal Investigator (PI) to lead this new collaborative project on '{research_topic}'.\n",
    "\n",
    "        Provide a detailed explanation for your recommendation. Consider factors apparent from the data, such as:\n",
    "        - Direct relevance of their past research (award titles, abstracts, program elements) to the topic '{research_topic}'.\n",
    "        - Demonstrated experience (e.g., number of awards listed, roles held like 'Principal Investigator').\n",
    "        - Any indicators of leadership or seniority (e.g., award types like 'Career Award' if present, consistent PI roles).\n",
    "\n",
    "        Please identify the suggested PI clearly by name and justify your choice thoroughly using specific evidence from the provided context. If the data is insufficient to make a strong recommendation for any particular candidate, please state that clearly as well.\n",
    "        \"\"\"\n",
    "    print(\"Prompt generated.\")\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gemini_response(model: genai.GenerativeModel, prompt: str) -> Tuple[Optional[str], float]:\n",
    "    \"\"\"\n",
    "    Sends the prompt to the Gemini model, streams the response, and measures time.\n",
    "\n",
    "    Args:\n",
    "        model: The configured Gemini model object.\n",
    "        prompt: The prompt string to send to the model.\n",
    "\n",
    "    Returns:\n",
    "        A tuple containing:\n",
    "            - The full response text as a string (or None if an error occurs).\n",
    "            - The time taken for the API call in seconds.\n",
    "    \"\"\"\n",
    "    print(\"--- Sending Request to Gemini ---\")\n",
    "    start_time = time.time()\n",
    "    full_response_text = \"\"\n",
    "    contents = [prompt] # Prepare contents for the API\n",
    "\n",
    "    try:\n",
    "        responses = model.generate_content(contents, stream=True)\n",
    "\n",
    "        print(\"\\n-------Response--------\")\n",
    "        for response in responses:\n",
    "            print(response.text, end=\"\")\n",
    "            full_response_text += response.text\n",
    "        print(\"\\n-----------------------\")\n",
    "\n",
    "        response_time = time.time() - start_time\n",
    "        print(f\"\\nResponse generated in {response_time:.2f} seconds.\")\n",
    "        return full_response_text, response_time\n",
    "\n",
    "    except AttributeError:\n",
    "        response_time = time.time() - start_time\n",
    "        print(\"\\nError: 'model' object not found or not configured correctly.\")\n",
    "        print(\"Please ensure the 'model' variable holds your loaded Gemini model.\")\n",
    "        return None, response_time\n",
    "    except Exception as e:\n",
    "        response_time = time.time() - start_time\n",
    "        print(f\"\\nAn error occurred during the API call: {e}\")\n",
    "        print(f\"Attempt failed after {response_time:.2f} seconds.\")\n",
    "        return None, response_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_pi(df: pd.DataFrame, model: genai.GenerativeModel, pi_ids: List[str], research_topic: str) -> Optional[str]:\n",
    "    \"\"\"\n",
    "    Orchestrates the process of filtering data, formatting, generating prompt,\n",
    "    and getting a PI recommendation from the Gemini model.\n",
    "\n",
    "    Args:\n",
    "        df: The main DataFrame.\n",
    "        model: The configured Gemini model object.\n",
    "        pi_ids: A list of PI IDs to consider.\n",
    "        research_topic: The topic for collaboration.\n",
    "\n",
    "    Returns:\n",
    "        The recommendation text from the model, or None if an error occurred\n",
    "        or essential steps failed.\n",
    "    \"\"\"\n",
    "    print(f\"\\n--- Starting PI Recommendation Process for Topic: '{research_topic}' ---\")\n",
    "\n",
    "    # 1. Filter Data\n",
    "    filtered_data = filter_data_by_pi(df, pi_ids)\n",
    "    # Optional: Add a check here if you want to stop if no data is found at all\n",
    "    # if filtered_data.empty:\n",
    "    #     print(\"Stopping process as no data was found for any specified PI.\")\n",
    "    #     return None\n",
    "\n",
    "    # 2. Format Data\n",
    "    # Pass the original pi_ids list to ensure all are mentioned in formatting\n",
    "    formatted_text, pi_names = format_pi_data_for_prompt(filtered_data, pi_ids)\n",
    "\n",
    "    # 3. Generate Prompt\n",
    "    prompt_text = generate_recommendation_prompt(formatted_text, pi_names, research_topic)\n",
    "\n",
    "    # 4. Get Response\n",
    "    recommendation, duration = get_gemini_response(model, prompt_text)\n",
    "\n",
    "    print(f\"--- PI Recommendation Process Complete ({duration:.2f}s) ---\")\n",
    "    return recommendation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Starting PI Recommendation Process for Topic: 'STATISTICS' ---\n",
      "Filtering DataFrame for PI IDs: ['000025017', '000025762', '000030655']...\n",
      "Found 8 relevant entries.\n",
      "Formatting data for prompt...\n",
      "Data formatting complete.\n",
      "Generating prompt...\n",
      "Prompt generated.\n",
      "--- Sending Request to Gemini ---\n",
      "\n",
      "-------Response--------\n",
      "## Analysis of Researcher Qualifications and Experience for 'STATISTICS' Project:\n",
      "\n",
      "Here's an analysis of each researcher based on the provided data, focusing on their suitability as PI for a 'STATISTICS' project:\n",
      "\n",
      "**1. Robert D Palmer (ID: 000025017)**\n",
      "\n",
      "* **Department:** Meteorology\n",
      "* **Relevance to 'STATISTICS':**  Low. His research is centered around weather radar technology (RaXPol), atmospheric research, and meteorological education. The keywords in his award titles and abstracts are \"Radar,\" \"Weather,\" \"Atmospheric,\" \"Mobile,\" and \"Education.\"  There is no explicit mention of statistical methodologies, statistical theory, or statistical applications as the primary focus of his funded projects. The program elements are also within atmospheric science and education.\n",
      "* **Demonstrated Experience:**  Two listed awards, both as **Co-Principal Investigator**. This indicates experience in collaborative research and project execution, but not in a leading role as PI for these specific projects.\n",
      "* **Indicators of Leadership/Seniority:** Co-PI roles suggest collaborative experience but not primary leadership in project direction.  His departmental affiliation is Meteorology, further reinforcing his expertise in atmospheric science rather than statistics.\n",
      "\n",
      "**2. Steven N MacEachern (ID: 000025762)**\n",
      "\n",
      "* **Department:** Statistics Department\n",
      "* **Relevance to 'STATISTICS':** **High**. His research is directly and explicitly related to 'STATISTICS'. Both award titles and abstracts use statistical terminology like \"Bayesian inference,\" \"misspecified models,\" \"low-information settings,\" \"Bayesian methods,\" \"Semiparametric Inference,\" and \"Causal Effects.\" The program element for one award is explicitly listed as \"STATISTICS.\" His research focuses on developing and improving statistical methodologies and applying them to data-driven decision-making and causal inference.\n",
      "* **Demonstrated Experience:** Two listed awards, one as **Principal Investigator** and one as **Co-Principal Investigator**. This demonstrates both leadership experience as a PI and collaborative experience as a Co-PI within the field of statistics.\n",
      "* **Indicators of Leadership/Seniority:**  Holding a PI role in a statistics-focused project and being affiliated with the Statistics Department strongly indicates his seniority and leadership within the field of statistics.\n",
      "\n",
      "**3. Howard B Bluestein (ID: 000030655)**\n",
      "\n",
      "* **Department:** School of Meteorology\n",
      "* **Relevance to 'STATISTICS':**  Moderate to Low. His research is primarily focused on \"Radar Data Collection and Analysis\" of \"Severe Convective Storms and Tornadoes.\" While \"analysis\" implies the use of statistical methods, the core focus is on meteorological phenomena, radar technology, and data collection in atmospheric science.  His research involves using radar to study weather events.  While statistical techniques are likely employed in the \"analysis\" of radar data, the descriptions do not emphasize the development or advancement of statistical methodologies themselves. The program elements are within Physical & Dynamic Meteorology and atmospheric research and education.\n",
      "* **Demonstrated Experience:** Four listed awards, two as **Principal Investigator** and two as **Co-Principal Investigator**. This shows significant research experience and experience in both leading and collaborating on projects. He has more listed awards than the other researchers.\n",
      "* **Indicators of Leadership/Seniority:**  Holding PI roles in multiple meteorology-focused projects indicates leadership experience. However, his departmental affiliation and research focus are primarily in meteorology, not statistics.  His involvement as Co-PI on the same radar projects as Robert Palmer suggests a collaboration within meteorology.\n",
      "\n",
      "## Recommendation for Principal Investigator:\n",
      "\n",
      "**Based on the information provided, Steven N MacEachern is the most suitable Principal Investigator (PI) for a new collaborative project on 'STATISTICS'.**\n",
      "\n",
      "**Justification:**\n",
      "\n",
      "* **Direct Relevance to 'STATISTICS':** Steven N MacEachern's past research is **directly and explicitly relevant** to the topic 'STATISTICS'. His funded projects are centered on developing and applying statistical methodologies, specifically Bayesian methods, which falls squarely within the domain of statistics. His department is also the Statistics Department, reinforcing his core expertise. In contrast, while Robert D Palmer and Howard B Bluestein's work in meteorology likely *uses* statistical methods for data analysis, their research focus, as described in the provided data, is on meteorological phenomena, radar technology, and atmospheric science, not on the field of statistics itself.\n",
      "\n",
      "* **Demonstrated Experience in Statistics as PI:** Steven N MacEachern has demonstrated experience as a **Principal Investigator** on a project explicitly focused on 'STATISTICS' (\"Robust and efficient Bayesian inference...\"). This is a crucial indicator of his capability to lead a statistics-focused project. While Howard B Bluestein also has PI experience, his projects are within meteorology. Robert D Palmer has only Co-PI experience.\n",
      "\n",
      "* **Departmental Affiliation:** Steven N MacEachern is affiliated with the **Statistics Department**, which further solidifies his expertise and focus on statistics. Robert D Palmer and Howard B Bluestein are affiliated with Meteorology departments, indicating their primary expertise lies in atmospheric science.\n",
      "\n",
      "**In summary:** Steven N MacEachern is the only researcher among the three whose documented past work and departmental affiliation demonstrably align with the topic 'STATISTICS'. He also has experience as a PI in a statistics-related project, making him the most qualified and suitable candidate to lead a new collaborative project on 'STATISTICS'.  While Robert D Palmer and Howard B Bluestein are experienced researchers, their expertise and past projects, based on the provided data, are not directly in the field of statistics.\n",
      "-----------------------\n",
      "\n",
      "Response generated in 12.07 seconds.\n",
      "--- PI Recommendation Process Complete (12.07s) ---\n",
      "\n",
      "--- Final Recommendation Text ---\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    # Example model setup (replace with your actual model)\n",
    "    # Note: You need to handle API key configuration securely\n",
    "    try:\n",
    "        # -----------------------------------------------------------------\n",
    "\n",
    "        # --- Input Parameters ---\n",
    "        pi_ids_to_analyze = ['000025017', '000025762', '000030655']\n",
    "        research_topic = 'STATISTICS'\n",
    "\n",
    "        # --- Run the Recommendation Process ---\n",
    "        recommendation_result = recommend_pi(df, model, pi_ids_to_analyze, research_topic)\n",
    "\n",
    "        # Optional: Do something with the result\n",
    "        if recommendation_result:\n",
    "            print(\"\\n--- Final Recommendation Text ---\")\n",
    "            # print(recommendation_result) # Already printed during streaming\n",
    "            pass # Result is already printed by get_gemini_response\n",
    "        else:\n",
    "            print(\"\\nRecommendation could not be generated.\")\n",
    "\n",
    "    except ImportError:\n",
    "        print(\"Please install required libraries: pip install pandas google-generativeai\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred during setup or execution: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['pi_id'].isin(pi_ids_to_analyze)][['pi_full_name', 'pi_id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from datetime import datetime\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Combine relevant text columns into one (you may adjust columns as needed)\n",
    "text_columns = [\n",
    "    \"award_type\", \"award_title\", \"abstract\", \n",
    "    \"org_name\", \"org_name2\", \"perf_inst_name\", \n",
    "    \"program_element\", \"program_reference\"\n",
    "]\n",
    "df[\"combined_text\"] = df[text_columns].astype(str).agg(\" \".join, axis=1)\n",
    "\n",
    "# a. Leadership indicator: 1 if role suggests prior leadership (e.g., contains \"Principal Investigator\")\n",
    "df[\"leadership\"] = df[\"role\"].apply(lambda x: 1 if \"Principal Investigator\" in str(x) else 0)\n",
    "\n",
    "# b. Experience in years: use start_date and a reference date (here we use today)\n",
    "df[\"start_date\"] = pd.to_datetime(df[\"start_date\"], errors='coerce')\n",
    "reference_date = datetime.now()  # or use a fixed project date\n",
    "df[\"experience_years\"] = (reference_date - df[\"start_date\"]).dt.days / 365.25\n",
    "\n",
    "# Load a pre-trained sentence transformer\n",
    "embedder = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "# Compute embedding for each award's combined text\n",
    "df[\"text_embedding\"] = df[\"combined_text\"].apply(lambda x: embedder.encode(x))\n",
    "\n",
    "# We assume each row has a researcher ID (\"pi_id\"). If a researcher has multiple rows, we aggregate.\n",
    "# For aggregated text, we average the embeddings; for numeric features, we use appropriate aggregation.\n",
    "award_counts = df.groupby(\"pi_id\").size().reset_index(name=\"award_count\")\n",
    "df_grouped = df.groupby(\"pi_id\").agg({\n",
    "    \"experience_years\": \"mean\",       # average experience across awards\n",
    "    \"leadership\": \"max\",              # if they have ever been a PI, mark as leadership\n",
    "    \"text_embedding\": lambda embs: np.mean(np.stack(embs), axis=0)\n",
    "}).reset_index()\n",
    "df_grouped = df_grouped.merge(award_counts, on=\"pi_id\", how=\"left\")\n",
    "\n",
    "# For later scoring, normalize the numeric features (experience and award_count)\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "df_grouped[[\"exp_norm\", \"award_norm\"]] = scaler.fit_transform(df_grouped[[\"experience_years\", \"award_count\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rank_candidates(research_topic, candidate_ids, base_weight=0.5, topic_weight=0.5):\n",
    "    # Compute embedding for the research topic\n",
    "    topic_emb = embedder.encode(research_topic)\n",
    "    \n",
    "    candidate_scores = []\n",
    "    for cid in candidate_ids:\n",
    "        candidate = df_grouped[df_grouped[\"pi_id\"] == cid].iloc[0]\n",
    "        \n",
    "        # Topic relevance score: cosine similarity between candidate's aggregated embedding and the topic\n",
    "        candidate_emb = candidate[\"text_embedding\"]\n",
    "        relevance_score = cosine_similarity([candidate_emb], [topic_emb])[0][0]\n",
    "        \n",
    "        # Base score: a simple weighted sum of normalized features plus a bonus for leadership\n",
    "        # Adjust weights as needed. Here, leadership gets a bonus of 1 if present.\n",
    "        base_score = candidate[\"exp_norm\"] + candidate[\"award_norm\"] + (1 if candidate[\"leadership\"] == 1 else 0)\n",
    "        \n",
    "        # Combined score: weighted combination of base score and topic relevance\n",
    "        combined_score = base_weight * base_score + topic_weight * relevance_score\n",
    "        candidate_scores.append(combined_score)\n",
    "    \n",
    "    candidate_scores = np.array(candidate_scores)\n",
    "    best_index = np.argmax(candidate_scores)\n",
    "    pi_candidate = candidate_ids[best_index]\n",
    "    co_pi_candidates = [cid for i, cid in enumerate(candidate_ids) if i != best_index]\n",
    "    \n",
    "    return pi_candidate, co_pi_candidates, candidate_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with various topics dynamically.\n",
    "for test_topic in [\"knowledge graph\", \"AI\", \"Neuroscience\", \"STATISTICS\"]:\n",
    "    print(\"Testing with topic:\", test_topic)\n",
    "    pi_candidate, co_pi_candidates, scores = rank_candidates(test_topic, pi_ids_to_analyze)\n",
    "    print(\"Predicted PI:\", pi_candidate)\n",
    "    print(\"Predicted Co-PIs:\", co_pi_candidates)\n",
    "    print(\"Candidate Combined Scores:\", scores)\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.pi_id.isin(pi_ids_to_analyze)][['pi_id', 'pi_full_name', 'role', 'department', 'leadership', 'experience_years', 'program_element']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agent",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
