{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f400bf32",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/agent/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Combined Scholar KG and PI Ranking System (Class-Based)\n",
    "\n",
    "# --- Imports ---\n",
    "import os\n",
    "import re\n",
    "import io\n",
    "import sys\n",
    "import json\n",
    "import time\n",
    "import warnings\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from dotenv import load_dotenv\n",
    "from langchain_community.graphs import Neo4jGraph\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain.chains import GraphCypherQAChain\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import google.generativeai as genai # For PI ranking and Router LLM calls\n",
    "import textwrap\n",
    "from typing import List, Dict, Tuple, Optional, Any\n",
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "90b6a9c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Configuration & Setup ---\n",
    "load_dotenv(dotenv_path=\".env\")\n",
    "\n",
    "GOOGLE_API_KEY = os.getenv(\"GOOGLE_API_KEY\")\n",
    "NEO4J_URL = os.getenv(\"NEO4J_CONNECTION_URL\")\n",
    "NEO4J_USER = os.getenv(\"NEO4J_USER\")\n",
    "NEO4J_PASSWORD = os.getenv(\"NEO4J_PASSWORD\")\n",
    "NEO4J_SCHOLAR_DB = os.getenv(\"NEO4J_SCHOLAR\")\n",
    "\n",
    "if not GOOGLE_API_KEY:\n",
    "    raise ValueError(\"GOOGLE_API_KEY not found.\")\n",
    "if not all([NEO4J_URL, NEO4J_USER, NEO4J_PASSWORD, NEO4J_SCHOLAR_DB]):\n",
    "     raise ValueError(\"Neo4j details not fully found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "58ffbdb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Constants ---\n",
    "KG_LLM_MODEL = \"gemini-2.5-pro-preview-03-25\" #\"gemini-2.0-flash-exp\"\n",
    "PI_RANKING_LLM_MODEL = \"gemini-2.0-flash-thinking-exp-01-21\" # Equivalent for 'gemini-2.0-flash-thinking-exp'\n",
    "ROUTER_LLM_MODEL = \"gemini-2.0-flash-lite\"     # Equivalent for 'gemini-2.0-flash-lite'\n",
    "\n",
    "# --- Data Loading (Global Scope or within classes as needed) ---\n",
    "scholar_df = None\n",
    "ranking_df = None\n",
    "ranking_df_grouped = None\n",
    "embedder = SentenceTransformer(\"all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "356c9916",
   "metadata": {},
   "outputs": [],
   "source": [
    "def duplicate_row_check(df):\n",
    "    duplicate_list = []\n",
    "    previous_row = 0\n",
    "    D_count = 0\n",
    "    for index, row in df.iterrows():\n",
    "        if index > 0:\n",
    "            is_match = (previous_row == row).all()\n",
    "            if is_match:\n",
    "                duplicate_list.append(index)\n",
    "            D_count = D_count + is_match\n",
    "        previous_row = row.copy()\n",
    "    return D_count, duplicate_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1c4c0a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorize_venue(venue):\n",
    "    if 'conference' in venue.lower() or 'symposium' in venue.lower() or 'workshop' in venue.lower():\n",
    "        return 'Conference'\n",
    "    elif 'journal' in venue.lower() or 'transactions' in venue.lower() or 'letters' in venue.lower():\n",
    "        return 'Journal'\n",
    "    else:\n",
    "        return 'Other'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d9937fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def safe_get(data, keys, default=None):\n",
    "    \"\"\"\n",
    "    Safely get a nested key from a dictionary using a list of keys.\n",
    "    Returns default if any key is missing.\n",
    "    \"\"\"\n",
    "    for key in keys:\n",
    "        if isinstance(data, dict) and key in data:\n",
    "            data = data[key]\n",
    "        else:\n",
    "            return default\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9cb74b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_all_data(scholar_csv_path=\"data/scholer_recommendation.csv\", ranking_data_dir=\"data/ranking_data/\"):\n",
    "    \"\"\"Loads and preprocesses both datasets.\"\"\"\n",
    "    global scholar_data, ranking_data, ranking_data_grouped, embedder\n",
    "\n",
    "    print(\"Loading Scholar Data...\")\n",
    "    try:\n",
    "        # --- Add Scholar Data Loading & Preprocessing from Scholar-KG-RAG.ipynb ---\n",
    "        scholar_data = pd.read_csv(scholar_csv_path)\n",
    "        scholar_data = scholar_data.drop(columns=[\"Abstract\", \"Keywords\"], axis=1, errors='ignore')\n",
    "        scholar_data = pd.concat([scholar_data.head(80), scholar_data.tail(20)], ignore_index=True)\n",
    "        scholar_data.rename(columns={'Fields of Study': 'Discipline', 'Category': 'Topic'}, inplace=True)\n",
    "        print(\"Scholar data loaded.\")\n",
    "        print(f\"Data processing started. {len(scholar_data)} rows found.\")\n",
    "        duplicate_count, duplicate_list = duplicate_row_check(scholar_data)\n",
    "        \n",
    "        scholar_data['Authors_list'] = scholar_data['Authors'].str.split(',')\n",
    "        scholar_data = scholar_data.explode('Authors_list').reset_index(drop=True)\n",
    "        scholar_data[\"Authors\"] = scholar_data[\"Authors_list\"]\n",
    "        scholar_data.drop([\"Authors_list\"], axis=1, inplace=True)\n",
    "\n",
    "        scholar_data['Discipline_list'] = scholar_data['Discipline'].str.split(',')\n",
    "        scholar_data = scholar_data.explode('Discipline_list').reset_index(drop=True)\n",
    "        scholar_data[\"Discipline\"] = scholar_data[\"Discipline_list\"]\n",
    "        scholar_data.drop([\"Discipline_list\"], axis=1, inplace=True)\n",
    "        duplicate_count, duplicate_list = duplicate_row_check(scholar_data)\n",
    "        \n",
    "        scholar_data.drop(duplicate_list, inplace=True)\n",
    "        scholar_data.reset_index(drop=True, inplace=True)\n",
    "        duplicate_count, duplicate_list = duplicate_row_check(scholar_data)\n",
    "        \n",
    "        scholar_data.dropna(inplace=True)\n",
    "        duplicate_count, duplicate_list = duplicate_row_check(scholar_data)\n",
    "        \n",
    "        scholar_data.rename(columns={'Title': 'Paper Title', 'Authors': 'Author', 'Year': 'Year Published'}, inplace=True)\n",
    "        \n",
    "        scholar_data['Venue Type'] = scholar_data['Venue'].apply(categorize_venue)\n",
    "        scholar_data = scholar_data.applymap(lambda x: x.strip() if isinstance(x, str) else x)\n",
    "        duplicate_count, duplicate_list = duplicate_row_check(scholar_data)\n",
    "        \n",
    "        scholar_data.drop(duplicate_list, inplace=True)\n",
    "        scholar_data.reset_index(drop=True, inplace=True)\n",
    "        duplicate_count, duplicate_list = duplicate_row_check(scholar_data)\n",
    "\n",
    "        print(f\"Data processing complete. {len(scholar_data)} rows loaded.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading scholar data: {e}\")\n",
    "        scholar_data = None\n",
    "\n",
    "    print(\"Loading Ranking Data...\")\n",
    "    print(f\"Paused for a while to avoid rate limits...\")\n",
    "    records = []\n",
    "    if not os.path.exists(ranking_data_dir):\n",
    "        print(f\"Error: Ranking data directory not found at {ranking_data_dir}\")\n",
    "    else:\n",
    "        for sub_dir in os.listdir(ranking_data_dir):\n",
    "            print(f\"Reading files in {sub_dir}...\")\n",
    "            sub_directory = os.path.join(ranking_data_dir, sub_dir)\n",
    "            for filename in os.listdir(sub_directory):\n",
    "                if filename.endswith('.json'):\n",
    "                    filepath = os.path.join(sub_directory, filename)\n",
    "                    try:\n",
    "                        with open(filepath, 'r') as file:\n",
    "                            data = json.load(file)\n",
    "                    except Exception as e:\n",
    "                        print(f\"Error reading {filepath}: {e}\")\n",
    "                        continue\n",
    "\n",
    "                    # Extract award-level context information safely\n",
    "                    award_type = data.get(\"awd_istr_txt\")\n",
    "                    award_title = data.get(\"awd_titl_txt\")\n",
    "                    abstract = data.get(\"abst_narr_txt\")\n",
    "                    org_name = data.get(\"org_long_name\")\n",
    "                    org_name2 = data.get(\"org_long_name2\")\n",
    "                    perf_inst_name = safe_get(data, [\"perf_inst\", \"perf_inst_name\"])\n",
    "                    \n",
    "                    # Extract program element and reference safely (checking if list exists)\n",
    "                    pgm_ele_list = data.get(\"pgm_ele\")\n",
    "                    if isinstance(pgm_ele_list, list) and len(pgm_ele_list) > 0:\n",
    "                        program_element = pgm_ele_list[0].get(\"pgm_ele_long_name\")\n",
    "                    else:\n",
    "                        program_element = None\n",
    "\n",
    "                    pgm_ref_list = data.get(\"pgm_ref\")\n",
    "                    if isinstance(pgm_ref_list, list) and len(pgm_ref_list) > 0:\n",
    "                        program_reference = pgm_ref_list[0].get(\"pgm_ref_long_name\")\n",
    "                    else:\n",
    "                        program_reference = None\n",
    "\n",
    "                    # Get investigator information, ensuring it's a list\n",
    "                    pi_list = data.get(\"pi\")\n",
    "                    if not isinstance(pi_list, list):\n",
    "                        continue\n",
    "\n",
    "                    # Loop through each investigator in the file\n",
    "                    for pi in pi_list:\n",
    "                        record = {\n",
    "                            \"award_type\": award_type,\n",
    "                            \"award_title\": award_title,\n",
    "                            \"abstract\": abstract,\n",
    "                            \"org_name\": org_name,\n",
    "                            \"org_name2\": org_name2,\n",
    "                            \"perf_inst_name\": perf_inst_name,\n",
    "                            \"program_element\": program_element,\n",
    "                            \"program_reference\": program_reference,\n",
    "                            \"pi_id\": pi.get(\"pi_id\"),\n",
    "                            \"pi_full_name\": pi.get(\"pi_full_name\", \"\").strip() if pi.get(\"pi_full_name\") else None,\n",
    "                            \"role\": pi.get(\"proj_role_code2\", \"\").strip() if pi.get(\"proj_role_code2\") else None,\n",
    "                            \"department\": pi.get(\"pi_dept_name\"),\n",
    "                            \"email\": pi.get(\"pi_email_addr\"),\n",
    "                            \"start_date\": pi.get(\"start_date\")\n",
    "                        }\n",
    "                        records.append(record)\n",
    "\n",
    "        # Create a DataFrame from the records\n",
    "        ranking_data = pd.DataFrame(records)\n",
    "        ranking_data = ranking_data[ranking_data['role'].isin(['Co-Principal Investigator', 'Principal Investigator'])]\n",
    "        print(f\"Ranking data loaded and processed. {len(ranking_data)} rows found.\")\n",
    "        \n",
    "    print(f\"Preparing ranking data group for analysis...\")\n",
    "    # Combine relevant text columns into one (you may adjust columns as needed)\n",
    "    text_columns = [\n",
    "        \"award_type\", \"award_title\", \"abstract\", \n",
    "        \"org_name\", \"org_name2\", \"perf_inst_name\", \n",
    "        \"program_element\", \"program_reference\"\n",
    "    ]\n",
    "    ranking_data[\"combined_text\"] = ranking_data[text_columns].astype(str).agg(\" \".join, axis=1)\n",
    "\n",
    "    # a. Leadership indicator: 1 if role suggests prior leadership (e.g., contains \"Principal Investigator\")\n",
    "    ranking_data[\"leadership\"] = ranking_data[\"role\"].apply(lambda x: 1 if \"Principal Investigator\" in str(x) else 0)\n",
    "\n",
    "    # b. Experience in years: use start_date and a reference date (here we use today)\n",
    "    ranking_data[\"start_date\"] = pd.to_datetime(ranking_data[\"start_date\"], errors='coerce')\n",
    "    reference_date = datetime.now()  # or use a fixed project date\n",
    "    ranking_data[\"experience_years\"] = (reference_date - ranking_data[\"start_date\"]).dt.days / 365.25\n",
    "\n",
    "    # Load a pre-trained sentence transformer\n",
    "    embedder = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "    # Compute embedding for each award's combined text\n",
    "    ranking_data[\"text_embedding\"] = ranking_data[\"combined_text\"].apply(lambda x: embedder.encode(x))\n",
    "\n",
    "    # We assume each row has a researcher ID (\"pi_id\"). If a researcher has multiple rows, we aggregate.\n",
    "    # For aggregated text, we average the embeddings; for numeric features, we use appropriate aggregation.\n",
    "    award_counts = ranking_data.groupby(\"pi_id\").size().reset_index(name=\"award_count\")\n",
    "    ranking_data_grouped = ranking_data.groupby(\"pi_id\").agg({\n",
    "        \"experience_years\": \"mean\",       # average experience across awards\n",
    "        \"leadership\": \"max\",              # if they have ever been a PI, mark as leadership\n",
    "        \"text_embedding\": lambda embs: np.mean(np.stack(embs), axis=0)\n",
    "    }).reset_index()\n",
    "    ranking_data_grouped = ranking_data_grouped.merge(award_counts, on=\"pi_id\", how=\"left\")\n",
    "\n",
    "    # For later scoring, normalize the numeric features (experience and award_count)\n",
    "    from sklearn.preprocessing import MinMaxScaler\n",
    "    scaler = MinMaxScaler()\n",
    "\n",
    "    ranking_data_grouped[[\"exp_norm\", \"award_norm\"]] = scaler.fit_transform(ranking_data_grouped[[\"experience_years\", \"award_count\"]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2bc8cab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load_all_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "70768b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "example = [\n",
    "    {\n",
    "        \"question\": \"List all papers authored by 'Han Xiao'.\",\n",
    "        \"query\": \"MATCH (a:Author {name: 'Han Xiao'})-[:AUTHORED]->(p:Paper) RETURN p.title AS PapersAuthoredByHanXiao\",\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"Which papers belong to the 'Computer Science' discipline?\",\n",
    "        \"query\": \"MATCH (p:Paper)-[:BELONGS_TO]->(d:Discipline {name: 'Computer Science'}) RETURN p.title AS PapersInComputerScience Limit 5\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"What are the papers published in 'Nature' in the year 2018?\",\n",
    "        \"query\": \"MATCH (p:Paper)-[:PUBLISHED_IN]->(v:Venue {name: 'Nature'}) WHERE p.year = 2018 RETURN p.title AS PapersPublishedInNature2018\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"How many papers did 'Jianmin Chen' author?\",\n",
    "        'query': \"MATCH (a:Author {name: 'Jianmin Chen'})-[:AUTHORED]->(p:Paper) RETURN COUNT(p) AS NumberOfPapersAuthoredByJianminChen\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"List all authors who have published papers in the topic 'Machine Learning'.\",\n",
    "        \"query\": \"MATCH (a:Author)-[:AUTHORED]->(p:Paper {topic: 'Machine Learning'}) RETURN DISTINCT a.name AS AuthorsInMachineLearning Limit 5\"\n",
    "    },\n",
    "    {\n",
    "        'question': \"What are the most cited papers in 'Mathematics'?\",\n",
    "        'query': \"MATCH (p:Paper)-[:BELONGS_TO]->(d:Discipline {name: 'Mathematics'}) RETURN p.title AS PapersInComputerScience Limit 5\"\n",
    "    },\n",
    "    {\n",
    "        'question': \"What are the most cited papers in 'Materials Science' discipline?\",\n",
    "        'query': \"MATCH (p:Paper)-[:BELONGS_TO]->(d:Discipline {name: 'Materials Science'}) RETURN p.title AS Paper, p.citations AS Citations ORDER BY Citations DESC LIMIT 5\"\n",
    "    },\n",
    "    {\n",
    "        'question': \"Which venues have published papers in the 'Network Science' topic?\",\n",
    "        'query': \"MATCH (p:Paper {topic: 'Network Science'})-[:PUBLISHED_IN]->(v:Venue) RETURN DISTINCT v.name AS VenuesForNetworkScience LIMIT 5\"\n",
    "    },\n",
    "    {\n",
    "        'question': \"I am 'Han Xiao' conducts research in 'Computer Science' and 'Machine Learning'. Which professors should he collaborate with?\",\n",
    "        'query': \"MATCH (a:Author {name: 'Han Xiao'})-[:AUTHORED]->(p:Paper)-[:BELONGS_TO]->(d:Discipline) WHERE d.name = 'Computer Science' OR p.topic = 'Machine Learning' WITH DISTINCT d AS Discipline, p.topic AS Topic MATCH (other:Author)-[:AUTHORED]->(:Paper)-[:BELONGS_TO]->(d) WHERE other.name <> 'Han Xiao' RETURN DISTINCT other.name AS PotentialCollaborators LIMIT 5\"\n",
    "    },\n",
    "    {\n",
    "        'question': \"I am 'Han Xiao'. Which researchers I collaborated with before?\",\n",
    "        'query': \"MATCH (a1:Author {name: 'Han Xiao'})-[:AUTHORED]->(p:Paper)<-[:AUTHORED]-(a2:Author) WHERE a1 <> a2 RETURN DISTINCT a2.name\"\n",
    "    },\n",
    "    {\n",
    "        'question': \"I am 'Han Xiao'. Which new researchers should I collaborate with for future work?\",\n",
    "        'query': \"MATCH (a1:Author {name: 'Han Xiao'})-[:AUTHORED]->(p:Paper)-[:BELONGS_TO]->(d:Discipline)<-[:BELONGS_TO]-(p2:Paper)<-[:AUTHORED]-(a2:Author) WHERE a1 <> a2 RETURN a2.name, COUNT(p2) AS collaborations ORDER BY collaborations DESC\"\n",
    "    },\n",
    "    {\n",
    "        'question': \"I am 'Kashif Rasul'. I have some workes in 'Mathematics' and want to expand my research in this field. Which researchers should I collaborate with based on papers related to 'Mathematics'?\",\n",
    "        'query': \"MATCH (a:Author {name: 'Kashif Rasul'})-[:AUTHORED]->(p:Paper)-[:BELONGS_TO]->(d:Discipline) WHERE d.name = 'Mathematics' WITH DISTINCT d AS Discipline MATCH (other:Author)-[:AUTHORED]->(:Paper)-[:BELONGS_TO]->(d) WHERE other.name <> 'Kashif Rasul' RETURN DISTINCT other.name AS PotentialCollaborators\"\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "37a1097e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScholarKGQA:\n",
    "    def __init__(\n",
    "        self,\n",
    "        google_api_key: Optional[str] = None,\n",
    "        neo4j_url: Optional[str] = None,\n",
    "        neo4j_user: Optional[str] = None,\n",
    "        neo4j_password: Optional[str] = None,\n",
    "        neo4j_db: Optional[str] = None,\n",
    "        llm_model_tag: str = \"gemini-2.5-pro-preview-03-25\",\n",
    "        llm_temperature: float = 0.0,\n",
    "        example: List[Dict[str, str]] = example,\n",
    "        verbose: bool = True,\n",
    "        allow_dangerous_requests: bool = True\n",
    "    ):\n",
    "        # This internal logic correctly uses os.getenv, fitting with the external loading pattern\n",
    "        self.google_api_key = google_api_key or os.getenv(\"GOOGLE_API_KEY\")\n",
    "        self.neo4j_url = neo4j_url or os.getenv(\"NEO4J_CONNECTION_URL\")\n",
    "        self.neo4j_user = neo4j_user or os.getenv(\"NEO4J_USER\")\n",
    "        self.neo4j_password = neo4j_password or os.getenv(\"NEO4J_PASSWORD\")\n",
    "        self.neo4j_db = neo4j_db or os.getenv(\"NEO4J_SCHOLAR\") # Ensure env var name matches\n",
    "        self.llm_model_tag = llm_model_tag\n",
    "        self.verbose = verbose\n",
    "        self.example = example\n",
    "        self.ALLOW_DANGEROUS_REQUEST = allow_dangerous_requests\n",
    "        self.llm_temperature = llm_temperature\n",
    "        self.graph = Neo4jGraph(self.neo4j_url,self. neo4j_user, self.neo4j_password, database=self.neo4j_db)\n",
    "        \n",
    "        if not all([self.google_api_key, self.neo4j_url, self.neo4j_user, self.neo4j_password, self.neo4j_db]):\n",
    "            raise ValueError(\"Missing required configuration (API Key or Neo4j credentials/URL/DB). \"\n",
    "                             \"Ensure environment variables are set or pass arguments directly.\")\n",
    "            \n",
    "        self.llm = ChatGoogleGenerativeAI(model=llm_model_tag, google_api_key=self.google_api_key, temperature=self.llm_temperature)\n",
    "        \n",
    "        self.cypher_generation_prompt = PromptTemplate(\n",
    "            template=\"\"\"Based on the schema, write a Cypher query to answer the question.\n",
    "\n",
    "            The question may ask about:\n",
    "            - Authors and their research fields\n",
    "            - Publication venues and trends\n",
    "            - Paper citations and collaborations\n",
    "            - Discipline for authors and papers\n",
    "            - Recommendations for collaborations or venues\n",
    "\n",
    "            Schema:\n",
    "            {schema}\n",
    "\n",
    "            Example questions and queries:\n",
    "            {example}\n",
    "\n",
    "            **Important**:\n",
    "            - Always filter by specific properties in the question when provided, such as `category` for papers or `name` for authors.\n",
    "            - Ensure the query aligns precisely with the requested category, author, or venue.\n",
    "            - When counting or aggregating, provide meaningful aliases like `VenueName`, `PaperCount`, or `AuthorName`.\n",
    "            - Do not include irrelevant nodes or relationships in the query.\n",
    "\n",
    "            Question: {question}\n",
    "            Query:\"\"\",\n",
    "            input_variables=[\"schema\", \"question\", \"example\"],\n",
    "        )\n",
    "        \n",
    "        self.qa_prompt = PromptTemplate(\n",
    "            template=\"\"\"Based on the Cypher query results, answer the question.\n",
    "            Question: {question}\n",
    "            Results: {context}\n",
    "            Give a clear, direct, and human-friendly answer using the data from the results. \n",
    "            If it's a list, combine all items and summarize. For example, for authors or papers, list them in a human-readable format.\n",
    "            Answer:\"\"\",\n",
    "            input_variables=[\"question\", \"context\"],\n",
    "        )\n",
    "        \n",
    "        self.chain = GraphCypherQAChain.from_llm(\n",
    "            llm=self.llm,\n",
    "            graph=self.graph,  # Your Neo4j graph object\n",
    "            verbose=True,\n",
    "            cypher_generation_prompt=self.cypher_generation_prompt,\n",
    "            qa_prompt=self.qa_prompt,\n",
    "            allow_dangerous_requests=self.ALLOW_DANGEROUS_REQUEST,\n",
    "        )\n",
    "        \n",
    "    def clean_ansi(self, text):\n",
    "        # Remove ANSI escape codes\n",
    "        ansi_escape = re.compile(r'\\x1B(?:[@-Z\\\\-_]|\\[[0-?]*[ -/]*[@-~])')\n",
    "        return ansi_escape.sub('', text).strip()\n",
    "\n",
    "    def query(self, question):\n",
    "        try:\n",
    "            # Create a string buffer to capture the output\n",
    "            output_buffer = io.StringIO()\n",
    "            original_stdout = sys.stdout\n",
    "            # sys.stdout = output_buffer\n",
    "\n",
    "            # Explicitly generate the Cypher query first using the prompt\n",
    "            generated_query = self.cypher_generation_prompt.format(\n",
    "                schema=self.graph.schema,  # Ensure dynamic schema usage\n",
    "                question=question,\n",
    "                example=self.example\n",
    "            )\n",
    "\n",
    "            # Run the chain with the generated query\n",
    "            # result = self.chain.run(query=generated_query, question=question)\n",
    "            input_data = {\n",
    "                \"query\": generated_query,\n",
    "                \"question\": question\n",
    "            }\n",
    "            result = self.chain.invoke(input_data)\n",
    "            # result = self.chain.invoke({\n",
    "            #     \"query\": question,\n",
    "            #     \"example\": self.example_queries # Pass examples here\n",
    "            #     })\n",
    "            \n",
    "            # Restore original stdout and get the captured output\n",
    "            sys.stdout = original_stdout\n",
    "            output = output_buffer.getvalue()\n",
    "            \n",
    "            # Extract Cypher query and context from the captured output\n",
    "            cypher_query = None\n",
    "            full_context = None\n",
    "            \n",
    "            if 'Generated Cypher:' in output:\n",
    "                cypher_query = output.split('Generated Cypher:')[1].split('Full Context:')[0].strip()\n",
    "                cypher_query = self.clean_ansi(cypher_query)\n",
    "            \n",
    "            if 'Full Context:' in output:\n",
    "                full_context = output.split('Full Context:')[1].split('>')[0].strip()\n",
    "                full_context = self.clean_ansi(full_context)\n",
    "            \n",
    "            # print(f\"Q: {question}\")\n",
    "            # print(f\"A: {result}\\n\")\n",
    "            \n",
    "            return {\n",
    "                'result': result,\n",
    "                'cypher_query': cypher_query,\n",
    "                'full_context': full_context\n",
    "            }\n",
    "        except Exception as e:\n",
    "            print(f\"Error: {str(e)}\")\n",
    "            return {\n",
    "                'result': None,\n",
    "                'cypher_query': None,\n",
    "                'full_context': None,\n",
    "                'error': str(e)\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "158607f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Class for PI Ranking and Analysis ---\n",
    "class PIRankingAnalysis:\n",
    "    def __init__(self, ranking_data: pd.DataFrame, grouped_data: pd.DataFrame, llm_model_name: str):\n",
    "        print(f\"Initializing PIRankingAnalysis with model: {llm_model_name}\")\n",
    "        self.df = ranking_data\n",
    "        self.df_grouped = grouped_data\n",
    "        self.embedder = embedder # Use global embedder\n",
    "        try:\n",
    "            # Use specific Gemini model via genai SDK\n",
    "            self.model = genai.GenerativeModel(llm_model_name)\n",
    "            print(f\"PI Ranking LLM ({llm_model_name}) initialized.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error initializing PI Ranking LLM: {e}\")\n",
    "            self.model = None\n",
    "            \n",
    "    def _get_llm_response(self, prompt: str) -> Optional[str]:\n",
    "        \"\"\"Internal helper to call the PI Ranking LLM.\"\"\"\n",
    "        if not self.model: return \"Error: PI Ranking LLM not initialized.\"\n",
    "        start_time = time.time()\n",
    "        try:\n",
    "            response = self.model.generate_content(prompt)\n",
    "            duration = time.time() - start_time\n",
    "            print(f\"PI Ranking LLM response generated in {duration:.2f} seconds.\")\n",
    "            # Adapt response extraction based on genai SDK version/behavior\n",
    "            if hasattr(response, 'text'): return response.text\n",
    "            if hasattr(response, 'candidates') and response.candidates: return response.candidates[0].content.parts[0].text\n",
    "            return None\n",
    "        except Exception as e:\n",
    "            duration = time.time() - start_time\n",
    "            print(f\"Error during PI Ranking LLM call ({duration:.2f}s): {e}\")\n",
    "            return None\n",
    "        \n",
    "    # --- PI Recommendation Methods (adapted from functions) ---\n",
    "    def _format_pi_data_for_prompt(self, filtered_df: pd.DataFrame, pi_ids_to_format: List[str]) -> Tuple[str, Dict[str, str]]:\n",
    "        # Identical to format_pi_data_for_prompt function above\n",
    "        formatted_data = \"\"\n",
    "        pi_names = {}\n",
    "        # ... (copy logic from the function version) ...\n",
    "        if filtered_df.empty:\n",
    "             formatted_data = \"No data could be retrieved for the specified potential collaborators.\\n\"\n",
    "             for pi_id in pi_ids_to_format: pi_names[pi_id] = f\"PI ID {pi_id}\"\n",
    "             return formatted_data, pi_names\n",
    "        for pi_id in pi_ids_to_format:\n",
    "             pi_specific_data = filtered_df[filtered_df['pi_id'] == pi_id]\n",
    "             if not pi_specific_data.empty:\n",
    "                 full_name = pi_specific_data['pi_full_name'].iloc[0]\n",
    "                 department = pi_specific_data['department'].iloc[0]\n",
    "                 pi_names[pi_id] = full_name\n",
    "                 formatted_data += f\"--- Researcher: {full_name} (ID: {pi_id}) ---\\n\"\n",
    "                 formatted_data += f\"Department: {department}\\n\"\n",
    "                 formatted_data += \"Relevant Roles & Awards Found:\\n\"\n",
    "                 for _, row in pi_specific_data.iterrows():\n",
    "                      formatted_data += f\"- Role: {row.get('role', 'N/A')}\\n\"\n",
    "                      formatted_data += f\"  Award Title: {row.get('award_title', 'N/A')}\\n\"\n",
    "                      formatted_data += f\"  Start Date: {row.get('start_date', 'N/A')}\\n\"\n",
    "                      abstract_preview = textwrap.shorten(str(row.get('abstract', 'N/A')), width=150, placeholder=\"...\")\n",
    "                      formatted_data += f\"  Abstract Snippet: {abstract_preview}\\n\"\n",
    "                      formatted_data += f\"  Program Element/Reference: {row.get('program_element', 'N/A')} / {row.get('program_reference', 'N/A')}\\n\\n\"\n",
    "             else:\n",
    "                 formatted_data += f\"--- Researcher ID: {pi_id} ---\\nNo award data found.\\n\\n\"\n",
    "                 pi_names[pi_id] = f\"PI ID {pi_id}\"\n",
    "        return formatted_data, pi_names\n",
    "\n",
    "    def _generate_recommendation_prompt(self, formatted_data_string: str, pi_names_dict: Dict[str, str], research_topic: str) -> str:\n",
    "         # Identical to generate_recommendation_prompt function above\n",
    "         collaborator_names_list = \", \".join(pi_names_dict.values())\n",
    "         # ... (copy logic from the function version) ...\n",
    "         prompt = f\"\"\"Context:\n",
    "            The following researchers ({collaborator_names_list}) are candidates for a new research project focused on '{research_topic}'. Below is information about their past grants and roles:\n",
    "\n",
    "            {formatted_data_string}\n",
    "\n",
    "            Task:\n",
    "            Based ONLY on the information provided above, analyze the qualifications and past work relevance for each researcher ({collaborator_names_list}).\n",
    "            Recommend which ONE of these individuals would be the MOST suitable Principal Investigator (PI) to lead this project on '{research_topic}'.\n",
    "\n",
    "            Provide a detailed explanation for your recommendation. Consider:\n",
    "            - Direct relevance of past research (titles, abstracts, programs) to '{research_topic}'.\n",
    "            - Demonstrated experience (e.g., number of awards, roles held like 'Principal Investigator').\n",
    "\n",
    "            Clearly state the recommended PI by name and justify your choice using specific evidence from the provided context. If the data is insufficient, state that clearly.\n",
    "            \"\"\"\n",
    "         return prompt\n",
    "\n",
    "    def recommend_pi(self, pi_ids: List[str], research_topic: str) -> str:\n",
    "        if self.df is None: return \"Error: Ranking data not loaded.\"\n",
    "        pi_ids_str = [str(pid) for pid in pi_ids]\n",
    "        filtered_data = self.df[self.df['pi_id'].isin(pi_ids_str)].copy()\n",
    "        if filtered_data.empty: return f\"No ranking data found for PI IDs: {pi_ids_str}\"\n",
    "\n",
    "        formatted_text, pi_names = self._format_pi_data_for_prompt(filtered_data, pi_ids_str)\n",
    "        prompt_text = self._generate_recommendation_prompt(formatted_text, pi_names, research_topic)\n",
    "        recommendation = self._get_llm_response(prompt_text)\n",
    "        return recommendation if recommendation else \"Could not generate PI recommendation.\"\n",
    "\n",
    "    # --- Influencer Methods ---\n",
    "    def _get_collaborators_for_awards(self, award_titles: List[str]) -> Dict[str, List[str]]:\n",
    "         # Helper from PI_ranking.ipynb\n",
    "         # ... (copy logic from function version) ...\n",
    "         collaborators = {}\n",
    "         relevant_awards_df = self.df[self.df['award_title'].isin(award_titles)]\n",
    "         for title in award_titles:\n",
    "              award_pis = relevant_awards_df[\n",
    "                   (relevant_awards_df['award_title'] == title) &\n",
    "                   (relevant_awards_df['role'].isin(['Principal Investigator', 'Co-Principal Investigator']))\n",
    "              ]\n",
    "              names = [name for name in award_pis['pi_full_name'].unique() if pd.notna(name)]\n",
    "              collaborators[title] = names\n",
    "         return collaborators\n",
    "\n",
    "    def _format_influencer_data(self, pi_ids: List[str]) -> Tuple[str, Dict[str, str]]:\n",
    "         # Simplified version - copy from function above\n",
    "         formatted_data = \"\"\n",
    "         pi_names = {}\n",
    "         # ... (copy logic from function version) ...\n",
    "         filtered_df = self.df[self.df['pi_id'].isin(pi_ids)].copy()\n",
    "         if filtered_df.empty: return \"No data found for specified PI IDs.\", {}\n",
    "         for pi_id in pi_ids:\n",
    "             pi_specific_data = filtered_df[filtered_df['pi_id'] == pi_id]\n",
    "             if not pi_specific_data.empty:\n",
    "                  full_name = pi_specific_data['pi_full_name'].iloc[0]\n",
    "                  pi_names[pi_id] = full_name\n",
    "                  formatted_data += f\"--- Potential Influencer: {full_name} (ID: {pi_id}) ---\\n\"\n",
    "                  unique_award_titles = pi_specific_data['award_title'].unique()\n",
    "                  num_projects = len(unique_award_titles)\n",
    "                  formatted_data += f\"Total Projects Involved In: {num_projects}\\n\"\n",
    "                  collaborators_by_award = self._get_collaborators_for_awards(list(unique_award_titles))\n",
    "                  all_collaborators = set(name for names in collaborators_by_award.values() for name in names if name != full_name)\n",
    "                  num_unique_collaborators = len(all_collaborators)\n",
    "                  formatted_data += f\"Total Unique Collaborators: {num_unique_collaborators}\\n\"\n",
    "                  unique_elements = pi_specific_data['program_element'].dropna().unique()\n",
    "                  unique_references = pi_specific_data['program_reference'].dropna().unique()\n",
    "                  all_fields = set(unique_elements) | set(unique_references)\n",
    "                  num_unique_fields = len(all_fields)\n",
    "                  formatted_data += f\"Number of Unique Research Fields: {num_unique_fields}\\n\\n\"\n",
    "             else:\n",
    "                  formatted_data += f\"--- Potential Influencer ID: {pi_id} ---\\nNo data found.\\n\\n\"\n",
    "                  pi_names[pi_id] = f\"PI ID {pi_id}\"\n",
    "         return formatted_data, pi_names\n",
    "\n",
    "\n",
    "    def _generate_influencer_prompt(self, formatted_data_string: str, pi_names_dict: Dict[str, str]) -> str:\n",
    "         # Copy from function version above\n",
    "         candidate_names_list = \", \".join(pi_names_dict.values())\n",
    "         # ... (copy logic from function version) ...\n",
    "         prompt = f\"\"\"Context:\n",
    "            You are analyzing research data to identify 'influencers' based on:\n",
    "            1. Number of distinct projects/awards.\n",
    "            2. Number of unique collaborators.\n",
    "            3. Diversity of research fields (Program Elements/References).\n",
    "\n",
    "            Below is summarized data for potential influencers ({candidate_names_list}):\n",
    "\n",
    "            {formatted_data_string}\n",
    "\n",
    "            Task:\n",
    "            Based ONLY on the summarized information, rank these individuals ({candidate_names_list}) from most influential to least influential according to the criteria above.\n",
    "            Provide a clear ranking and a concise justification for each, referencing the specific metrics (project count, collaborator count, field count).\n",
    "            \"\"\"\n",
    "         return prompt\n",
    "\n",
    "\n",
    "    def rank_influencers_by_list(self, pi_ids: List[str]) -> str:\n",
    "        if self.df is None: return \"Error: Ranking data not loaded.\"\n",
    "        pi_ids_str = [str(pid) for pid in pi_ids]\n",
    "        formatted_text, pi_names = self._format_influencer_data(pi_ids_str)\n",
    "        if not pi_names: return \"Could not format data for influencer ranking.\"\n",
    "        prompt_text = self._generate_influencer_prompt(formatted_text, pi_names)\n",
    "        ranking_result = self._get_llm_response(prompt_text)\n",
    "        return ranking_result if ranking_result else \"Could not generate influencer ranking.\"\n",
    "\n",
    "    # --- Influencer by Criterion Methods ---\n",
    "    def _select_candidate_pis(self, criterion_type: str, criterion_value: str, top_k: int = 10) -> List[str]:\n",
    "         # Copy logic from select_candidate_pis_v2 function above\n",
    "         if self.df is None or self.df_grouped is None: return []\n",
    "         # ... (copy logic, using self.df and self.df_grouped) ...\n",
    "         print(f\"Selecting top {top_k} candidates based on {criterion_type}: '{criterion_value}'...\")\n",
    "         candidate_ids = []\n",
    "         if criterion_type == \"topic\":\n",
    "             if 'text_embedding' not in self.df_grouped.columns: return []\n",
    "             topic_emb = self.embedder.encode(criterion_value)\n",
    "             valid_embeddings = self.df_grouped['text_embedding'][self.df_grouped['text_embedding'].apply(lambda x: isinstance(x, np.ndarray))]\n",
    "             if valid_embeddings.empty: return []\n",
    "             all_embeddings = np.stack(valid_embeddings.values)\n",
    "             similarities = cosine_similarity([topic_emb], all_embeddings)[0]\n",
    "             top_indices = np.argsort(similarities)[::-1][:top_k]\n",
    "             candidate_ids = self.df_grouped.iloc[valid_embeddings.index[top_indices]]['pi_id'].tolist()\n",
    "         elif criterion_type == \"department\":\n",
    "             if 'department' not in self.df.columns: return []\n",
    "             dept_match_df = self.df[self.df['department'].str.contains(criterion_value, case=False, na=False)]\n",
    "             if dept_match_df.empty: return []\n",
    "             unique_dept_pi_ids = dept_match_df['pi_id'].unique()\n",
    "             if len(unique_dept_pi_ids) > top_k:\n",
    "                 candidate_subset = self.df_grouped[self.df_grouped['pi_id'].isin(unique_dept_pi_ids)]\n",
    "                 if 'award_count' in candidate_subset.columns:\n",
    "                      ranked_candidates = candidate_subset.sort_values(by='award_count', ascending=False)\n",
    "                      candidate_ids = ranked_candidates.head(top_k)['pi_id'].tolist()\n",
    "                 else: candidate_ids = list(unique_dept_pi_ids)[:top_k]\n",
    "                 print(f\"  (Found {len(unique_dept_pi_ids)} PIs, selecting top {top_k} based on award count)\")\n",
    "             else: candidate_ids = list(unique_dept_pi_ids)\n",
    "         else: return []\n",
    "         print(f\"Selected candidate PI IDs: {candidate_ids}\")\n",
    "         return candidate_ids\n",
    "\n",
    "\n",
    "    def find_influencer_by_criterion(self, criterion_type: str, criterion_value: str, top_k: int = 5) -> str:\n",
    "        candidate_pi_ids = self._select_candidate_pis(criterion_type, criterion_value, top_k=top_k)\n",
    "        if not candidate_pi_ids:\n",
    "            return f\"Could not find influencers matching {criterion_type}: '{criterion_value}'.\"\n",
    "        # Rank the selected candidates\n",
    "        return self.rank_influencers_by_list(candidate_pi_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c498a1fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Query Router Class ---\n",
    "class QueryRouter:\n",
    "    def __init__(self, kg_system: ScholarKGQA, pi_system: PIRankingAnalysis, router_llm_model_name: str):\n",
    "        print(f\"Initializing QueryRouter with model: {router_llm_model_name}\")\n",
    "        self.kg_system = kg_system\n",
    "        self.pi_system = pi_system\n",
    "        try:\n",
    "            # Use specific Gemini model via genai SDK\n",
    "            self.router_model = genai.GenerativeModel(router_llm_model_name)\n",
    "            print(f\"Router LLM ({router_llm_model_name}) initialized.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error initializing Router LLM: {e}\")\n",
    "            self.router_model = None\n",
    "\n",
    "    def _get_intent_from_llm(self, question: str) -> str:\n",
    "        \"\"\"Uses LLM to classify the question intent.\"\"\"\n",
    "        if not self.router_model: return \"unknown\"\n",
    "        prompt = f\"\"\"Classify the user's question into one of the following categories:\n",
    "            - kg_query: Asking about papers, authors, venues, citations, specific collaborations, disciplines.\n",
    "            - pi_recommendation: Asking to recommend a PI for a topic from a given list of researchers.\n",
    "            - influencer_list: Asking to rank or find the best influencer from a given list of researchers.\n",
    "            - influencer_topic: Asking to find the best influencer for a specific research topic.\n",
    "            - influencer_dept: Asking to find the best influencer within a specific department.\n",
    "            - unknown: If the question doesn't fit the above categories.\n",
    "\n",
    "            Question: \"{question}\"\n",
    "            Category: \"\"\"\n",
    "        try:\n",
    "            # Adding safety settings to prevent potential blocks on classification\n",
    "            safety_settings = [\n",
    "                {\"category\": \"HARM_CATEGORY_HARASSMENT\", \"threshold\": \"BLOCK_NONE\"},\n",
    "                {\"category\": \"HARM_CATEGORY_HATE_SPEECH\", \"threshold\": \"BLOCK_NONE\"},\n",
    "                {\"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\", \"threshold\": \"BLOCK_NONE\"},\n",
    "                {\"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\", \"threshold\": \"BLOCK_NONE\"},\n",
    "            ]\n",
    "            response = self.router_model.generate_content(prompt, safety_settings=safety_settings)\n",
    "            # Adapt response extraction\n",
    "            if hasattr(response, 'text'): intent = response.text.strip().lower()\n",
    "            elif hasattr(response, 'candidates') and response.candidates: intent = response.candidates[0].content.parts[0].text.strip().lower()\n",
    "            else: intent = \"unknown\"\n",
    "\n",
    "            # Basic validation\n",
    "            valid_intents = [\"kg_query\", \"pi_recommendation\", \"influencer_list\", \"influencer_topic\", \"influencer_dept\", \"unknown\"]\n",
    "            # Allow for slight variations like punctuation\n",
    "            intent = re.sub(r'[^\\w_]', '', intent) # Remove non-alphanumeric/_ characters\n",
    "            if intent not in valid_intents:\n",
    "                 print(f\"Warning: LLM returned unexpected intent '{intent}'. Defaulting to 'unknown'.\")\n",
    "                 return \"unknown\"\n",
    "            print(f\"LLM classified intent as: {intent}\")\n",
    "            return intent\n",
    "        except Exception as e:\n",
    "            # Handle potential blocked prompts explicitly if possible\n",
    "            if \"block_reason\" in str(e):\n",
    "                 print(f\"Intent classification blocked: {e}\")\n",
    "                 return \"unknown\" # Or handle appropriately\n",
    "            print(f\"Error during intent classification: {e}\")\n",
    "            return \"unknown\"\n",
    "\n",
    "    def _extract_parameters(self, question: str, intent: str) -> Dict[str, Any]:\n",
    "        \"\"\"Extracts parameters based on intent (using regex).\"\"\"\n",
    "        params = {}\n",
    "        print(f\"Attempting to extract parameters for intent: {intent}\") # Debug print\n",
    "        if intent == \"pi_recommendation\":\n",
    "            # --- MODIFIED Regex Logic ---\n",
    "            # 1. Find the PI ID list\n",
    "            id_match = re.search(r\"(\\[.*?\\])\", question, re.IGNORECASE)\n",
    "            pi_ids = []\n",
    "            if id_match:\n",
    "                pi_ids_str = id_match.group(1)\n",
    "                pi_ids = self._extract_pi_ids(pi_ids_str) # Use helper\n",
    "                if pi_ids: params[\"pi_ids\"] = pi_ids\n",
    "                print(f\"Found PI IDs: {pi_ids}\") # Debug print\n",
    "\n",
    "            # 2. Find the topic (often after 'in' or 'topic' and quoted)\n",
    "            topic_match = re.search(r\"\\s(?:in|topic)\\s+[\\'\\\"]?([^\\'\\\"]+)[\\'\\\"]?\", question, re.IGNORECASE)\n",
    "            if topic_match:\n",
    "                topic = topic_match.group(1).strip()\n",
    "                # Avoid capturing the start of the ID list if topic is unquoted and appears just before it\n",
    "                if not topic.startswith('['):\n",
    "                     params[\"topic\"] = topic\n",
    "                     print(f\"Found Topic: {topic}\") # Debug print\n",
    "            # --- END MODIFIED ---\n",
    "\n",
    "        elif intent == \"influencer_list\":\n",
    "             match = re.search(r\"among\\s+(?:them|these)\\s*:\\s*(.*)\", question, re.IGNORECASE)\n",
    "             if match:\n",
    "                 pi_ids = self._extract_pi_ids(match.group(1))\n",
    "                 if pi_ids: params[\"pi_ids\"] = pi_ids\n",
    "\n",
    "        elif intent == \"influencer_topic\":\n",
    "             match = re.search(r\"topic\\s+[\\'\\\"]?([^\\'\\\"]+)[\\'\\\"]?\", question, re.IGNORECASE)\n",
    "             if match:\n",
    "                 params[\"topic\"] = match.group(1).strip()\n",
    "\n",
    "        elif intent == \"influencer_dept\":\n",
    "             match = re.search(r\"in\\s+[\\'\\\"]?([^\\'\\\"]+)[\\'\\\"]?\\s+department\", question, re.IGNORECASE)\n",
    "             if match:\n",
    "                 params[\"department\"] = match.group(1).strip()\n",
    "\n",
    "        print(f\"Final extracted parameters: {params}\") # Debug print\n",
    "        return params\n",
    "\n",
    "    def _extract_pi_ids(self, text: str) -> List[str]:\n",
    "         \"\"\"Helper to extract list-like PI IDs (e.g., ['id1', 'id2']).\"\"\"\n",
    "         # Extracts numbers within brackets, separated by commas, optional quotes\n",
    "         match = re.search(r\"\\[\\s*([\\'\\\"]?\\s*\\d+\\s*[\\'\\\"]?(?:\\s*,\\s*[\\'\\\"]?\\d+\\s*[\\'\\\"]?)*)\\s*\\]\", text)\n",
    "         if match:\n",
    "             id_list_str = match.group(1)\n",
    "             # Split by comma, then strip quotes and spaces from each item\n",
    "             ids = [item.strip('\\'\" ') for item in id_list_str.split(',')]\n",
    "             return [item for item in ids if item.isdigit()] # Ensure only valid numbers are returned\n",
    "         return []\n",
    "\n",
    "    def route(self, question: str) -> str:\n",
    "        \"\"\"Routes the question to the correct system and method.\"\"\"\n",
    "        print(f\"\\nRouting question: \\\"{question}\\\"\")\n",
    "        # LLM classification first\n",
    "        intent = self._get_intent_from_llm(question)\n",
    "        print(f\"Identified intent: {intent}\") # Debug print\n",
    "\n",
    "        # Parameter extraction based on identified intent\n",
    "        params = self._extract_parameters(question, intent)\n",
    "        print(f\"Extracted parameters: {params}\") # Debug print\n",
    "\n",
    "        if intent == \"pi_recommendation\":\n",
    "            if \"pi_ids\" in params and params[\"pi_ids\"] and \"topic\" in params and params[\"topic\"]:\n",
    "                 return self.pi_system.recommend_pi(params[\"pi_ids\"], params[\"topic\"])\n",
    "            else:\n",
    "                 # Fallback if extraction failed but intent was clear\n",
    "                 print(\"Warning: PI Recommendation intent identified, but parameters extraction failed. Falling back to KG.\")\n",
    "                 return self.kg_system.query(question)\n",
    "\n",
    "        elif intent == \"influencer_list\":\n",
    "             if \"pi_ids\" in params and params[\"pi_ids\"]:\n",
    "                 return self.pi_system.rank_influencers_by_list(params[\"pi_ids\"])\n",
    "             else:\n",
    "                  print(\"Warning: Influencer List intent identified, but parameters extraction failed. Falling back to KG.\")\n",
    "                  return self.kg_system.query(question)\n",
    "\n",
    "        elif intent == \"influencer_topic\":\n",
    "             if \"topic\" in params and params[\"topic\"]:\n",
    "                 return self.pi_system.find_influencer_by_criterion(\"topic\", params[\"topic\"])\n",
    "             else:\n",
    "                  print(\"Warning: Influencer Topic intent identified, but parameters extraction failed. Falling back to KG.\")\n",
    "                  return self.kg_system.query(question)\n",
    "\n",
    "        elif intent == \"influencer_dept\":\n",
    "             if \"department\" in params and params[\"department\"]:\n",
    "                 return self.pi_system.find_influencer_by_criterion(\"department\", params[\"department\"])\n",
    "             else:\n",
    "                  print(\"Warning: Influencer Dept intent identified, but parameters extraction failed. Falling back to KG.\")\n",
    "                  return self.kg_system.query(question)\n",
    "\n",
    "        if intent == \"kg_query\":\n",
    "            print(\"Routing to KG system for query...\")\n",
    "            return self.kg_system.query(question)\n",
    "\n",
    "        else: # Fallback for 'unknown' intent\n",
    "            print(\"Intent unclear or extraction failed, falling back to Knowledge Graph query.\")\n",
    "            return self.kg_system.query(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e7ee521c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- System Initialization ---\n",
      "Loading Scholar Data...\n",
      "Scholar data loaded.\n",
      "Data processing started. 100 rows found.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/hc/dq1y9hzx51s30kq78z6v4jsm0000gp/T/ipykernel_19733/417375466.py:37: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  scholar_data = scholar_data.applymap(lambda x: x.strip() if isinstance(x, str) else x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data processing complete. 848 rows loaded.\n",
      "Loading Ranking Data...\n",
      "Paused for a while to avoid rate limits...\n",
      "Reading files in 2022...\n",
      "Reading files in 2024...\n",
      "Reading files in 2023...\n",
      "Reading files in 2021...\n",
      "Reading files in 2020...\n",
      "Ranking data loaded and processed. 83112 rows found.\n",
      "Preparing ranking data group for analysis...\n",
      "Initializing PIRankingAnalysis with model: gemini-2.0-flash-thinking-exp-01-21\n",
      "PI Ranking LLM (gemini-2.0-flash-thinking-exp-01-21) initialized.\n",
      "Initializing QueryRouter with model: gemini-2.0-flash-lite\n",
      "Router LLM (gemini-2.0-flash-lite) initialized.\n",
      "\n",
      "--- Systems Ready ---\n",
      "\n",
      "Routing question: \"These researchers ['269948909', '000173003', '269886945'] want to start a reserach group in 'STATISTICS', who should be the PI\"\n",
      "LLM classified intent as: pi_recommendation\n",
      "Identified intent: pi_recommendation\n",
      "Attempting to extract parameters for intent: pi_recommendation\n",
      "Found PI IDs: ['269948909', '000173003', '269886945']\n",
      "Found Topic: STATISTICS\n",
      "Final extracted parameters: {'pi_ids': ['269948909', '000173003', '269886945'], 'topic': 'STATISTICS'}\n",
      "Extracted parameters: {'pi_ids': ['269948909', '000173003', '269886945'], 'topic': 'STATISTICS'}\n",
      "PI Ranking LLM response generated in 9.87 seconds.\n",
      "\n",
      "Q: These researchers ['269948909', '000173003', '269886945'] want to start a reserach group in 'STATISTICS', who should be the PI\n",
      "A: Based ONLY on the information provided:\n",
      "\n",
      "The most suitable Principal Investigator (PI) to lead the research project on 'STATISTICS' is **Xin Zhang**.\n",
      "\n",
      "**Detailed Explanation:**\n",
      "\n",
      "Xin Zhang's qualifications and past work demonstrate the most direct relevance to the field of 'STATISTICS' among the three candidates presented:\n",
      "\n",
      "1.  **Departmental Affiliation:** Xin Zhang is affiliated with the \"Department of Statistics,\" which directly aligns with the focus of the new project.\n",
      "2.  **Direct Relevance in Grants:**\n",
      "    *   One grant titled \"Collaborative Research: New Regression Models and Methods for Studying Multiple Categorical Responses\" is clearly focused on statistical modeling methods (Regression). The abstract snippet also discusses modeling tasks relevant to statistical applications in various fields.\n",
      "    *   The Program Element listed for this grant explicitly includes \"STATISTICS\". This is the only instance across all three candidates where the specific program element directly names 'STATISTICS'.\n",
      "    *   Another grant is related to \"Tensor and Subspace Learning Methods\" with a Program Element including \"Machine Learning Theory\". Machine learning theory is a field closely related to and often built upon statistical principles.\n",
      "3.  **Demonstrated Experience:** Xin Zhang has served as \"Principal Investigator\" on both listed grants, indicating experience leading research projects.\n",
      "\n",
      "In contrast:\n",
      "\n",
      "*   **Peter D Hislop** is in the Department of Mathematics. While mathematics is foundational, the provided information for their grant focuses on \"Analysis Meetings\" supported by the \"ANALYSIS PROGRAM\". There is no explicit mention of 'STATISTICS' in the title, abstract, or program element of the listed award.\n",
      "*   **Mircea Teodorescu** is in the Department of Computer Engineering. The listed grants are focused on robotics, bioengineering, and neuroscience/biology topics (\"Fabricating cable-driven robots\", \"RECODE-ing the Logic of Ectodermal Organoid Patterning\", \"The evolution and diversity of the human brain\") and supported by programs like \"I-Corps\", \"Cellular & Biochem Engineering\", and \"NSF 2026 Fund / EAGER\". None of the titles, abstracts, or program elements directly relate to 'STATISTICS' based on the provided text.\n",
      "\n",
      "Therefore, based on the explicit departmental affiliation, the direct mention of 'STATISTICS' in a program element, and the clear statistical relevance of a grant title and abstract, Xin Zhang is the most qualified candidate for a 'STATISTICS' research project among the three based *solely* on the provided information.\n",
      "------------------------------\n",
      "\n",
      "Routing question: \"who is the best influencer in 'computer science' department\"\n",
      "LLM classified intent as: influencer_dept\n",
      "Identified intent: influencer_dept\n",
      "Attempting to extract parameters for intent: influencer_dept\n",
      "Final extracted parameters: {'department': 'computer science'}\n",
      "Extracted parameters: {'department': 'computer science'}\n",
      "Selecting top 5 candidates based on department: 'computer science'...\n",
      "  (Found 2938 PIs, selecting top 5 based on award count)\n",
      "Selected candidate PI IDs: ['269935164', '269779708', '269765937', '000235919', '270031750']\n",
      "PI Ranking LLM response generated in 9.75 seconds.\n",
      "\n",
      "Q: who is the best influencer in 'computer science' department\n",
      "A: Based ONLY on the provided summarized data and criteria, here is the ranking from most influential to least influential:\n",
      "\n",
      "1.  **Prasad Calyam**\n",
      "    *   **Justification:** Ranks highest or second highest in all metrics: 14 projects (highest), 25 unique collaborators (second highest), and 22 unique research fields (highest). Shows broad activity, extensive collaboration, and high diversity.\n",
      "\n",
      "2.  **Tiffany M Barnes**\n",
      "    *   **Justification:** Ranks highest in unique collaborators (30), second highest in unique research fields (13), and has a moderate number of projects (11). Demonstrates the broadest collaborative network and strong field diversity, despite fewer projects than Calyam or Ye.\n",
      "\n",
      "3.  **Yanfang Ye**\n",
      "    *   **Justification:** Ranks second highest in projects (13) and is in the middle range for unique research fields (12), but has a lower number of unique collaborators (11). Shows strong project involvement and decent field diversity, but a smaller collaboration network compared to those ranked above.\n",
      "\n",
      "4.  **Sharad Mehrotra**\n",
      "    *   **Justification:** Is in the mid-range for unique collaborators (18) and projects (10), but towards the lower end for unique research fields (11). Ranks below Ye in projects and fields, although higher in collaborators.\n",
      "\n",
      "5.  **Ferdinando Fioretto**\n",
      "    *   **Justification:** Ranks lowest in both total projects (7) and unique collaborators (6), and is tied for the lowest number of unique research fields (11). Demonstrates the least activity, smallest collaboration network, and least diversity among this group according to the metrics.\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "# --- Main Execution ---\n",
    "print(\"--- System Initialization ---\")\n",
    "load_all_data()\n",
    "\n",
    "if scholar_data is None:\n",
    "    print(\"Critical Error: Data loading failed. Exiting.\")\n",
    "else:\n",
    "    pi_analysis_system = PIRankingAnalysis(\n",
    "            ranking_data = ranking_data, \n",
    "            grouped_data = ranking_data_grouped, \n",
    "            llm_model_name = PI_RANKING_LLM_MODEL\n",
    "        )\n",
    "    scholar_kg_system = ScholarKGQA(\n",
    "             google_api_key=GOOGLE_API_KEY,\n",
    "             neo4j_url=NEO4J_URL,\n",
    "             neo4j_user=NEO4J_USER,\n",
    "             neo4j_password=NEO4J_PASSWORD,\n",
    "             neo4j_db=NEO4J_SCHOLAR_DB,\n",
    "             llm_model_tag=KG_LLM_MODEL,\n",
    "             example=example,\n",
    "             verbose=True\n",
    "             )\n",
    "\n",
    "    router = QueryRouter(\n",
    "        scholar_kg_system, pi_analysis_system, ROUTER_LLM_MODEL\n",
    "    )\n",
    "    if not scholar_kg_system.chain:\n",
    "            print(\"Critical Error: System components failed to initialize. Exiting.\")\n",
    "    else:\n",
    "        print(\"\\n--- Systems Ready ---\")\n",
    "\n",
    "        # --- Run Example Questions ---\n",
    "        questions = [\n",
    "            # \"List all papers authored by 'Han Xiao'\", # OK\n",
    "            # \"I am 'Han Xiao'. Which researchers I collaborated with before?\",\n",
    "            \"These researchers ['269948909', '000173003', '269886945'] want to start a reserach group in 'STATISTICS', who should be the PI\", # OK\n",
    "            # \"who is the best influencer among them: ['000025762', '269811881', '269807623', '270021884']\", # OK\n",
    "            # \"who will be the best influencer for this topic 'AI Circuits design'\", # OK\n",
    "            \"who is the best influencer in 'computer science' department\", # OK\n",
    "            # \"How many citations does the paper 'Fashion-MNIST' have?\"\n",
    "        ]\n",
    "\n",
    "        for q in questions:\n",
    "            # cypher\n",
    "            # answer = router.route(q)['result']\n",
    "            # print(f\"\\nQ: {q}\\nA: {answer['result']}\")\n",
    "            # PI ranking\n",
    "            # answer = router.route(q)\n",
    "            # print(f\"\\nQ: {q}\")\n",
    "            # print(f\"A: {answer}\")\n",
    "            # best influencer\n",
    "            # answer = router.route(q)\n",
    "            # print(f\"\\nQ: {q}\")\n",
    "            # print(f\"A: {answer}\")\n",
    "            # influencer in a topic\n",
    "            # answer = router.route(q)\n",
    "            # print(f\"\\nQ: {q}\")\n",
    "            # print(f\"A: {answer}\")\n",
    "            # influencer in a department\n",
    "            answer = router.route(q)\n",
    "            print(f\"\\nQ: {q}\")\n",
    "            print(f\"A: {answer}\")\n",
    "            print(\"-\" * 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9134790",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agent",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
