{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/agent/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "from dotenv import load_dotenv\n",
    "from langchain_community.graphs import Neo4jGraph\n",
    "from langchain.chains import GraphCypherQAChain\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_community.llms import HuggingFaceHub\n",
    "from langchain.chains import GraphCypherQAChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "load_dotenv(dotenv_path=\".env\")\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Function to extract the year and clean the title\n",
    "# def separate_title_and_year(title):\n",
    "#     # Use regex to find the year in parentheses\n",
    "#     year_match = re.search(r'\\((\\d{4})\\)$', title)\n",
    "    \n",
    "#     # If a match is found, extract the year and clean the title\n",
    "#     if year_match:\n",
    "#         year = year_match.group(1)\n",
    "#         # Remove the year from the title\n",
    "#         cleaned_title = re.sub(r'\\(\\d{4}\\)$', '', title).strip()\n",
    "#     else:\n",
    "#         year = None\n",
    "#         cleaned_title = title\n",
    "    \n",
    "#     return cleaned_title, year\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load the first 500 rows of each dataset\n",
    "# ratings = pd.read_csv('data/ratings.csv', usecols=['userId', 'movieId', 'rating'], nrows=500)\n",
    "# movies = pd.read_csv('data/movies.csv', nrows=500)\n",
    "# tags = pd.read_csv('data/tags.csv', usecols=['userId', 'movieId', 'tag'], nrows=500)  # Optional\n",
    "\n",
    "# movies['title'], movies['year'] = zip(*movies['title'].apply(separate_title_and_year))\n",
    "\n",
    "# # Merge ratings with movies based on 'movieId'\n",
    "# df = pd.merge(ratings, movies, on='movieId', how='inner')\n",
    "\n",
    "# # Optional: Merge tags if needed (without timestamps)\n",
    "# # df = pd.merge(merged_data, tags, on=['userId', 'movieId'], how='left')\n",
    "\n",
    "# # Now you have the merged dataset for recommendation (limited to 500 rows)\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['genres_list'] = df['genres'].str.split('|')\n",
    "\n",
    "# # Step 2: Explode the list into multiple rows (one genre per row per movie)\n",
    "# movies_exploded = df.explode('genres_list').reset_index(drop=True)\n",
    "# movies_exploded[\"genres\"] = movies_exploded[\"genres_list\"]\n",
    "# movies_exploded.drop([\"genres_list\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# movies_exploded.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "gemini_api = os.getenv(\"GOOGLE_API_KEY\")\n",
    "hugging_face_api = os.getenv(\"HF_API_KEY\")\n",
    "gpt_api = os.getenv(\"GPT_API_KEY_IE\")\n",
    "anthropic_api = os.getenv(\"ANTHROPIC_API_KEY\")\n",
    "neo4j_url = os.getenv(\"NEO4J_CONNECTION_URL\")\n",
    "neo4j_user = os.getenv(\"NEO4J_USER\")\n",
    "neo4j_password = os.getenv(\"NEO4J_PASSWORD\")\n",
    "neo4j_db = os.getenv(\"NEO4J_MOVIE\")\n",
    "\n",
    "# graph = Neo4jGraph(neo4j_url, neo4j_user, neo4j_password, database=neo4j_db)\n",
    "\n",
    "neo4j_db = os.getenv(\"NEO4J_SCHOLAR\")\n",
    "graph = Neo4jGraph(neo4j_url, neo4j_user, neo4j_password, database=neo4j_db)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node properties:\n",
      "Paper {citations: INTEGER, title: STRING, topic: STRING, year: FLOAT}\n",
      "Author {name: STRING}\n",
      "Discipline {name: STRING}\n",
      "Venue {name: STRING}\n",
      "Relationship properties:\n",
      "\n",
      "The relationships:\n",
      "(:Paper)-[:BELONGS_TO]->(:Discipline)\n",
      "(:Paper)-[:PUBLISHED_IN]->(:Venue)\n",
      "(:Author)-[:AUTHORED]->(:Paper)\n"
     ]
    }
   ],
   "source": [
    "graph.refresh_schema()\n",
    "print(graph.schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "example = [\n",
    "    {\n",
    "        \"question\": \"Give me 10 movies similar to 'Forrest Gump' released in 1990 or later.\",\n",
    "        \"query\": \"MATCH (m:Movie {title: 'Forrest Gump'})-[:HAS_GENRE]->(g:Genre)<-[:HAS_GENRE] -(similar:Movie) WHERE m <> similar AND similar.year >= 1990 RETURN similar.title AS SimilarMovies, COUNT(g) AS SharedGenres ORDER BY SharedGenres DESC LIMIT 10\",\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"What are the ratings for 'Forrest Gump'?\",\n",
    "        \"query\": \"MATCH (m:Movie {title: 'Forrest Gump'})<-[r:RATED]-(u:User) RETURN u.userId AS UserId, r.rating AS Rating\",\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"What is the average rating for 'Forrest Gump'?\",\n",
    "        \"query\": \"MATCH (m:Movie {title: 'Forrest Gump'})<-[r:RATED]-(u:User) RETURN AVG(r.rating) AS AverageRating\",\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"Find all movies released in 1995.\",\n",
    "        \"query\": \"MATCH (m:Movie) WHERE m.year = 1995RETURN m.title AS MoviesReleasedIn1995\",\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"What are the genres of 'Pocahontas'?\",\n",
    "        \"query\": \"MATCH (m:Movie {title: 'Pocahontas'})-[:HAS_GENRE]->(g:Genre) RETURN g.name AS Genres\",\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"How many movies are in the 'Comedy' genre?\",\n",
    "        \"query\": \"MATCH (m:Movie)-[:HAS_GENRE]->(g:Genre {name: 'Comedy'}) RETURN COUNT(m) AS ComedyMovieCount\",\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"List all users who rated movies in the 'Drama' genre.\",\n",
    "        \"query\": \"MATCH (m:Movie)-[:HAS_GENRE]->(g:Genre {name: 'Drama'})<-[:RATED]-(u:User)RETURN DISTINCT u.userId AS UsersWhoRatedDrama\",\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"Find all movies rated above 4.0.\",\n",
    "        \"query\": \"MATCH (m:Movie)<-[r:RATED]-(u:User) WHERE r.rating > 4.0 RETURN m.title AS HighRatedMovies, AVG(r.rating) AS AverageRating\",\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"Find movies with 'City' in the title.\",\n",
    "        \"query\": \" MATCH (m:Movie) WHERE m.title CONTAINS 'City' RETURN m.title AS MoviesWithCityInTitle\",\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"What companies do workers named John work in?\",\n",
    "        \"query\": \"MATCH (p:Person {name: 'John'})-[:WORKS_IN]->(c:Company) RETURN c.name\",\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"What are the ratings for 'Eat Drink Man Woman (Yin shi nan nu)'?\",\n",
    "        \"query\": \"MATCH (m:Movie {title: 'Eat Drink Man Woman (Yin shi nan nu)'})<-[r:RATED]-(u:User) RETURN u.userId AS UserId, r.rating AS Rating\",\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"Which movies have the most shared genres with 'While You Were Sleeping'?\",\n",
    "        \"query\": \"MATCH (m:Movie {title: 'While You Were Sleeping'})-[:HAS_GENRE]->(g:Genre)<-[:HAS_GENRE]-(similar:Movie) WHERE m <> similar RETURN similar.title AS SimilarMovies, COUNT(g) AS SharedGenres ORDER BY SharedGenres DESC LIMIT 10\",\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"What is the highest rated movie?\",\n",
    "        \"query\": \"MATCH (m:Movie)<-[r:RATED]-(u:User) RETURN m.title AS HighestRatedMovie, AVG(r.rating) AS AverageRating ORDER BY AverageRating DESC LIMIT 1\",\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"Find all movies that are both 'Comedy' and 'Romance'.\",\n",
    "        \"query\": \"MATCH (m:Movie)-[:HAS_GENRE]->(g:Genre) WHERE g.name IN ['Comedy', 'Romance'] RETURN m.title AS MoviesThatAreComedyAndRomance\",\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"How many users rated 'French Kiss'?\",\n",
    "        \"query\": \"MATCH (m:Movie {title: 'French Kiss'})<-[:RATED]-(u:User) RETURN COUNT(u) AS NumberOfUsersWhoRatedFrenchKiss\",\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"What movies did user 1 rate?\",\n",
    "        \"query\": \"MATCH (u:User {userId: 1})-[r:RATED]->(m:Movie) RETURN m.title AS MoviesRatedByUser1\",\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"Find all movies in the 'True Lies' genre.\",\n",
    "        \"query\": \"MATCH (m:Movie)-[:HAS_GENRE]->(g:Genre {name: 'True Lies'}) RETURN m.title AS MoviesInTrueLiesGenre\",\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"List users who rated movies released in 1995.\",\n",
    "        \"query\": \"MATCH (m:Movie)<-[r:RATED]-(u:User) WHERE m.year = 1995 RETURN DISTINCT u.userId AS UsersWhoRatedMoviesIn1995\",\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"How many movies has each user rated?\",\n",
    "        \"query\": \"MATCH (u:User)-[r:RATED]->(m:Movie) RETURN u.userId AS UserId, COUNT(r) AS RatedMoviesCount\",\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"What are the genres of 'Hot Shots! Part Deux'?\",\n",
    "        \"query\": \" MATCH (m:Movie {title: 'Hot Shots! Part Deux'})-[:HAS_GENRE]->(g:Genre) RETURN g.name AS Genres\",\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"I like the movie 'True Lies'. give me 5 movie similar to this one with their genres\",\n",
    "        \"query\": \"MATCH (m:Movie {title: 'True Lies'})-[:HAS_GENRE]->(g:Genre) WITH g MATCH (other:Movie)-[:HAS_GENRE]->(g) WHERE other.title <> 'True Lies' WITH other, collect(g.name) as genres, COUNT(g) as genreCount ORDER BY genreCount DESC RETURN other.title as Movie, genres as Genres LIMIT 5\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"I liked the movie 'Braveheart'. What are 5 similar movies I should watch?\",\n",
    "        \"query\": \"MATCH (m:Movie {title: 'Braveheart'})-[:HAS_GENRE]->(g:Genre) WITH g MATCH (other:Movie)-[:HAS_GENRE]->(g) WHERE other.title <> 'Braveheart' WITH other, COLLECT(g.name) as genres, COUNT(g) as genreCount ORDER BY genreCount DESC RETURN other.title as SimilarMovie, genres LIMIT 5\",\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"I like 'Drama' and 'Romance'. I have watched 'Sense and Sensibility' and 'Leaving Las Vegas'. What should I watch next?\",\n",
    "        \"query\": \"MATCH (x:Movie {title: 'Sense and Sensibility'})-[:HAS_GENRE]->(g1:Genre), (z:Movie {title: 'Leaving Las Vegas'})-[:HAS_GENRE]->(g2:Genre) WITH g1, g2 MATCH (other:Movie)-[:HAS_GENRE]->(g)  WHERE (g = g1 OR g = g2) AND other.title <> 'Sense and Sensibility' AND other.title <> 'Leaving Las Vegas' RETURN DISTINCT other.title AS RecommendedMovie LIMIT 5\",\n",
    "    }\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "example = [\n",
    "    {\n",
    "        \"question\": \"List all papers authored by 'Han Xiao'.\",\n",
    "        \"query\": \"MATCH (a:Author {name: 'Han Xiao'})-[:AUTHORED]->(p:Paper) RETURN p.title AS PapersAuthoredByHanXiao\",\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"Which papers belong to the 'Computer Science' discipline?\",\n",
    "        \"query\": \"MATCH (p:Paper)-[:BELONGS_TO]->(d:Discipline {name: 'Computer Science'}) RETURN p.title AS PapersInComputerScience Limit 5\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"What are the papers published in 'Nature' in the year 2018?\",\n",
    "        \"query\": \"MATCH (p:Paper)-[:PUBLISHED_IN]->(v:Venue {name: 'Nature'}) WHERE p.year = 2018 RETURN p.title AS PapersPublishedInNature2018\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"How many papers did 'Jianmin Chen' author?\",\n",
    "        'query': \"MATCH (a:Author {name: 'Jianmin Chen'})-[:AUTHORED]->(p:Paper) RETURN COUNT(p) AS NumberOfPapersAuthoredByJianminChen\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"List all authors who have published papers in the topic 'Machine Learning'.\",\n",
    "        \"query\": \"MATCH (a:Author)-[:AUTHORED]->(p:Paper {topic: 'Machine Learning'}) RETURN DISTINCT a.name AS AuthorsInMachineLearning Limit 5\"\n",
    "    },\n",
    "    {\n",
    "        'question': \"What are the most cited papers in 'Mathematics'?\",\n",
    "        'query': \"MATCH (p:Paper)-[:BELONGS_TO]->(d:Discipline {name: 'Mathematics'}) RETURN p.title AS PapersInComputerScience Limit 5\"\n",
    "    },\n",
    "    {\n",
    "        'question': \"What are the most cited papers in 'Materials Science' discipline?\",\n",
    "        'query': \"MATCH (p:Paper)-[:BELONGS_TO]->(d:Discipline {name: 'Materials Science'}) RETURN p.title AS Paper, p.citations AS Citations ORDER BY Citations DESC LIMIT 5\"\n",
    "    },\n",
    "    {\n",
    "        'question': \"Which venues have published papers in the 'Network Science' topic?\",\n",
    "        'query': \"MATCH (p:Paper {topic: 'Network Science'})-[:PUBLISHED_IN]->(v:Venue) RETURN DISTINCT v.name AS VenuesForNetworkScience LIMIT 5\"\n",
    "    },\n",
    "    {\n",
    "        'question': \"I am 'Han Xiao' conducts research in 'Computer Science' and 'Machine Learning'. Which professors should he collaborate with?\",\n",
    "        'query': \"MATCH (a:Author {name: 'Han Xiao'})-[:AUTHORED]->(p:Paper)-[:BELONGS_TO]->(d:Discipline) WHERE d.name = 'Computer Science' OR p.topic = 'Machine Learning' WITH DISTINCT d AS Discipline, p.topic AS Topic MATCH (other:Author)-[:AUTHORED]->(:Paper)-[:BELONGS_TO]->(d) WHERE other.name <> 'Han Xiao' RETURN DISTINCT other.name AS PotentialCollaborators LIMIT 5\"\n",
    "    },\n",
    "    {\n",
    "        'question': \"I am 'Han Xiao'. Which researchers I collaborated with before?\",\n",
    "        'query': \"MATCH (a1:Author {name: 'Han Xiao'})-[:AUTHORED]->(p:Paper)<-[:AUTHORED]-(a2:Author) WHERE a1 <> a2 RETURN DISTINCT a2.name\"\n",
    "    },\n",
    "    {\n",
    "        'question': \"I am 'Han Xiao'. Which new researchers should I collaborate with for future work?\",\n",
    "        'query': \"MATCH (a1:Author {name: 'Han Xiao'})-[:AUTHORED]->(p:Paper)-[:BELONGS_TO]->(d:Discipline)<-[:BELONGS_TO]-(p2:Paper)<-[:AUTHORED]-(a2:Author) WHERE a1 <> a2 RETURN a2.name, COUNT(p2) AS collaborations ORDER BY collaborations DESC\"\n",
    "    },\n",
    "    {\n",
    "        'question': \"I am 'Kashif Rasul'. I have some workes in 'Mathematics' and want to expand my research in this field. Which researchers should I collaborate with based on papers related to 'Mathematics'?\",\n",
    "        'query': \"MATCH (a:Author {name: 'Kashif Rasul'})-[:AUTHORED]->(p:Paper)-[:BELONGS_TO]->(d:Discipline) WHERE d.name = 'Mathematics' WITH DISTINCT d AS Discipline MATCH (other:Author)-[:AUTHORED]->(:Paper)-[:BELONGS_TO]->(d) WHERE other.name <> 'Kashif Rasul' RETURN DISTINCT other.name AS PotentialCollaborators\"\n",
    "    }\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Cypher query prompt template\n",
    "cypher_generation_prompt = PromptTemplate(\n",
    "    template=\"\"\"Based on the schema, write a Cypher query to answer the question.\n",
    "    \n",
    "    The question may ask about:\n",
    "    - Similar movies based on genre\n",
    "    - Movies a user has rated\n",
    "    - Recommendations based on genres the user likes\n",
    "\n",
    "    Schema:\n",
    "    {schema}\n",
    "\n",
    "    Example questions and queries:\n",
    "    {example}\n",
    "\n",
    "    **Important**:\n",
    "    - Always identify movies based on their **titles**.\n",
    "    - Use the exact movie titles provided in the question for any matching logic.\n",
    "    - Do not reference `userId` or `movieId`; focus solely on the titles of movies and their genres.\n",
    "    - Assume that if a user has rated a movie, they have watched it.\n",
    "\n",
    "    Question: {question}\n",
    "    Query:\"\"\",\n",
    "    input_variables=[\"schema\", \"question\", \"example\"],\n",
    ")\n",
    "\n",
    "# Define the answer generation prompt template\n",
    "qa_prompt = PromptTemplate(\n",
    "    template=\"\"\"Based on the Cypher query results, answer the question.\n",
    "    Question: {question}\n",
    "    Results: {context}\n",
    "    Give a clear, direct but human-friendly answer using the data from the results. \n",
    "    If it's a list, combine all items.\n",
    "    Answer:\"\"\",\n",
    "    input_variables=[\"question\", \"context\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Initialize the LLM (Google Generative AI)\n",
    "# llm = ChatGoogleGenerativeAI(model=\"gemini-pro\", google_api_key=gemini_api, temperature=0)\n",
    "\n",
    "# ALLOW_DANGEROUS_REQUEST = True\n",
    "\n",
    "# # Define the chain\n",
    "# chain = GraphCypherQAChain.from_llm(\n",
    "#     llm=llm,\n",
    "#     graph=graph,  # Your Neo4j graph object\n",
    "#     verbose=True,\n",
    "#     cypher_generation_prompt=cypher_generation_prompt,\n",
    "#     qa_prompt=qa_prompt,\n",
    "#     allow_dangerous_requests=ALLOW_DANGEROUS_REQUEST,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Test query function\n",
    "# def test_query(question):\n",
    "#     try:\n",
    "#         # Explicitly generate the Cypher query first using the prompt\n",
    "#         generated_query = cypher_generation_prompt.format(\n",
    "#             schema=graph.schema,  # Ensure dynamic schema usage\n",
    "#             question=question,\n",
    "#             example=example\n",
    "#         )\n",
    "\n",
    "#         # Run the chain with the generated query\n",
    "#         result = chain.run(query=generated_query, question=question)\n",
    "        \n",
    "#         print(f\"Q: {question}\")\n",
    "#         print(f\"A: {result}\\n\")\n",
    "#     except Exception as e:\n",
    "#         print(f\"Error: {str(e)}\")\n",
    "#     return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import io\n",
    "# import sys\n",
    "# import re\n",
    "\n",
    "# def clean_ansi(text):\n",
    "#     # Remove ANSI escape codes\n",
    "#     ansi_escape = re.compile(r'\\x1B(?:[@-Z\\\\-_]|\\[[0-?]*[ -/]*[@-~])')\n",
    "#     return ansi_escape.sub('', text).strip()\n",
    "\n",
    "# def test_query(question):\n",
    "#     try:\n",
    "#         # Create a string buffer to capture the output\n",
    "#         output_buffer = io.StringIO()\n",
    "#         original_stdout = sys.stdout\n",
    "#         # sys.stdout = output_buffer\n",
    "\n",
    "#         # Explicitly generate the Cypher query first using the prompt\n",
    "#         generated_query = cypher_generation_prompt.format(\n",
    "#             schema=graph.schema,  # Ensure dynamic schema usage\n",
    "#             question=question,\n",
    "#             example=example\n",
    "#         )\n",
    "#         # Run the chain with the generated query\n",
    "#         result = chain.run(query=generated_query, question=question)\n",
    "        \n",
    "#         # Restore original stdout and get the captured output\n",
    "#         sys.stdout = original_stdout\n",
    "#         output = output_buffer.getvalue()\n",
    "        \n",
    "#         # Extract Cypher query and context from the captured output\n",
    "#         cypher_query = None\n",
    "#         full_context = None\n",
    "        \n",
    "#         if 'Generated Cypher:' in output:\n",
    "#             cypher_query = output.split('Generated Cypher:')[1].split('Full Context:')[0].strip()\n",
    "#             cypher_query = clean_ansi(cypher_query)\n",
    "        \n",
    "#         if 'Full Context:' in output:\n",
    "#             full_context = output.split('Full Context:')[1].split('>')[0].strip()\n",
    "#             full_context = clean_ansi(full_context)\n",
    "        \n",
    "#         print(f\"Q: {question}\")\n",
    "#         print(f\"A: {result}\\n\")\n",
    "        \n",
    "#         return {\n",
    "#             'result': result,\n",
    "#             'cypher_query': cypher_query,\n",
    "#             'full_context': full_context\n",
    "#         }\n",
    "#     except Exception as e:\n",
    "#         print(f\"Error: {str(e)}\")\n",
    "#         return {\n",
    "#             'result': None,\n",
    "#             'cypher_query': None,\n",
    "#             'full_context': None,\n",
    "#             'error': str(e)\n",
    "#         }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# response = test_query(\"How many users rated 'Jungle Book, The'?\")\n",
    "# print(f\"Cypher Query: {response['cypher_query']}\")\n",
    "# print(f\"Full Context: {response['full_context']}\")\n",
    "# print(f\"Result: {response['result']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hugging face Lamma "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from huggingface_hub import login\n",
    "# login(token=hugging_face_api)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import pipeline, AutoTokenizer, AutoModelForCausalLM\n",
    "# from langchain.llms import HuggingFacePipeline\n",
    "\n",
    "# # Load tokenizer and model\n",
    "# model_name = \"meta-llama/Llama-2-7b-chat-hf\"\n",
    "# cache_dir = \"./HF_models\"\n",
    "\n",
    "# tokenizer = AutoTokenizer.from_pretrained(model_name, cache_dir=cache_dir)\n",
    "# model = AutoModelForCausalLM.from_pretrained(model_name, cache_dir=cache_dir)\n",
    "\n",
    "# # Create a text generation pipeline for Hugging Face\n",
    "# pipeline_model = pipeline(\n",
    "#     \"text-generation\",\n",
    "#     model=model,\n",
    "#     tokenizer=tokenizer,\n",
    "#     device_map=\"auto\",\n",
    "#     max_new_tokens=256,\n",
    "#     temperature=0.1,\n",
    "#     top_k=40,\n",
    "#     top_p=0.95,\n",
    "# )\n",
    "\n",
    "# # Wrap pipeline in HuggingFacePipeline, which is Runnable-compatible\n",
    "# llm = HuggingFacePipeline(pipeline=pipeline_model)\n",
    "\n",
    "# # Define the chain with Hugging Face LLM\n",
    "# chain = GraphCypherQAChain.from_llm(\n",
    "#     llm=llm,\n",
    "#     graph=graph,  # Your Neo4j graph object\n",
    "#     verbose=True,\n",
    "#     cypher_generation_prompt=cypher_generation_prompt,\n",
    "#     qa_prompt=qa_prompt,\n",
    "#     allow_dangerous_requests=ALLOW_DANGEROUS_REQUEST,\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# response = test_query(\"How many users rated 'Jungle Book, The'?\")\n",
    "# print(f\"Cypher Query: {response['cypher_query']}\")\n",
    "# print(f\"Full Context: {response['full_context']}\")\n",
    "# print(f\"Result: {response['result']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain.llms import OpenAI\n",
    "\n",
    "# # Initialize the OpenAI model with your stored API key\n",
    "# llm = OpenAI(\n",
    "#     model=\"gpt-3.5-turbo\",  # Choose the model, e.g., \"gpt-3.5-turbo\" or \"gpt-4\"\n",
    "#     temperature=0.1,\n",
    "#     max_tokens=256,\n",
    "#     openai_api_key=gpt_api  # Pass your API key directly\n",
    "# )\n",
    "\n",
    "# # Define the chain with the OpenAI LLM\n",
    "# chain = GraphCypherQAChain.from_llm(\n",
    "#     llm=llm,\n",
    "#     graph=graph,  # Your Neo4j graph object\n",
    "#     verbose=True,\n",
    "#     cypher_generation_prompt=cypher_generation_prompt,\n",
    "#     qa_prompt=qa_prompt,\n",
    "#     allow_dangerous_requests=ALLOW_DANGEROUS_REQUEST,\n",
    "# )\n",
    "# response = test_query(\"How many users rated 'Jungle Book, The'?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GPT-3.5 Turbo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/hc/dq1y9hzx51s30kq78z6v4jsm0000gp/T/ipykernel_2949/4195536157.py:4: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import ChatOpenAI``.\n",
      "  llm = ChatOpenAI(\n"
     ]
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "# Initialize the ChatOpenAI model with your stored API key\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-3.5-turbo\",  # or \"gpt-4\"\n",
    "    temperature=0.1,\n",
    "    max_tokens=256,\n",
    "    openai_api_key=gpt_api  # Pass your API key directly\n",
    ")\n",
    "ALLOW_DANGEROUS_REQUEST = True\n",
    "\n",
    "# Define the chain with the ChatOpenAI LLM\n",
    "chain = GraphCypherQAChain.from_llm(\n",
    "    llm=llm,\n",
    "    graph=graph,  # Your Neo4j graph object\n",
    "    verbose=True,\n",
    "    cypher_generation_prompt=cypher_generation_prompt,\n",
    "    qa_prompt=qa_prompt,\n",
    "    allow_dangerous_requests=ALLOW_DANGEROUS_REQUEST,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import sys\n",
    "import re\n",
    "\n",
    "def clean_ansi(text):\n",
    "    # Remove ANSI escape codes\n",
    "    ansi_escape = re.compile(r'\\x1B(?:[@-Z\\\\-_]|\\[[0-?]*[ -/]*[@-~])')\n",
    "    return ansi_escape.sub('', text).strip()\n",
    "\n",
    "def test_query(question):\n",
    "    try:\n",
    "        # Create a string buffer to capture the output\n",
    "        output_buffer = io.StringIO()\n",
    "        original_stdout = sys.stdout\n",
    "        # sys.stdout = output_buffer\n",
    "\n",
    "        # Explicitly generate the Cypher query first using the prompt\n",
    "        generated_query = cypher_generation_prompt.format(\n",
    "            schema=graph.schema,  # Ensure dynamic schema usage\n",
    "            question=question,\n",
    "            example=example\n",
    "        )\n",
    "        # Run the chain with the generated query\n",
    "        result = chain.run(query=generated_query, question=question)\n",
    "        \n",
    "        # Restore original stdout and get the captured output\n",
    "        sys.stdout = original_stdout\n",
    "        output = output_buffer.getvalue()\n",
    "        \n",
    "        # Extract Cypher query and context from the captured output\n",
    "        cypher_query = None\n",
    "        full_context = None\n",
    "        \n",
    "        if 'Generated Cypher:' in output:\n",
    "            cypher_query = output.split('Generated Cypher:')[1].split('Full Context:')[0].strip()\n",
    "            cypher_query = clean_ansi(cypher_query)\n",
    "        \n",
    "        if 'Full Context:' in output:\n",
    "            full_context = output.split('Full Context:')[1].split('>')[0].strip()\n",
    "            full_context = clean_ansi(full_context)\n",
    "        \n",
    "        print(f\"Q: {question}\")\n",
    "        print(f\"A: {result}\\n\")\n",
    "        \n",
    "        return {\n",
    "            'result': result,\n",
    "            'cypher_query': cypher_query,\n",
    "            'full_context': full_context\n",
    "        }\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {str(e)}\")\n",
    "        return {\n",
    "            'result': None,\n",
    "            'cypher_query': None,\n",
    "            'full_context': None,\n",
    "            'error': str(e)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/hc/dq1y9hzx51s30kq78z6v4jsm0000gp/T/ipykernel_2949/31340994.py:24: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  result = chain.run(query=generated_query, question=question)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new GraphCypherQAChain chain...\u001b[0m\n",
      "Generated Cypher:\n",
      "\u001b[32;1m\u001b[1;3mMATCH (a:Author {name: 'Han Xiao'})-[:AUTHORED]->(p:Paper)\n",
      "RETURN p.title\u001b[0m\n",
      "Full Context:\n",
      "\u001b[32;1m\u001b[1;3m[{'p.title': 'Fashion-MNIST: a Novel Image Dataset for Benchmarking Machine Learning Algorithms'}]\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Q: List all papers authored by 'Han Xiao'.\n",
      "A: The paper authored by Han Xiao is \"Fashion-MNIST: a Novel Image Dataset for Benchmarking Machine Learning Algorithms\".\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# response = test_query(\"How many users rated 'Jungle Book, The'?\")\n",
    "response = test_query(\"List all papers authored by 'Han Xiao'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Anthropic Haruku"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import anthropic\n",
    "# from langchain.llms import Anthropic\n",
    "\n",
    "# # Define a custom function to count tokens\n",
    "# def count_tokens(text):\n",
    "#     return len(text.split())\n",
    "\n",
    "# # Extend the Anthropic model to include count_tokens\n",
    "# class AnthropicWithTokenCount(Anthropic):\n",
    "#     def count_tokens(self, text):\n",
    "#         return count_tokens(text)\n",
    "\n",
    "# # Initialize the custom Anthropic model\n",
    "# llm = AnthropicWithTokenCount(\n",
    "#     model=\"claude-2\",  # Specify the model, e.g., \"claude-2\"\n",
    "#     anthropic_api_key=anthropic_api,\n",
    "#     temperature=0.1,\n",
    "#     max_tokens_to_sample=256,\n",
    "# )\n",
    "\n",
    "# # Define the chain with the custom Anthropic model\n",
    "# chain = GraphCypherQAChain.from_llm(\n",
    "#     llm=llm,\n",
    "#     graph=graph,  # Your Neo4j graph object\n",
    "#     verbose=True,\n",
    "#     cypher_generation_prompt=cypher_generation_prompt,\n",
    "#     qa_prompt=qa_prompt,\n",
    "#     allow_dangerous_requests=ALLOW_DANGEROUS_REQUEST,\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_SET = [\n",
    "    {\n",
    "        \"question\": \"What are the genres of 'Star Wars: Episode IV - A New Hope'?\",\n",
    "        \"query\": \"MATCH (m:Movie {title: 'Star Wars: Episode IV - A New Hope'})-[:HAS_GENRE]->(g:Genre) RETURN g.name AS Genres\",\n",
    "        \"answer\": \"The genres of 'Star Wars: Episode IV - A New Hope' are 'Sci-Fi', 'Action', and 'Adventure'.\",\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"How many users rated 'Jungle Book, The'?\",\n",
    "        \"query\": \"MATCH (m:Movie {title: 'Jungle Book, The'})<-[:RATED]-(u:User) RETURN COUNT(u) AS NumberOfUsersWhoRatedJungleBook\",\n",
    "        \"answer\": \"2 users rated 'Jungle Book, The'.\",\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"I like the movie 'Dumb & Dumber (Dumb and Dumber)'. Give me 5 movies similar to this one with their genres.\",\n",
    "        \"query\": \"MATCH (m:Movie {title: 'Dumb & Dumber (Dumb and Dumber)'})-[:HAS_GENRE]->(g:Genre) WITH g MATCH (other:Movie)-[:HAS_GENRE]->(g) WHERE other.title <> 'InceptDumb & Dumber (Dumb and Dumber)ion' WITH other, COLLECT(g.name) AS genres, COUNT(g) AS genreCount ORDER BY genreCount DESC RETURN other.title AS Movie, genres AS Genres LIMIT 5\",\n",
    "        \"answer\": \"Based on your preference for 'Dumb & Dumber (Dumb and Dumber)', here are 5 similar movies you might enjoy: 'Batman Forever', 'True Lies', 'City Slickers II: The Legend of Curly's Gold', 'Coneheads', and 'Bullets Over Broadway'. These movies share the genres of Comedy and Adventure.\",\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"What are the ratings for 'Taxi Driver'?\",\n",
    "        \"query\": \"MATCH (m:Movie {title: 'Taxi Driver'})<-[r:RATED]-(u:User) RETURN  r.rating AS Rating\",\n",
    "        \"answer\": \"The ratings for 'Taxi Driver' are 5.0.\",\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"Find all movies released in 1993.\",\n",
    "        \"query\": \"MATCH (m:Movie) WHERE m.year = 1993 RETURN m.title AS MoviesReleasedIn1993\",\n",
    "        \"answer\": \"The movies released in 1993 are 'Three Colors: Blue (Trois couleurs: Bleu)', 'Firm, The', 'Fugitive, The', 'Hot Shots! Part Deux', 'Mrs. Doubtfire', 'Whats Eating Gilbert Grape', 'Cliffhanger', 'Demolition Man', 'Jurassic Park', 'Addams Family Values', 'Coneheads', and 'Dave'\",\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"What is the average rating for 'Pulp Fiction'?\",\n",
    "        \"query\": \"MATCH (m:Movie {title: 'Pulp Fiction'})<-[r:RATED]-(u:User) RETURN AVG(r.rating) AS AverageRating\",\n",
    "        \"answer\": \"The average rating for 'Pulp Fiction' is 2.875.\",\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"Find all movies that are both 'Action' and 'Thriller'.\",\n",
    "        \"query\": \"MATCH (m:Movie)-[:HAS_GENRE]->(g:Genre) WHERE g.name IN ['Action', 'Thriller'] WITH m, COLLECT(g.name) AS genres WHERE 'Action' IN genres AND 'Thriller' IN genres RETURN m.title AS MoviesThatAreActionAndThriller\",\n",
    "        \"answer\": \"The movies which are both Action and Thriller are 'Outbreak', 'Natural Born Killers', 'Die Hard: With a Vengeance', 'Jurassic Park', 'Cliffhanger', 'GoldenEye', 'True Lies', 'Speed', 'Clear and Present Danger'  and 'Net, The'.\",\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"List all users who rated movies in the 'Horror' genre.\",\n",
    "        \"query\": \"MATCH (m:Movie)-[:HAS_GENRE]->(g:Genre {name: 'Horror'}) OPTIONAL MATCH (u:User)-[:RATED]->(m) RETURN DISTINCT u.userId as users LIMIT 10\",\n",
    "        \"answer\": \"User 2 and 5 rated Horror movies.\",\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"What is the highest rated movie released before 2000?\",\n",
    "        \"query\": \"MATCH (m:Movie)<-[r:RATED]-(u:User) WHERE m.year < 2000 RETURN m.title AS HighestRatedMovie, AVG(r.rating) AS AverageRating ORDER BY AverageRating DESC LIMIT 1\",\n",
    "        \"answer\": \"Height rated movie resleased before 2000 is Shanghai Triad (Yao a yao yao dao waipo qiao).\",\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"Find movies with 'Love' in the title.\",\n",
    "        \"query\": \"MATCH (m:Movie) WHERE m.title CONTAINS 'Love' RETURN m.title AS MoviesWithLoveInTitle\",\n",
    "        \"answer\": \"The movie that have love in title is 'When a Man Loves a Woman'.\",\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"How many movies are in the 'Fantasy' genre?\",\n",
    "        \"query\": \"MATCH (m:Movie)-[:HAS_GENRE]->(g:Genre {name: 'Fantasy'}) RETURN COUNT(m) AS FantasyMovieCount\",\n",
    "        \"answer\": \"There are 5 movies in the 'Fantasy' genre.\",\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"What movies did user 2 rate?\",\n",
    "        \"query\": \"MATCH (u:User {userId: 2})-[r:RATED]->(m:Movie) RETURN m.title AS MoviesRatedByUser2\",\n",
    "        \"answer\": \"User 2 rated 'Mrs. Doubtfire','Hot Shots! Part Deux','Fugitive, The','Firm, The','When a Man Loves a Woman','True Lies','Speed','Lion King, The','Jungle Book, The','Four Weddings and a Funeral','Forrest Gump','Client, The','Clear and Present Danger','Ace Ventura: Pet Detective','While You Were Sleeping','Shawshank Redemption, The','Ready to Wear (Pret-A-Porter)','Pulp Fiction','Nell','Milk Money','Interview with the Vampire: The Vampire Chronicles','Forget Paris','French Kiss','Dumb & Dumber (Dumb and Dumber)','Disclosure','Circle of Friends','Boys on the Side','Billy Madison','Walk in the Clouds, A','Showgirls','Nine Months','Net, The','Batman Forever','Pocahontas','Clueless','Babe' and 'Dangerous Minds'.\",\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"List users who rated movies released in 1994.\",\n",
    "        \"query\": \"MATCH (m:Movie)<-[r:RATED]-(u:User) WHERE m.year = 1994 RETURN DISTINCT u.userId AS UsersWhoRatedMoviesIn1994\",\n",
    "        \"answer\": \"Users who rated movies released in 1994 include User 1, User 2, User 3, User 4, User 5, User 7 and User 8.\",\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"What are the genres of 'The Lion King'?\",\n",
    "        \"query\": \"MATCH (m:Movie {title: 'Lion King, The'})-[:HAS_GENRE]->(g:Genre) RETURN g.name AS Genres\",\n",
    "        \"answer\": \"'Lion King, The' is a movie in the 'Adventure', 'Animation', 'Children', 'Drama', 'Musical' and 'IMAX' genres.\",\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"I liked the movie 'French Kiss'. What are 5 similar movies I should watch?\",\n",
    "        \"query\": \"MATCH (m:Movie {title: 'French Kiss'})-[:HAS_GENRE]->(g:Genre) WITH g MATCH (other:Movie)-[:HAS_GENRE]->(g) WHERE other.title <> 'French Kiss' WITH other, collect(g.name) as genres, COUNT(g) as genreCount ORDER BY genreCount DESC RETURN other.title as Movie, genres as Genres LIMIT 5\",\n",
    "        \"answer\": \"Based on your preference for 'Dead Man Walking', here are 5 similar movies you might enjoy: 'True Lies','Englishman Who Went Up a Hill But Came Down a Mountain, The','First Knight','Rob Roy','Dave'.\",\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"What movies have the most shared genres with 'Milk Money'?\",\n",
    "        \"query\": \"MATCH (m:Movie {title: 'Milk Money'})-[:HAS_GENRE]->(g:Genre)<-[:HAS_GENRE]-(similar:Movie) WHERE m <> similar RETURN similar.title AS SimilarMovies, COUNT(g) AS SharedGenres ORDER BY SharedGenres DESC LIMIT 5\",\n",
    "        \"answer\": \"Five movies that have the same genres as 'Milk Money' are 'Englishman Who Went Up a Hill But Came Down a Mountain, The','Dave','Like Water for Chocolate (Como agua para chocolate)','First Knight', and 'Rob Roy'.\",\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"Find all movies rated above 4 and rated by atlead 2 user.\",\n",
    "        \"query\": \"MATCH (m:Movie)<-[r:RATED]-(u:User) WHERE r.rating = 4 WITH m, COUNT(r) AS ratingCount, AVG(r.rating) AS averageRating WHERE ratingCount > 2 RETURN m.title AS HighRatedMovies, averageRating\",\n",
    "        \"answer\": \"The movie that has rating above 4 and rated by at least 2 users are 'Firm, The', 'Four Weddings and a Funeral' and 'Clear and Present Danger'.\",\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"How many users rated 'Dangerous Minds'?\",\n",
    "        \"query\": \"MATCH (m:Movie {title: 'Dangerous Minds'})<-[:RATED]-(u:User) RETURN COUNT(u) AS NumberOfUsersWhoRatedDarkKnight\",\n",
    "        \"answer\": \"1 users rated 'Dangerous Minds'\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"I like 'Adventure' and 'Fantasy' genres. What movies should I watch next?\",\n",
    "        \"query\": \"MATCH (m:Movie)-[:HAS_GENRE]->(g:Genre) WHERE g.name IN ['Adventure', 'Fantasy'] RETURN DISTINCT m.title AS RecommendedMovies LIMIT 5\",\n",
    "        \"answer\": \"Based on your preferences for 'Adventure' and 'Fantasy', you might enjoy watching 'City Slickers II: The Legend of Curly's Gold', 'Jurassic Park', 'Demolition Man', 'Cliffhanger' and 'Star Trek: Generations'.\"\n",
    "    },\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_SET = [\n",
    "    {\n",
    "        \"question\": \"List the titles of papers authored by 'Jianmin Chen' in 2016?\",\n",
    "        \"query\": \"\",\n",
    "        \"answer\": \"Jianmin Chen authored the paper 'TensorFlow: A system for large-scale machine learning' in 2016.\",\n",
    "        \"DF\": \"\",\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"What are the most cited papers in 'Physics'?\",\n",
    "        \"query\": \"\",\n",
    "        \"answer\": \"\",\n",
    "        \"DF\": \"scholar_data[scholar_data.Discipline == 'Physics'][['Paper Title', 'Citations']].drop_duplicates().sort_values(by='Citations', ascending=False).head(5)\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"Which authors have worked on the 'Network Science' topic?\",\n",
    "        \"query\": \"\",\n",
    "        \"answer\": \"\",\n",
    "        \"DF\": \"scholar_data[scholar_data.Topic == 'Network Science']['Author'].drop_duplicates().head(5)\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"What venues have published papers in 'Environmental Science' Discipline?\",\n",
    "        \"query\": \"\",\n",
    "        \"answer\": \"\",\n",
    "        \"DF\": \"scholar_data[scholar_data.Discipline == 'Environmental Science']['Venue'].drop_duplicates().head(5)\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"How many papers authored by 'Roland Vollgraf'?\",\n",
    "        \"query\": \"\",\n",
    "        \"answer\": \"\",\n",
    "        \"DF\": \"scholar_data[scholar_data.Author == 'Roland Vollgraf']['Paper Title'].drop_duplicates().shape[0]\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"I am 'Kashif Rasul'. Which researchers I collaborated with before?\",\n",
    "        \"query\": \"\",\n",
    "        \"answer\": \"Kashif Rasul has collaborated with Han Xiao and Roland Vollgraf.\",\n",
    "        \"DF\": \"\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"I am 'Kashif Rasul'. Which professors should I collaborate with for future work?\",\n",
    "        \"query\": \"\",\n",
    "        \"answer\": \"Kashif Rasul could collaborate with Vijay Vasudevan, Pete Warden, M. Wicke, Yuan Yu, Ashish Agarwal, E. Brevdo, C. Citro, G. Corrado, I. Goodfellow, and A. Harp.\",\n",
    "        \"GT_NDCG\": [\"Vijay Vasudevan\", \"Pete Warden\", \"M. Wicke\", \"Yuan Yu\", \"Ashish Agarwal\", \"E. Brevdo\", \"C. Citro\", \"G. Corrado\", \"I. Goodfellow\", \"A. Harp\"],\n",
    "        \"DF\": \"\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"List all papers published in 'Biology' before 2015\",\n",
    "        \"query\": \"\",\n",
    "        \"answer\": \"\",\n",
    "        \"DF\": \"scholar_data[(scholar_data.Discipline == 'Biology') & (scholar_data['Year Published'] < 2015)]['Paper Title'].drop_duplicates().to_list()\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"Find the authors who have contributed to papers in 'Chemistry' and 'Materials Science'\",\n",
    "        \"query\": \"\",\n",
    "        \"answer\": \"\",\n",
    "        \"DF\": \"scholar_data[scholar_data.Discipline.isin(['Chemistry', 'Materials Science'])]['Author'].drop_duplicates().head(5).to_list()\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"Which papers were published in the 'Medicine' discipline in venues of type 'Journal'?\",\n",
    "        \"query\": \"\",\n",
    "        \"answer\": \"\",\n",
    "        \"DF\": \"scholar_data[(scholar_data.Discipline == 'Medicine') & (scholar_data['Venue Type'] == 'Journal')]['Paper Title'].drop_duplicates().to_list()\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"List papers with 'Machine Learning' as the topic and citations greater than 5000.\",\n",
    "        \"query\": \"\",\n",
    "        \"answer\": \"\",\n",
    "        \"DF\": \"scholar_data[(scholar_data.Topic == 'Machine Learning') & (scholar_data.Citations > 5000)]['Paper Title'].drop_duplicates().head().to_list()\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"What are the venues where 'Jianmin Chen' has published papers\",\n",
    "        \"query\": \"\",\n",
    "        \"answer\": \"\",\n",
    "        \"DF\": \"scholar_data[scholar_data['Author'] == 'Jianmin Chen']['Venue'].drop_duplicates().to_list()\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"What are the papers authored by 'Roland Vollgraf' in 'Machine Learning'?\",\n",
    "        \"query\": \"\",\n",
    "        \"answer\": \"\",\n",
    "        \"DF\": \"scholar_data[(scholar_data['Author'] == 'Roland Vollgraf') & (scholar_data['Topic'] == 'Machine Learning')]['Paper Title'].drop_duplicates().tolist()\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"Which authors have worked in both 'Computer Science' and 'Mathematics'?\",\n",
    "        \"query\": \"\",\n",
    "        \"answer\": \"\",\n",
    "        \"DF\": \"cs_authors = scholar_data[scholar_data['Discipline'] == 'Computer Science']['Author'] / math_authors = scholar_data[scholar_data['Discipline'] == 'Mathematics']['Author']/ cs_authors[cs_authors.isin(math_authors)].drop_duplicates().to_list()[:5]\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"Which authors have published in 'Materials Science' and the venue 'Nature'?\",\n",
    "        \"query\": \"\",\n",
    "        \"answer\": \"\",\n",
    "        \"DF\": \"scholar_data[(scholar_data['Discipline'] == 'Materials Science') & (scholar_data['Venue'] == 'Nature')]['Author'].drop_duplicates().to_list()\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"What are the least cited papers in the discipline 'Psychology'?\",\n",
    "        \"query\": \"\",\n",
    "        \"answer\": \"\",\n",
    "        \"DF\": \"scholar_data[scholar_data['Discipline'] == 'Psychology'][['Paper Title', 'Citations']].sort_values(by='Citations').drop_duplicates()['Paper Title'].to_list()\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"what are the top venues for papers on 'Network Science'?\",\n",
    "        \"query\": \"\",\n",
    "        \"answer\": \"\",\n",
    "        \"DF\": \"scholar_data[scholar_data['Topic'] == 'Network Science']['Venue'].value_counts().index.tolist()[:5]\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"Which authors published papers in 'Medicine' after 2015?\",\n",
    "        \"query\": \"\",\n",
    "        \"answer\": \"\",\n",
    "        \"DF\": \"scholar_data[(scholar_data['Discipline'] == 'Medicine') & (scholar_data['Year Published'] > 2015)]['Author'].to_list()[:5]\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"which authors have collaborated with 'D. Davies' on papers in 'Chemistry'?\",\n",
    "        \"query\": \"\",\n",
    "        \"answer\": \"\",\n",
    "        \"DF\": \"z_chen_papers = scholar_data[(scholar_data['Author'] == 'D. Davies') & (scholar_data['Discipline'] == 'Chemistry')]['Paper Title']/scholar_data[scholar_data['Paper Title'].isin(z_chen_papers) & (scholar_data['Author'] != 'Z. Chen')]['Author'].drop_duplicates().to_list()\"\n",
    "    }\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of test cases:  19\n"
     ]
    }
   ],
   "source": [
    "print(\"number of test cases: \", len(TEST_SET))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new GraphCypherQAChain chain...\u001b[0m\n",
      "Generated Cypher:\n",
      "\u001b[32;1m\u001b[1;3mMATCH (a:Author {name: 'Jianmin Chen'})-[:AUTHORED]->(p:Paper {year: 2016})\n",
      "RETURN p.title;\u001b[0m\n",
      "Full Context:\n",
      "\u001b[32;1m\u001b[1;3m[{'p.title': 'TensorFlow: A system for large-scale machine learning'}]\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Q: List the titles of papers authored by 'Jianmin Chen' in 2016?\n",
      "A: The paper authored by Jianmin Chen in 2016 is \"TensorFlow: A system for large-scale machine learning\".\n",
      "\n",
      "Answer: Jianmin Chen authored the paper 'TensorFlow: A system for large-scale machine learning' in 2016.\n",
      "-------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new GraphCypherQAChain chain...\u001b[0m\n",
      "Generated Cypher:\n",
      "\u001b[32;1m\u001b[1;3mMATCH (p:Paper)-[:BELONGS_TO]->(:Discipline{name:'Physics'})\n",
      "RETURN p.title, p.citations\n",
      "ORDER BY p.citations DESC\u001b[0m\n",
      "Full Context:\n",
      "\u001b[32;1m\u001b[1;3m[{'p.title': 'Machine Learning for Fluid Mechanics', 'p.citations': 1830}, {'p.title': 'MoleculeNet: a benchmark for molecular machine learning', 'p.citations': 1557}, {'p.title': 'Machine learning and the physical sciences', 'p.citations': 1381}, {'p.title': 'Machine learning–accelerated computational fluid dynamics', 'p.citations': 698}, {'p.title': 'Power of data in quantum machine learning', 'p.citations': 510}, {'p.title': 'Challenges and opportunities in quantum machine learning', 'p.citations': 279}, {'p.title': 'NetSci High: Bringing Network Science Research to High Schools', 'p.citations': 19}, {'p.title': 'Topics in social network analysis and network science', 'p.citations': 12}]\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Q: What are the most cited papers in 'Physics'?\n",
      "A: The most cited papers in 'Physics' are:\n",
      "- \"Machine Learning for Fluid Mechanics\" with 1830 citations\n",
      "- \"MoleculeNet: a benchmark for molecular machine learning\" with 1557 citations\n",
      "- \"Machine learning and the physical sciences\" with 1381 citations\n",
      "- \"Machine learning–accelerated computational fluid dynamics\" with 698 citations\n",
      "- \"Power of data in quantum machine learning\" with 510 citations\n",
      "- \"Challenges and opportunities in quantum machine learning\" with 279 citations\n",
      "- \"NetSci High: Bringing Network Science Research to High Schools\" with 19 citations\n",
      "- \"Topics in social network analysis and network science\" with 12 citations\n",
      "\n",
      "Answer: \n",
      "-------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new GraphCypherQAChain chain...\u001b[0m\n",
      "Generated Cypher:\n",
      "\u001b[32;1m\u001b[1;3mMATCH (a:Author)-[:AUTHORED]->(:Paper {topic: 'Network Science'})\n",
      "RETURN a.name;\u001b[0m\n",
      "Full Context:\n",
      "\u001b[32;1m\u001b[1;3m[{'a.name': 'Robin W. Wilkins'}, {'a.name': 'D. Hodges'}, {'a.name': 'P. Laurienti'}, {'a.name': 'M. Steen'}, {'a.name': 'J. Burdette'}, {'a.name': 'Wilkins'}, {'a.name': 'T. Tiropanis'}, {'a.name': 'W. Hall'}, {'a.name': 'J. Crowcroft'}, {'a.name': 'N. Contractor'}]\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Q: Which authors have worked on the 'Network Science' topic?\n",
      "A: Authors who have worked on the 'Network Science' topic include Robin W. Wilkins, D. Hodges, P. Laurienti, M. Steen, J. Burdette, Wilkins, T. Tiropanis, W. Hall, J. Crowcroft, and N. Contractor.\n",
      "\n",
      "Answer: \n",
      "-------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new GraphCypherQAChain chain...\u001b[0m\n",
      "Generated Cypher:\n",
      "\u001b[32;1m\u001b[1;3mMATCH (p:Paper)-[:BELONGS_TO]->(:Discipline{name:'Environmental Science'})-[:PUBLISHED_IN]->(v:Venue)\n",
      "RETURN DISTINCT v.name;\u001b[0m\n",
      "Full Context:\n",
      "\u001b[32;1m\u001b[1;3m[]\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Q: What venues have published papers in 'Environmental Science' Discipline?\n",
      "A: There are no venues that have published papers in the 'Environmental Science' discipline.\n",
      "\n",
      "Answer: \n",
      "-------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new GraphCypherQAChain chain...\u001b[0m\n",
      "Generated Cypher:\n",
      "\u001b[32;1m\u001b[1;3mMATCH (a:Author {name: 'Roland Vollgraf'})-[:AUTHORED]->(p:Paper)\n",
      "RETURN COUNT(p)\u001b[0m\n",
      "Full Context:\n",
      "\u001b[32;1m\u001b[1;3m[{'COUNT(p)': 1}]\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Q: How many papers authored by 'Roland Vollgraf'?\n",
      "A: Roland Vollgraf authored 1 paper.\n",
      "\n",
      "Answer: \n",
      "-------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new GraphCypherQAChain chain...\u001b[0m\n",
      "Generated Cypher:\n",
      "\u001b[32;1m\u001b[1;3mMATCH (a:Author {name: 'Kashif Rasul'})-[:AUTHORED]->(p:Paper)<-[:AUTHORED]-(collaborator:Author)\n",
      "RETURN collaborator.name\u001b[0m\n",
      "Full Context:\n",
      "\u001b[32;1m\u001b[1;3m[{'collaborator.name': 'Han Xiao'}, {'collaborator.name': 'Roland Vollgraf'}]\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Q: I am 'Kashif Rasul'. Which researchers I collaborated with before?\n",
      "A: You have collaborated with Han Xiao and Roland Vollgraf before.\n",
      "\n",
      "Answer: Kashif Rasul has collaborated with Han Xiao and Roland Vollgraf.\n",
      "-------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new GraphCypherQAChain chain...\u001b[0m\n",
      "Generated Cypher:\n",
      "\u001b[32;1m\u001b[1;3mMATCH (a:Author {name: 'Kashif Rasul'})-[:AUTHORED]->(:Paper)-[:BELONGS_TO]->(:Discipline)<-[:BELONGS_TO]-(:Paper)<-[:AUTHORED]-(p:Author)\n",
      "RETURN DISTINCT p.name\u001b[0m\n",
      "Full Context:\n",
      "\u001b[32;1m\u001b[1;3m[{'p.name': 'Martín Abadi'}, {'p.name': 'P. Barham'}, {'p.name': 'Jianmin Chen'}, {'p.name': 'Z. Chen'}, {'p.name': 'Andy Davis'}, {'p.name': 'J. Dean'}, {'p.name': 'M. Devin'}, {'p.name': 'Sanjay Ghemawat'}, {'p.name': 'G. Irving'}, {'p.name': 'M. Isard'}]\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Q: I am 'Kashif Rasul'. Which professors should I collaborate with for future work?\n",
      "A: You should collaborate with Martín Abadi, P. Barham, Jianmin Chen, Z. Chen, Andy Davis, J. Dean, M. Devin, Sanjay Ghemawat, G. Irving, and M. Isard for future work.\n",
      "\n",
      "Answer: Kashif Rasul could collaborate with Vijay Vasudevan, Pete Warden, M. Wicke, Yuan Yu, Ashish Agarwal, E. Brevdo, C. Citro, G. Corrado, I. Goodfellow, and A. Harp.\n",
      "-------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new GraphCypherQAChain chain...\u001b[0m\n",
      "Generated Cypher:\n",
      "\u001b[32;1m\u001b[1;3mMATCH (p:Paper)-[:BELONGS_TO]->(:Discipline{name:'Biology'})-[:PUBLISHED_IN]->(:Venue)\n",
      "WHERE p.year < 2015\n",
      "RETURN p.title, p.year\u001b[0m\n",
      "Full Context:\n",
      "\u001b[32;1m\u001b[1;3m[]\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Q: List all papers published in 'Biology' before 2015\n",
      "A: There are no papers published in 'Biology' before 2015.\n",
      "\n",
      "Answer: \n",
      "-------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new GraphCypherQAChain chain...\u001b[0m\n",
      "Generated Cypher:\n",
      "\u001b[32;1m\u001b[1;3mMATCH (a:Author)-[:AUTHORED]->(:Paper)-[:BELONGS_TO]->(d:Discipline)\n",
      "WHERE d.name IN ['Chemistry', 'Materials Science']\n",
      "RETURN DISTINCT a.name\u001b[0m\n",
      "Full Context:\n",
      "\u001b[32;1m\u001b[1;3m[{'a.name': 'K. Butler'}, {'a.name': 'D. Davies'}, {'a.name': 'H. Cartwright'}, {'a.name': 'O. Isayev'}, {'a.name': 'A. Walsh'}]\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Q: Find the authors who have contributed to papers in 'Chemistry' and 'Materials Science'\n",
      "A: The authors who have contributed to papers in both 'Chemistry' and 'Materials Science' are K. Butler, D. Davies, H. Cartwright, O. Isayev, and A. Walsh.\n",
      "\n",
      "Answer: \n",
      "-------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new GraphCypherQAChain chain...\u001b[0m\n",
      "Generated Cypher:\n",
      "\u001b[32;1m\u001b[1;3mMATCH (p:Paper)-[:BELONGS_TO]->(:Discipline{name:'Medicine'})-[:PUBLISHED_IN]->(:Venue{name:'Journal'})\n",
      "RETURN p.title\u001b[0m\n",
      "Full Context:\n",
      "\u001b[32;1m\u001b[1;3m[]\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Q: Which papers were published in the 'Medicine' discipline in venues of type 'Journal'?\n",
      "A: There are no papers that were published in the 'Medicine' discipline in venues of type 'Journal'.\n",
      "\n",
      "Answer: \n",
      "-------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new GraphCypherQAChain chain...\u001b[0m\n",
      "Generated Cypher:\n",
      "\u001b[32;1m\u001b[1;3mMATCH (p:Paper)\n",
      "WHERE p.topic = 'Machine Learning' AND p.citations > 5000\n",
      "RETURN p.title, p.citations, p.year\u001b[0m\n",
      "Full Context:\n",
      "\u001b[32;1m\u001b[1;3m[{'p.title': 'Fashion-MNIST: a Novel Image Dataset for Benchmarking Machine Learning Algorithms', 'p.citations': 8026, 'p.year': 2017.0}, {'p.title': 'TensorFlow: A system for large-scale machine learning', 'p.citations': 17652, 'p.year': 2016.0}, {'p.title': 'TensorFlow: Large-Scale Machine Learning on Heterogeneous Distributed Systems', 'p.citations': 10819, 'p.year': 2016.0}, {'p.title': 'Stop explaining black box machine learning models for high stakes decisions and use interpretable models instead', 'p.citations': 5152, 'p.year': 2018.0}, {'p.title': 'Convolutional LSTM Network: A Machine Learning Approach for Precipitation Nowcasting', 'p.citations': 7266, 'p.year': 2015.0}, {'p.title': 'Machine learning: Trends, perspectives, and prospects', 'p.citations': 5899, 'p.year': 2015.0}, {'p.title': 'Machine learning - a probabilistic perspective', 'p.citations': 9170, 'p.year': 2012.0}, {'p.title': 'Scikit-learn: Machine Learning in Python', 'p.citations': 70499, 'p.year': 2011.0}, {'p.title': 'Gaussian Processes For Machine Learning', 'p.citations': 16596, 'p.year': 2004.0}, {'p.title': 'Practical Bayesian Optimization of Machine Learning Algorithms', 'p.citations': 7340, 'p.year': 2012.0}]\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Q: List papers with 'Machine Learning' as the topic and citations greater than 5000.\n",
      "A: The papers with 'Machine Learning' as the topic and citations greater than 5000 are:\n",
      "1. Fashion-MNIST: a Novel Image Dataset for Benchmarking Machine Learning Algorithms (Citations: 8026, Year: 2017)\n",
      "2. TensorFlow: A system for large-scale machine learning (Citations: 17652, Year: 2016)\n",
      "3. TensorFlow: Large-Scale Machine Learning on Heterogeneous Distributed Systems (Citations: 10819, Year: 2016)\n",
      "4. Stop explaining black box machine learning models for high stakes decisions and use interpretable models instead (Citations: 5152, Year: 2018)\n",
      "5. Convolutional LSTM Network: A Machine Learning Approach for Precipitation Nowcasting (Citations: 7266, Year: 2015)\n",
      "6. Machine learning: Trends, perspectives, and prospects (Citations: 5899, Year: 2015)\n",
      "7. Machine learning - a probabilistic perspective (Citations: 9170, Year: 2012)\n",
      "8. Scikit-learn: Machine Learning in Python (Citations: 70499, Year: 2011)\n",
      "9. Gaussian Processes For Machine Learning (Citations: 16596\n",
      "\n",
      "Answer: \n",
      "-------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new GraphCypherQAChain chain...\u001b[0m\n",
      "Generated Cypher:\n",
      "\u001b[32;1m\u001b[1;3mMATCH (a:Author {name: 'Jianmin Chen'})-[:AUTHORED]->(p:Paper)-[:PUBLISHED_IN]->(v:Venue)\n",
      "RETURN v.name\u001b[0m\n",
      "Full Context:\n",
      "\u001b[32;1m\u001b[1;3m[{'v.name': 'USENIX Symposium on Operating Systems Design and Implementation'}]\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Q: What are the venues where 'Jianmin Chen' has published papers\n",
      "A: Jianmin Chen has published papers in the USENIX Symposium on Operating Systems Design and Implementation venue.\n",
      "\n",
      "Answer: \n",
      "-------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new GraphCypherQAChain chain...\u001b[0m\n",
      "Generated Cypher:\n",
      "\u001b[32;1m\u001b[1;3mMATCH (a:Author {name: 'Roland Vollgraf'})-[:AUTHORED]->(p:Paper)-[:BELONGS_TO]->(:Discipline {name: 'Machine Learning'})\n",
      "RETURN p.title\u001b[0m\n",
      "Full Context:\n",
      "\u001b[32;1m\u001b[1;3m[]\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Q: What are the papers authored by 'Roland Vollgraf' in 'Machine Learning'?\n",
      "A: There are no papers authored by 'Roland Vollgraf' in the 'Machine Learning' topic.\n",
      "\n",
      "Answer: \n",
      "-------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new GraphCypherQAChain chain...\u001b[0m\n",
      "Generated Cypher:\n",
      "\u001b[32;1m\u001b[1;3mMATCH (a:Author)-[:AUTHORED]->(:Paper)-[:BELONGS_TO]->(d:Discipline)\n",
      "WHERE d.name = 'Computer Science'\n",
      "MATCH (a)-[:AUTHORED]->(:Paper)-[:BELONGS_TO]->(d2:Discipline)\n",
      "WHERE d2.name = 'Mathematics'\n",
      "RETURN DISTINCT a.name\u001b[0m\n",
      "Full Context:\n",
      "\u001b[32;1m\u001b[1;3m[{'a.name': 'Han Xiao'}, {'a.name': 'Kashif Rasul'}, {'a.name': 'Roland Vollgraf'}, {'a.name': 'Ninareh Mehrabi'}, {'a.name': 'Fred Morstatter'}, {'a.name': 'N. Saxena'}, {'a.name': 'Kristina Lerman'}, {'a.name': 'A. Galstyan'}, {'a.name': 'Weihua Hu'}, {'a.name': 'Matthias Fey'}]\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Q: Which authors have worked in both 'Computer Science' and 'Mathematics'?\n",
      "A: Authors who have worked in both 'Computer Science' and 'Mathematics' include Han Xiao, Kashif Rasul, Roland Vollgraf, Ninareh Mehrabi, Fred Morstatter, N. Saxena, Kristina Lerman, A. Galstyan, Weihua Hu, and Matthias Fey.\n",
      "\n",
      "Answer: \n",
      "-------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new GraphCypherQAChain chain...\u001b[0m\n",
      "Generated Cypher:\n",
      "\u001b[32;1m\u001b[1;3mMATCH (a:Author)-[:AUTHORED]->(:Paper)-[:BELONGS_TO]->(:Discipline {name: 'Materials Science'})-[:PUBLISHED_IN]->(:Venue {name: 'Nature'})\n",
      "RETURN DISTINCT a.name\u001b[0m\n",
      "Full Context:\n",
      "\u001b[32;1m\u001b[1;3m[]\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Q: Which authors have published in 'Materials Science' and the venue 'Nature'?\n",
      "A: There are no authors who have published in both 'Materials Science' and the venue 'Nature'.\n",
      "\n",
      "Answer: \n",
      "-------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new GraphCypherQAChain chain...\u001b[0m\n",
      "Generated Cypher:\n",
      "\u001b[32;1m\u001b[1;3mMATCH (p:Paper)-[:BELONGS_TO]->(:Discipline{name:'Psychology'})\n",
      "RETURN p.title, p.citations\n",
      "ORDER BY p.citations ASC\u001b[0m\n",
      "Full Context:\n",
      "\u001b[32;1m\u001b[1;3m[{'p.title': 'The effects of alcohol on the nonhuman primate brain: a network science approach to neuroimaging.', 'p.citations': 11}, {'p.title': 'Insights into failed lexical retrieval from network science', 'p.citations': 81}]\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Q: What are the least cited papers in the discipline 'Psychology'?\n",
      "A: The least cited papers in the discipline of Psychology are \"The effects of alcohol on the nonhuman primate brain: a network science approach to neuroimaging\" with 11 citations and \"Insights into failed lexical retrieval from network science\" with 81 citations.\n",
      "\n",
      "Answer: \n",
      "-------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new GraphCypherQAChain chain...\u001b[0m\n",
      "Generated Cypher:\n",
      "\u001b[32;1m\u001b[1;3mMATCH (p:Paper {topic: 'Network Science'})-[:PUBLISHED_IN]->(v:Venue)\n",
      "RETURN v.name, COUNT(p) AS num_papers\n",
      "ORDER BY num_papers DESC\n",
      "LIMIT 5;\u001b[0m\n",
      "Full Context:\n",
      "\u001b[32;1m\u001b[1;3m[{'v.name': 'Scientific Reports', 'num_papers': 2}, {'v.name': 'Nature Reviews Methods Primers', 'num_papers': 1}, {'v.name': 'Cognitive Psychology', 'num_papers': 1}, {'v.name': 'Workshop on Complex Networks', 'num_papers': 1}, {'v.name': 'Communications of the ACM', 'num_papers': 1}]\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Q: what are the top venues for papers on 'Network Science'?\n",
      "A: The top venues for papers on 'Network Science' are Scientific Reports, Nature Reviews Methods Primers, Cognitive Psychology, Workshop on Complex Networks, and Communications of the ACM.\n",
      "\n",
      "Answer: \n",
      "-------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new GraphCypherQAChain chain...\u001b[0m\n",
      "Generated Cypher:\n",
      "\u001b[32;1m\u001b[1;3mMATCH (a:Author)-[:AUTHORED]->(p:Paper)-[:BELONGS_TO]->(:Discipline{name:'Medicine'})\n",
      "WHERE p.year > 2015\n",
      "RETURN DISTINCT a.name\u001b[0m\n",
      "Full Context:\n",
      "\u001b[32;1m\u001b[1;3m[{'a.name': 'C. Rudin'}, {'a.name': 'Iqbal H. Sarker'}, {'a.name': 'S. Berg'}, {'a.name': 'D. Kutra'}, {'a.name': 'Thorben Kroeger'}, {'a.name': 'C. Straehle'}, {'a.name': 'Bernhard X. Kausler'}, {'a.name': 'Carsten Haubold'}, {'a.name': 'Martin Schiegg'}, {'a.name': 'J. Ales'}]\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Q: Which authors published papers in 'Medicine' after 2015?\n",
      "A: Authors who published papers in 'Medicine' after 2015 include C. Rudin, Iqbal H. Sarker, S. Berg, D. Kutra, Thorben Kroeger, C. Straehle, Bernhard X. Kausler, Carsten Haubold, Martin Schiegg, and J. Ales.\n",
      "\n",
      "Answer: \n",
      "-------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new GraphCypherQAChain chain...\u001b[0m\n",
      "Generated Cypher:\n",
      "\u001b[32;1m\u001b[1;3mMATCH (a:Author {name: 'D. Davies'})-[:AUTHORED]->(:Paper)-[:BELONGS_TO]->(:Discipline {name: 'Chemistry'})<-[:BELONGS_TO]-(:Paper)<-[:AUTHORED]-(author)\n",
      "RETURN DISTINCT author.name\u001b[0m\n",
      "Full Context:\n",
      "\u001b[32;1m\u001b[1;3m[]\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Q: which authors have collaborated with 'D. Davies' on papers in 'Chemistry'?\n",
      "A: There are no authors who have collaborated with 'D. Davies' on papers in 'Chemistry'.\n",
      "\n",
      "Answer: \n",
      "-------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for test_data in TEST_SET:\n",
    "    question = test_data[\"question\"]\n",
    "    query = test_data[\"query\"]\n",
    "    answer = test_data[\"answer\"]\n",
    "    test_query(question)\n",
    "    print(f\"Answer: {answer}\")\n",
    "    print(\"-------------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import pprint\n",
    "import json\n",
    "from langchain.embeddings.huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "\n",
    "embed_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "# Load evaluation metrics\n",
    "rouge = evaluate.load(\"rouge\")\n",
    "bleu = evaluate.load(\"bleu\")\n",
    "\n",
    "# Load the JSON file\n",
    "with open('Q_A_LLM.json', 'r') as f:\n",
    "    evaluation_data = json.load(f)\n",
    "\n",
    "# Accumulate results\n",
    "rouge_scores = []\n",
    "bleu_scores = []\n",
    "cosine_similarities = []\n",
    "\n",
    "for data in evaluation_data:\n",
    "    question = data[\"question\"]\n",
    "    expected_answer = data[\"answer\"]\n",
    "    generated_answer = data[\"LLM\"]  # Use the generated answer from the JSON data\n",
    "    \n",
    "    # Compute evaluation metrics\n",
    "    rouge_result = rouge.compute(predictions=[generated_answer], references=[expected_answer])\n",
    "    bleu_result = bleu.compute(predictions=[generated_answer], references=[[expected_answer]])\n",
    "\n",
    "    # Compute cosine similarity between embeddings\n",
    "    reference_embedding = embed_model.embed_query(expected_answer)  # Replace with your embedding method\n",
    "    generated_embedding = embed_model.embed_query(generated_answer)  # Replace with your embedding method\n",
    "    cosine_sim = cosine_similarity([reference_embedding], [generated_embedding])[0][0]\n",
    "\n",
    "    # Store the results\n",
    "    rouge_scores.append(rouge_result)\n",
    "    bleu_scores.append(bleu_result)\n",
    "    cosine_similarities.append(cosine_sim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Compute the average ROUGE score\n",
    "avg_rouge1 = np.mean([score['rouge1'] for score in rouge_scores])\n",
    "avg_rouge2 = np.mean([score['rouge2'] for score in rouge_scores])\n",
    "avg_rougeL = np.mean([score['rougeL'] for score in rouge_scores])\n",
    "\n",
    "# Compute the average BLEU score\n",
    "avg_bleu = np.mean([score['bleu'] for score in bleu_scores])\n",
    "\n",
    "# Compute the average Cosine Similarity\n",
    "avg_cosine_similarity = np.mean(cosine_similarities)\n",
    "\n",
    "# Print the average scores\n",
    "print(f\"Average ROUGE-1: {avg_rouge1}\")\n",
    "print(f\"Average ROUGE-2: {avg_rouge2}\")\n",
    "print(f\"Average ROUGE-L: {avg_rougeL}\")\n",
    "print(f\"Average BLEU: {avg_bleu}\")\n",
    "print(f\"Average Cosine Similarity: {avg_cosine_similarity}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accumulate results\n",
    "results = []\n",
    "\n",
    "for data in evaluation_data:\n",
    "    question = data[\"question\"]\n",
    "    expected_answer = data[\"answer\"]\n",
    "\n",
    "    # Query the system\n",
    "    generated_answer = data[\"LLM\"]  # Using the LLM's response as generated answer\n",
    "    \n",
    "    # Check for specific phrases in the generated answer\n",
    "    if \"User Mistake.\" in generated_answer or \"ERROR: SAFETY Issue.\" in generated_answer:\n",
    "        # Skip score calculation for these responses\n",
    "        continue\n",
    "\n",
    "    # Compute evaluation metrics\n",
    "    rouge_result = rouge.compute(predictions=[generated_answer], references=[expected_answer])\n",
    "    bleu_result = bleu.compute(predictions=[generated_answer], references=[[expected_answer]])\n",
    "\n",
    "    # Compute cosine similarity between embeddings\n",
    "    reference_embedding = embed_model.embed_query(expected_answer)\n",
    "    generated_embedding = embed_model.embed_query(generated_answer)\n",
    "    cosine_sim = cosine_similarity([reference_embedding], [generated_embedding])[0][0]\n",
    "\n",
    "    # Append the result as a dictionary\n",
    "    results.append({\n",
    "        \"Question\": question,\n",
    "        \"Generated Answer\": generated_answer,\n",
    "        \"Expected Answer\": expected_answer,\n",
    "        \"Cosine Similarity\": cosine_sim,\n",
    "        # Separate ROUGE metrics\n",
    "        \"ROUGE-1\": rouge_result['rouge1'],\n",
    "        \"ROUGE-2\": rouge_result['rouge2'],\n",
    "        \"ROUGE-L\": rouge_result['rougeL'],\n",
    "        \"ROUGE-Lsum\": rouge_result['rougeLsum'],\n",
    "        # Separate BLEU metrics\n",
    "        \"BLEU\": bleu_result['bleu'],\n",
    "        \"Precision_1\": bleu_result['precisions'][0] if len(bleu_result['precisions']) > 0 else None,\n",
    "        \"Precision_2\": bleu_result['precisions'][1] if len(bleu_result['precisions']) > 1 else None,\n",
    "        \"Precision_3\": bleu_result['precisions'][2] if len(bleu_result['precisions']) > 2 else None,\n",
    "        \"Precision_4\": bleu_result['precisions'][3] if len(bleu_result['precisions']) > 3 else None,\n",
    "        \"Brevity Penalty\": bleu_result['brevity_penalty'],\n",
    "        \"Length Ratio\": bleu_result['length_ratio'],\n",
    "        \"Translation Length\": bleu_result['translation_length'],\n",
    "        \"Reference Length\": bleu_result['reference_length'],\n",
    "    })\n",
    "\n",
    "# Create a DataFrame for tabular results\n",
    "df = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the average scores\n",
    "print(f\"Average ROUGE-1: {df['ROUGE-1'].mean()}\")\n",
    "print(f\"Average ROUGE-2: {df['ROUGE-2'].mean()}\")\n",
    "print(f\"Average ROUGE-L: {df['ROUGE-L'].mean()}\")\n",
    "print(f\"Average ROUGE-L: {df['ROUGE-Lsum'].mean()}\")\n",
    "print(f\"Average BLEU: {df['BLEU'].mean()}\")\n",
    "print(f\"Average Cosine Similarity: {df['Cosine Similarity'].mean()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def calculate_ndcg(relevant_items, generated_items, k):\n",
    "    # Get relevance scores for the generated items\n",
    "    relevance_scores = [1 if item in relevant_items else 0 for item in generated_items[:k]]\n",
    "    \n",
    "    # Calculate DCG\n",
    "    dcg = sum(relevance_scores[i] / np.log2(i + 2) for i in range(len(relevance_scores)))\n",
    "    \n",
    "    # Calculate IDCG\n",
    "    sorted_relevance_scores = sorted(relevance_scores, reverse=True)\n",
    "    idcg = sum(sorted_relevance_scores[i] / np.log2(i + 2) for i in range(len(sorted_relevance_scores)))\n",
    "\n",
    "    # Handle the case where IDCG is zero to avoid division by zero\n",
    "    if idcg == 0:\n",
    "        return 0.0\n",
    "    \n",
    "    # Calculate NDCG\n",
    "    ndcg = dcg / idcg\n",
    "    return ndcg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "import numpy as np\n",
    "\n",
    "def calculate_metrics(evaluation_data, k):\n",
    "    ndcg_scores = []\n",
    "    precision_scores = []\n",
    "    recall_scores = []\n",
    "    f1_scores = []\n",
    "\n",
    "    for data in evaluation_data:\n",
    "        question = data[\"question\"]\n",
    "        expected_answer = data[\"answer\"]\n",
    "        generated_answer = data[\"LLM\"]\n",
    "\n",
    "        if \"User Mistake.\" in generated_answer or \"ERROR: SAFETY Issue.\" in generated_answer:\n",
    "            continue  # Skip this entry if there's an error message\n",
    "        \n",
    "        # Assume the expected answer is the only relevant item for simplicity\n",
    "        relevant_items = [expected_answer]\n",
    "        generated_items = generated_answer.split(\", \")  # Assuming comma-separated answers\n",
    "\n",
    "        # Calculate NDCG@k\n",
    "        # You can implement the NDCG function according to your relevance scoring\n",
    "        ndcg_score = calculate_ndcg(relevant_items, generated_items, k)  # Implement this function\n",
    "        ndcg_scores.append(ndcg_score)\n",
    "\n",
    "        # Calculate Precision@k\n",
    "        y_true = [1 if answer in relevant_items else 0 for answer in generated_items[:k]]\n",
    "        precision = precision_score([1] * len(y_true), y_true)\n",
    "        precision_scores.append(precision)\n",
    "\n",
    "        # Calculate Recall@k\n",
    "        recall = recall_score([1] * len(relevant_items), y_true)\n",
    "        recall_scores.append(recall)\n",
    "\n",
    "        # Calculate F1@k\n",
    "        f1 = f1_score([1] * len(relevant_items), y_true)\n",
    "        f1_scores.append(f1)\n",
    "\n",
    "    return ndcg_scores, precision_scores, recall_scores, f1_scores\n",
    "\n",
    "# Example of using the function\n",
    "ndcg_scores, precision_scores, recall_scores, f1_scores = calculate_metrics(evaluation_data, k=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agent",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
