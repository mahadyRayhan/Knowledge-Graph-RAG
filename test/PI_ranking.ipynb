{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv() ## load all the environment variables from .env\n",
    "import glob\n",
    "# import streamlit as st\n",
    "import os\n",
    "from PIL import Image\n",
    "import google.generativeai as genai\n",
    "from IPython.display import display\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import textwrap\n",
    "from typing import List, Dict, Tuple, Optional # For type hinting\n",
    "import time\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "genai.configure(api_key=os.getenv(\"GOOGLE_API_KEY\"))\n",
    "\n",
    "## Load Gemini model\n",
    "model=genai.GenerativeModel('gemini-2.0-flash-thinking-exp-01-21')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gemini_response(input,image,user_prompt):\n",
    "    response=model.generate_content([input,image[0],user_prompt])\n",
    "    return response.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DATA Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading files in 2022...\n",
      "Reading files in 2024...\n",
      "Reading files in 2023...\n",
      "Reading files in 2021...\n",
      "Reading files in 2020...\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "data_directory = 'data/ranking_data/'\n",
    "records = []\n",
    "\n",
    "def safe_get(data, keys, default=None):\n",
    "    \"\"\"\n",
    "    Safely get a nested key from a dictionary using a list of keys.\n",
    "    Returns default if any key is missing.\n",
    "    \"\"\"\n",
    "    for key in keys:\n",
    "        if isinstance(data, dict) and key in data:\n",
    "            data = data[key]\n",
    "        else:\n",
    "            return default\n",
    "    return data\n",
    "\n",
    "for sub_dir in os.listdir(data_directory):\n",
    "    print(f\"Reading files in {sub_dir}...\")\n",
    "    sub_directory = os.path.join(data_directory, sub_dir)\n",
    "    for filename in os.listdir(sub_directory):\n",
    "        if filename.endswith('.json'):\n",
    "            filepath = os.path.join(sub_directory, filename)\n",
    "            try:\n",
    "                with open(filepath, 'r') as file:\n",
    "                    data = json.load(file)\n",
    "            except Exception as e:\n",
    "                print(f\"Error reading {filepath}: {e}\")\n",
    "                continue\n",
    "\n",
    "            # Extract award-level context information safely\n",
    "            award_type = data.get(\"awd_istr_txt\")\n",
    "            award_title = data.get(\"awd_titl_txt\")\n",
    "            abstract = data.get(\"abst_narr_txt\")\n",
    "            org_name = data.get(\"org_long_name\")\n",
    "            org_name2 = data.get(\"org_long_name2\")\n",
    "            perf_inst_name = safe_get(data, [\"perf_inst\", \"perf_inst_name\"])\n",
    "            \n",
    "            # Extract program element and reference safely (checking if list exists)\n",
    "            pgm_ele_list = data.get(\"pgm_ele\")\n",
    "            if isinstance(pgm_ele_list, list) and len(pgm_ele_list) > 0:\n",
    "                program_element = pgm_ele_list[0].get(\"pgm_ele_long_name\")\n",
    "            else:\n",
    "                program_element = None\n",
    "\n",
    "            pgm_ref_list = data.get(\"pgm_ref\")\n",
    "            if isinstance(pgm_ref_list, list) and len(pgm_ref_list) > 0:\n",
    "                program_reference = pgm_ref_list[0].get(\"pgm_ref_long_name\")\n",
    "            else:\n",
    "                program_reference = None\n",
    "\n",
    "            # Get investigator information, ensuring it's a list\n",
    "            pi_list = data.get(\"pi\")\n",
    "            if not isinstance(pi_list, list):\n",
    "                continue\n",
    "\n",
    "            # Loop through each investigator in the file\n",
    "            for pi in pi_list:\n",
    "                record = {\n",
    "                    \"award_type\": award_type,\n",
    "                    \"award_title\": award_title,\n",
    "                    \"abstract\": abstract,\n",
    "                    \"org_name\": org_name,\n",
    "                    \"org_name2\": org_name2,\n",
    "                    \"perf_inst_name\": perf_inst_name,\n",
    "                    \"program_element\": program_element,\n",
    "                    \"program_reference\": program_reference,\n",
    "                    \"pi_id\": pi.get(\"pi_id\"),\n",
    "                    \"pi_full_name\": pi.get(\"pi_full_name\", \"\").strip() if pi.get(\"pi_full_name\") else None,\n",
    "                    \"role\": pi.get(\"proj_role_code2\", \"\").strip() if pi.get(\"proj_role_code2\") else None,\n",
    "                    \"department\": pi.get(\"pi_dept_name\"),\n",
    "                    \"email\": pi.get(\"pi_email_addr\"),\n",
    "                    \"start_date\": pi.get(\"start_date\")\n",
    "                }\n",
    "                records.append(record)\n",
    "\n",
    "# Create a DataFrame from the records\n",
    "df = pd.DataFrame(records)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>award_type</th>\n",
       "      <th>award_title</th>\n",
       "      <th>abstract</th>\n",
       "      <th>org_name</th>\n",
       "      <th>org_name2</th>\n",
       "      <th>perf_inst_name</th>\n",
       "      <th>program_element</th>\n",
       "      <th>program_reference</th>\n",
       "      <th>pi_id</th>\n",
       "      <th>pi_full_name</th>\n",
       "      <th>role</th>\n",
       "      <th>department</th>\n",
       "      <th>email</th>\n",
       "      <th>start_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Standard Grant</td>\n",
       "      <td>MRI: Acquisition of a High-Performance Computa...</td>\n",
       "      <td>This project will acquire and deploy a high-pe...</td>\n",
       "      <td>Directorate for Computer and Information Scien...</td>\n",
       "      <td>Office of Advanced Cyberinfrastructure (OAC)</td>\n",
       "      <td>Oklahoma State University</td>\n",
       "      <td>Major Research Instrumentation</td>\n",
       "      <td>WOMEN, MINORITY, DISABLED, NEC</td>\n",
       "      <td>269967889</td>\n",
       "      <td>Terrance   Figy</td>\n",
       "      <td>Co-Principal Investigator</td>\n",
       "      <td>Mathematics, Statistics, and Physics</td>\n",
       "      <td>Terrance.Figy@wichita.edu</td>\n",
       "      <td>2024-08-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Standard Grant</td>\n",
       "      <td>MRI: Acquisition of a High-Performance Computa...</td>\n",
       "      <td>This project will acquire and deploy a high-pe...</td>\n",
       "      <td>Directorate for Computer and Information Scien...</td>\n",
       "      <td>Office of Advanced Cyberinfrastructure (OAC)</td>\n",
       "      <td>Oklahoma State University</td>\n",
       "      <td>Major Research Instrumentation</td>\n",
       "      <td>WOMEN, MINORITY, DISABLED, NEC</td>\n",
       "      <td>269758255</td>\n",
       "      <td>Pratul K Agarwal</td>\n",
       "      <td>Principal Investigator</td>\n",
       "      <td></td>\n",
       "      <td>pratul.agarwal@okstate.edu</td>\n",
       "      <td>2022-08-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Standard Grant</td>\n",
       "      <td>MRI: Acquisition of a High-Performance Computa...</td>\n",
       "      <td>This project will acquire and deploy a high-pe...</td>\n",
       "      <td>Directorate for Computer and Information Scien...</td>\n",
       "      <td>Office of Advanced Cyberinfrastructure (OAC)</td>\n",
       "      <td>Oklahoma State University</td>\n",
       "      <td>Major Research Instrumentation</td>\n",
       "      <td>WOMEN, MINORITY, DISABLED, NEC</td>\n",
       "      <td>000224099</td>\n",
       "      <td>Mickey   Slimp</td>\n",
       "      <td>Co-Principal Investigator</td>\n",
       "      <td>Department of Chemistry</td>\n",
       "      <td></td>\n",
       "      <td>2024-08-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Standard Grant</td>\n",
       "      <td>MRI: Acquisition of a High-Performance Computa...</td>\n",
       "      <td>This project will acquire and deploy a high-pe...</td>\n",
       "      <td>Directorate for Computer and Information Scien...</td>\n",
       "      <td>Office of Advanced Cyberinfrastructure (OAC)</td>\n",
       "      <td>Oklahoma State University</td>\n",
       "      <td>Major Research Instrumentation</td>\n",
       "      <td>WOMEN, MINORITY, DISABLED, NEC</td>\n",
       "      <td>269666332</td>\n",
       "      <td>William H Hsu</td>\n",
       "      <td>Co-Principal Investigator</td>\n",
       "      <td>Computer Science</td>\n",
       "      <td>bhsu@ksu.edu</td>\n",
       "      <td>2022-08-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Standard Grant</td>\n",
       "      <td>MRI: Acquisition of a High-Performance Computa...</td>\n",
       "      <td>This project will acquire and deploy a high-pe...</td>\n",
       "      <td>Directorate for Computer and Information Scien...</td>\n",
       "      <td>Office of Advanced Cyberinfrastructure (OAC)</td>\n",
       "      <td>Oklahoma State University</td>\n",
       "      <td>Major Research Instrumentation</td>\n",
       "      <td>WOMEN, MINORITY, DISABLED, NEC</td>\n",
       "      <td>270046494</td>\n",
       "      <td>Robert   Fleming</td>\n",
       "      <td>Co-Principal Investigator</td>\n",
       "      <td>Engineering</td>\n",
       "      <td>rofleming@AState.edu</td>\n",
       "      <td>2024-08-29</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       award_type                                        award_title  \\\n",
       "0  Standard Grant  MRI: Acquisition of a High-Performance Computa...   \n",
       "1  Standard Grant  MRI: Acquisition of a High-Performance Computa...   \n",
       "2  Standard Grant  MRI: Acquisition of a High-Performance Computa...   \n",
       "4  Standard Grant  MRI: Acquisition of a High-Performance Computa...   \n",
       "7  Standard Grant  MRI: Acquisition of a High-Performance Computa...   \n",
       "\n",
       "                                            abstract  \\\n",
       "0  This project will acquire and deploy a high-pe...   \n",
       "1  This project will acquire and deploy a high-pe...   \n",
       "2  This project will acquire and deploy a high-pe...   \n",
       "4  This project will acquire and deploy a high-pe...   \n",
       "7  This project will acquire and deploy a high-pe...   \n",
       "\n",
       "                                            org_name  \\\n",
       "0  Directorate for Computer and Information Scien...   \n",
       "1  Directorate for Computer and Information Scien...   \n",
       "2  Directorate for Computer and Information Scien...   \n",
       "4  Directorate for Computer and Information Scien...   \n",
       "7  Directorate for Computer and Information Scien...   \n",
       "\n",
       "                                      org_name2             perf_inst_name  \\\n",
       "0  Office of Advanced Cyberinfrastructure (OAC)  Oklahoma State University   \n",
       "1  Office of Advanced Cyberinfrastructure (OAC)  Oklahoma State University   \n",
       "2  Office of Advanced Cyberinfrastructure (OAC)  Oklahoma State University   \n",
       "4  Office of Advanced Cyberinfrastructure (OAC)  Oklahoma State University   \n",
       "7  Office of Advanced Cyberinfrastructure (OAC)  Oklahoma State University   \n",
       "\n",
       "                  program_element               program_reference      pi_id  \\\n",
       "0  Major Research Instrumentation  WOMEN, MINORITY, DISABLED, NEC  269967889   \n",
       "1  Major Research Instrumentation  WOMEN, MINORITY, DISABLED, NEC  269758255   \n",
       "2  Major Research Instrumentation  WOMEN, MINORITY, DISABLED, NEC  000224099   \n",
       "4  Major Research Instrumentation  WOMEN, MINORITY, DISABLED, NEC  269666332   \n",
       "7  Major Research Instrumentation  WOMEN, MINORITY, DISABLED, NEC  270046494   \n",
       "\n",
       "       pi_full_name                       role  \\\n",
       "0   Terrance   Figy  Co-Principal Investigator   \n",
       "1  Pratul K Agarwal     Principal Investigator   \n",
       "2    Mickey   Slimp  Co-Principal Investigator   \n",
       "4     William H Hsu  Co-Principal Investigator   \n",
       "7  Robert   Fleming  Co-Principal Investigator   \n",
       "\n",
       "                             department                       email  \\\n",
       "0  Mathematics, Statistics, and Physics   Terrance.Figy@wichita.edu   \n",
       "1                                        pratul.agarwal@okstate.edu   \n",
       "2               Department of Chemistry                               \n",
       "4                      Computer Science                bhsu@ksu.edu   \n",
       "7                           Engineering        rofleming@AState.edu   \n",
       "\n",
       "   start_date  \n",
       "0  2024-08-29  \n",
       "1  2022-08-03  \n",
       "2  2024-08-29  \n",
       "4  2022-08-03  \n",
       "7  2024-08-29  "
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[df['role'].isin(['Co-Principal Investigator', 'Principal Investigator'])]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(83112, 14)"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_csv('combined_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scholer Identifier LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_data_by_pi(df: pd.DataFrame, pi_ids: List[str]) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Filters the DataFrame to include only rows matching the provided PI IDs.\n",
    "\n",
    "    Args:\n",
    "        df: The input DataFrame.\n",
    "        pi_ids: A list of PI IDs (strings) to filter by.\n",
    "\n",
    "    Returns:\n",
    "        A DataFrame containing only the rows for the specified PI IDs.\n",
    "    \"\"\"\n",
    "    print(f\"Filtering DataFrame for PI IDs: {pi_ids}...\")\n",
    "    filtered = df[df['pi_id'].isin(pi_ids)].copy()\n",
    "    # print(f\"Found {len(filtered)} relevant entries.\")\n",
    "    return filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_pi_data_for_prompt(filtered_df: pd.DataFrame, pi_ids_to_format: List[str]) -> Tuple[str, Dict[str, str]]:\n",
    "    \"\"\"\n",
    "    Formats the filtered PI data into a string suitable for the prompt context.\n",
    "\n",
    "    Args:\n",
    "        filtered_df: The DataFrame already filtered for relevant PIs.\n",
    "        pi_ids_to_format: The original list of PI IDs requested, to ensure all are mentioned.\n",
    "\n",
    "\n",
    "    Returns:\n",
    "        A tuple containing:\n",
    "            - formatted_data_string: A string with formatted details for each PI.\n",
    "            - pi_names_dict: A dictionary mapping PI ID to PI full name.\n",
    "    \"\"\"\n",
    "    # print(\"Formatting data for prompt...\")\n",
    "    formatted_data = \"\"\n",
    "    pi_names = {} # Dictionary to store PI names\n",
    "\n",
    "    if filtered_df.empty:\n",
    "        print(\"Warning: Filtered DataFrame is empty. Formatting 'no data' message.\")\n",
    "        formatted_data = \"No data could be retrieved for the specified potential collaborators.\\n\"\n",
    "        for pi_id in pi_ids_to_format:\n",
    "             pi_names[pi_id] = f\"PI ID {pi_id}\" # Use ID as placeholder name\n",
    "        return formatted_data, pi_names\n",
    "\n",
    "    # Iterate through the original list to ensure all requested PIs are accounted for\n",
    "    for pi_id in pi_ids_to_format:\n",
    "        pi_specific_data = filtered_df[filtered_df['pi_id'] == pi_id]\n",
    "\n",
    "        if not pi_specific_data.empty:\n",
    "            # Get consistent name and department from the first entry\n",
    "            full_name = pi_specific_data['pi_full_name'].iloc[0]\n",
    "            department = pi_specific_data['department'].iloc[0]\n",
    "            pi_names[pi_id] = full_name\n",
    "\n",
    "            formatted_data += f\"--- Researcher: {full_name} (ID: {pi_id}) ---\\n\"\n",
    "            formatted_data += f\"Department: {department}\\n\"\n",
    "            formatted_data += \"Relevant Roles & Awards Found:\\n\"\n",
    "\n",
    "            for index, row in pi_specific_data.iterrows():\n",
    "                formatted_data += f\"- Role: {row.get('role', 'N/A')}\\n\"\n",
    "                formatted_data += f\"  Award Title: {row.get('award_title', 'N/A')}\\n\"\n",
    "                formatted_data += f\"  Start Date: {row.get('start_date', 'N/A')}\\n\"\n",
    "                abstract_preview = textwrap.shorten(row.get('abstract', 'N/A'), width=200, placeholder=\"...\")\n",
    "                formatted_data += f\"  Abstract Snippet: {abstract_preview}\\n\"\n",
    "                formatted_data += f\"  Program Element/Reference: {row.get('program_element', 'N/A')} / {row.get('program_reference', 'N/A')}\\n\\n\"\n",
    "        else:\n",
    "            # Handle case where a specific PI ID from the list had no data in the filtered df\n",
    "            formatted_data += f\"--- Researcher ID: {pi_id} ---\\n\"\n",
    "            formatted_data += \"No award data found in the provided dataset for this PI.\\n\\n\"\n",
    "            pi_names[pi_id] = f\"PI ID {pi_id}\" # Use ID as placeholder name\n",
    "\n",
    "    # print(\"Data formatting complete.\")\n",
    "    return formatted_data, pi_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_recommendation_prompt(formatted_data_string: str, pi_names_dict: Dict[str, str], research_topic: str) -> str:\n",
    "    \"\"\"\n",
    "    Generates the full prompt string for the Gemini model.\n",
    "\n",
    "    Args:\n",
    "        formatted_data_string: The formatted string containing PI details.\n",
    "        pi_names_dict: A dictionary mapping PI ID to PI name.\n",
    "        research_topic: The research topic for collaboration.\n",
    "\n",
    "    Returns:\n",
    "        The complete prompt string.\n",
    "    \"\"\"\n",
    "    # print(\"Generating prompt...\")\n",
    "    collaborator_names_list = \", \".join(pi_names_dict.values())\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "        Context:\n",
    "        The following researchers ({collaborator_names_list}) are considering collaborating on a new research project focused on the topic '{research_topic}'. Below is information extracted from a database about their previous grants and roles:\n",
    "\n",
    "        {formatted_data_string}\n",
    "\n",
    "        Task:\n",
    "        Based *only* on the information provided above, please analyze the qualifications, experience, and relevance of past work for each researcher ({collaborator_names_list}). Recommend which of these individuals would be the most suitable Principal Investigator (PI) to lead this new collaborative project on '{research_topic}'.\n",
    "\n",
    "        Provide a detailed explanation for your recommendation. Consider factors apparent from the data, such as:\n",
    "        - Direct relevance of their past research (award titles, abstracts, program elements) to the topic '{research_topic}'.\n",
    "        - Demonstrated experience (e.g., number of awards listed, roles held like 'Principal Investigator').\n",
    "        - Any indicators of leadership or seniority (e.g., award types like 'Career Award' if present, consistent PI roles).\n",
    "\n",
    "        Please identify the suggested PI clearly by name.\n",
    "        \"\"\"\n",
    "    # print(\"Prompt generated.\")\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Please identify the suggested PI clearly by name and justify your choice thoroughly using specific evidence from the provided context. If the data is insufficient to make a strong recommendation for any particular candidate, please state that clearly as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gemini_response(model: genai.GenerativeModel, prompt: str) -> Tuple[Optional[str], float]:\n",
    "    \"\"\"\n",
    "    Sends the prompt to the Gemini model, streams the response, and measures time.\n",
    "\n",
    "    Args:\n",
    "        model: The configured Gemini model object.\n",
    "        prompt: The prompt string to send to the model.\n",
    "\n",
    "    Returns:\n",
    "        A tuple containing:\n",
    "            - The full response text as a string (or None if an error occurs).\n",
    "            - The time taken for the API call in seconds.\n",
    "    \"\"\"\n",
    "    # print(\"--- Sending Request to Gemini ---\")\n",
    "    start_time = time.time()\n",
    "    full_response_text = \"\"\n",
    "    contents = [prompt] # Prepare contents for the API\n",
    "\n",
    "    try:\n",
    "        responses = model.generate_content(contents, stream=True)\n",
    "        # responses = model.generate_content(contents)\n",
    "\n",
    "        # print(\"\\n-------Response--------\")\n",
    "        for response in responses:\n",
    "            # print(response.text, end=\"\")\n",
    "            full_response_text += response.text\n",
    "        # print(\"\\n-----------------------\")\n",
    "        PI_NAME = full_response_text.split('\\n')[-1].strip()\n",
    "        print(f\"\\nPI: {PI_NAME}\")\n",
    "\n",
    "        response_time = time.time() - start_time\n",
    "        print(f\"\\nResponse generated in {response_time:.2f} seconds.\")\n",
    "        return full_response_text, response_time\n",
    "\n",
    "    except AttributeError:\n",
    "        response_time = time.time() - start_time\n",
    "        print(\"\\nError: 'model' object not found or not configured correctly.\")\n",
    "        print(\"Please ensure the 'model' variable holds your loaded Gemini model.\")\n",
    "        return None, response_time\n",
    "    except Exception as e:\n",
    "        response_time = time.time() - start_time\n",
    "        print(f\"\\nAn error occurred during the API call: {e}\")\n",
    "        print(f\"Attempt failed after {response_time:.2f} seconds.\")\n",
    "        return None, response_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_pi(df: pd.DataFrame, model: genai.GenerativeModel, pi_ids: List[str], research_topic: str) -> Optional[str]:\n",
    "    \"\"\"\n",
    "    Orchestrates the process of filtering data, formatting, generating prompt,\n",
    "    and getting a PI recommendation from the Gemini model.\n",
    "\n",
    "    Args:\n",
    "        df: The main DataFrame.\n",
    "        model: The configured Gemini model object.\n",
    "        pi_ids: A list of PI IDs to consider.\n",
    "        research_topic: The topic for collaboration.\n",
    "\n",
    "    Returns:\n",
    "        The recommendation text from the model, or None if an error occurred\n",
    "        or essential steps failed.\n",
    "    \"\"\"\n",
    "    print(f\"\\n--- Starting PI Recommendation Process for Topic: '{research_topic}' ---\")\n",
    "\n",
    "    # 1. Filter Data\n",
    "    filtered_data = filter_data_by_pi(df, pi_ids)\n",
    "    # Optional: Add a check here if you want to stop if no data is found at all\n",
    "    # if filtered_data.empty:\n",
    "    #     print(\"Stopping process as no data was found for any specified PI.\")\n",
    "    #     return None\n",
    "\n",
    "    # 2. Format Data\n",
    "    # Pass the original pi_ids list to ensure all are mentioned in formatting\n",
    "    formatted_text, pi_names = format_pi_data_for_prompt(filtered_data, pi_ids)\n",
    "\n",
    "    # 3. Generate Prompt\n",
    "    prompt_text = generate_recommendation_prompt(formatted_text, pi_names, research_topic)\n",
    "\n",
    "    # 4. Get Response\n",
    "    recommendation, duration = get_gemini_response(model, prompt_text)\n",
    "\n",
    "    # print(f\"--- PI Recommendation Process Complete ({duration:.2f}s) ---\")\n",
    "    return recommendation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Starting PI Recommendation Process for Topic: 'STATISTICS' ---\n",
      "Filtering DataFrame for PI IDs: ['000025017', '000025762', '000030655']...\n",
      "\n",
      "PI: **Suggested Principal Investigator:** **Steven N MacEachern**\n",
      "\n",
      "Response generated in 13.89 seconds.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    pi_ids_to_analyze = ['000025017', '000025762', '000030655']\n",
    "    research_topic = 'STATISTICS'\n",
    "\n",
    "    # --- Run the Recommendation Process ---\n",
    "    recommendation_result = recommend_pi(df, model, pi_ids_to_analyze, research_topic)\n",
    "\n",
    "    # Optional: Do something with the result\n",
    "    if recommendation_result:\n",
    "        # print(\"\\n--- Final Recommendation Text ---\")\n",
    "        # print(recommendation_result) # Already printed during streaming\n",
    "        pass # Result is already printed by get_gemini_response\n",
    "    else:\n",
    "        print(\"\\nRecommendation could not be generated.\")\n",
    "\n",
    "except ImportError:\n",
    "    print(\"Please install required libraries: pip install pandas google-generativeai\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred during setup or execution: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing with topic: knowledge graph\n",
      "\n",
      "--- Starting PI Recommendation Process for Topic: 'knowledge graph' ---\n",
      "Filtering DataFrame for PI IDs: ['000025017', '000025762', '000030655']...\n",
      "\n",
      "PI: It is important to note that this analysis is based *only* on the provided text snippets. A more comprehensive assessment would require a deeper understanding of each researcher's full body of work and their potential to adapt their skills to a new domain like 'knowledge graph'.\n",
      "\n",
      "Response generated in 13.27 seconds.\n",
      "--------------------------------------------------\n",
      "Testing with topic: AI\n",
      "\n",
      "--- Starting PI Recommendation Process for Topic: 'AI' ---\n",
      "Filtering DataFrame for PI IDs: ['000025017', '000025762', '000030655']...\n",
      "\n",
      "PI: While Robert D Palmer and Howard B Bluestein are clearly experienced researchers in their field of meteorology, and collaboration between meteorology and AI could be valuable in broader contexts (e.g., AI for weather forecasting), based *only* on the provided data regarding their past grants and roles, Steven N MacEachern's statistical expertise and PI experience in a relevant field make him the most qualified individual to lead a research project specifically on 'AI'.\n",
      "\n",
      "Response generated in 12.02 seconds.\n",
      "--------------------------------------------------\n",
      "Testing with topic: Neuroscience\n",
      "\n",
      "--- Starting PI Recommendation Process for Topic: 'Neuroscience' ---\n",
      "Filtering DataFrame for PI IDs: ['000025017', '000025762', '000030655']...\n",
      "\n",
      "PI: In conclusion, **Steven N MacEachern** is recommended as the most suitable PI *from this group of three*, primarily due to the potential (though still indirect) applicability of his statistical expertise to data analysis that might be required in a neuroscience project.  However, it is important to reiterate that **none of these researchers appear to have a background in Neuroscience itself** based solely on the provided data.  If direct neuroscience expertise is crucial for the PI role, none of these individuals would be ideally suited, and researchers with relevant neuroscience backgrounds should be considered instead.  If the 'Neuroscience' project heavily involves statistical data analysis, then Steven N MacEachern's statistical background provides a marginal advantage over the other two researchers, despite the lack of direct neuroscience experience in his profile as presented.\n",
      "\n",
      "Response generated in 12.64 seconds.\n",
      "--------------------------------------------------\n",
      "Testing with topic: STATISTICS\n",
      "\n",
      "--- Starting PI Recommendation Process for Topic: 'STATISTICS' ---\n",
      "Filtering DataFrame for PI IDs: ['000025017', '000025762', '000030655']...\n",
      "\n",
      "PI: In summary, Steven N MacEachern's departmental affiliation, the explicit statistical focus of his past grants, and his experience as a Principal Investigator in a statistics-related project make him the most qualified and suitable individual to lead the new collaborative project on 'STATISTICS', based solely on the provided data.\n",
      "\n",
      "Response generated in 11.31 seconds.\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Test with various topics dynamically.\n",
    "for test_topic in [\"knowledge graph\", \"AI\", \"Neuroscience\", \"STATISTICS\"]:\n",
    "    print(\"Testing with topic:\", test_topic)\n",
    "    recommendation_result = recommend_pi(df, model, pi_ids_to_analyze, test_topic)\n",
    "    # print(\"Predicted PI:\", pi_candidate)\n",
    "    # print(\"Predicted Co-PIs:\", co_pi_candidates)\n",
    "    # print(\"Candidate Combined Scores:\", scores)\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Starting PI Recommendation Process for Topic: 'STATISTICS' ---\n",
      "Filtering DataFrame for PI IDs: ['269948909', '000173003', '269886945']...\n",
      "\n",
      "PI: In conclusion, **Xin Zhang** possesses the most direct and substantial background in 'STATISTICS', demonstrated by his department affiliation, project titles, abstracts, and program elements. His experience as a Principal Investigator further strengthens his suitability to lead the new collaborative project on 'STATISTICS'. Therefore, Xin Zhang is the most recommended PI among the three researchers based solely on the provided information.\n",
      "\n",
      "Response generated in 10.55 seconds.\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Starting PI Recommendation Process for Topic: 'AI Circuits design' ---\n",
      "Filtering DataFrame for PI IDs: ['269807623', '269794080', '269879497']...\n",
      "\n",
      "PI: **In conclusion, Azadeh Davoodi's directly relevant past research, demonstrated experience as a Principal Investigator, and departmental expertise in Electrical and Computer Engineering make her the most suitable and strongly recommended Principal Investigator to lead the new collaborative project on 'AI Circuits design'.**\n",
      "\n",
      "Response generated in 15.56 seconds.\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Starting PI Recommendation Process for Topic: 'hardware software co-design' ---\n",
      "Filtering DataFrame for PI IDs: ['269807623', '269794080', '269879497']...\n",
      "\n",
      "PI: **In conclusion, Azadeh Davoodi's research expertise is most directly aligned with the topic of 'hardware software co-design', and her experience as a Principal Investigator makes her the most qualified and suitable individual to lead this new collaborative project.**\n",
      "\n",
      "Response generated in 14.28 seconds.\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Starting PI Recommendation Process for Topic: 'Trustworthy AI' ---\n",
      "Filtering DataFrame for PI IDs: ['269677663', '269988546', '270021884']...\n",
      "\n",
      "PI: Therefore, based *solely* on the provided information, **Benjamin Fuller is the most suitable choice for Principal Investigator** for a new collaborative project on 'Trustworthy AI' due to the direct relevance of his past work and demonstrated leadership in the domain of secure and trustworthy systems.\n",
      "\n",
      "Response generated in 15.16 seconds.\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Starting PI Recommendation Process for Topic: 'Networking safety' ---\n",
      "Filtering DataFrame for PI IDs: ['269677663', '269988546', '269814599']...\n",
      "\n",
      "PI: **In conclusion, while all three researchers are accomplished, Benjamin Fuller's demonstrated expertise and research focus on cryptographic authentication, data security, and secure cyberspace, combined with his PI experience and leadership indicators, make him the most compelling and suitable choice to serve as the Principal Investigator for this new collaborative project on 'Networking safety'.**\n",
      "\n",
      "Response generated in 15.97 seconds.\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Starting PI Recommendation Process for Topic: 'Bioinformatics' ---\n",
      "Filtering DataFrame for PI IDs: ['269811881', '269958535', '270083608']...\n",
      "\n",
      "PI: Although Lucia Williams also has strong Bioinformatics credentials and experience as a Co-PI, the crucial factor is Jianlin Cheng's demonstrated experience as a **Principal Investigator** specifically within the domain of Bioinformatics. This makes him the most qualified and suitable candidate to lead the new collaborative project on 'Bioinformatics' based solely on the provided information. HaiYing Wang, while experienced as a PI and working in a relevant field (Statistics), lacks the explicit and direct Bioinformatics focus evident in Jianlin Cheng and Lucia Williams' projects.\n",
      "\n",
      "Response generated in 12.38 seconds.\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Starting PI Recommendation Process for Topic: 'Robotics' ---\n",
      "Filtering DataFrame for PI IDs: ['270082637', '269726900', '269963435']...\n",
      "\n",
      "PI: **In summary, Rodrigo O Spinola's direct experience as a Principal Investigator on a project explicitly within the field of robotics, combined with the clear relevance of his past work to the topic, makes him the most qualified and suitable candidate to lead this new collaborative project on 'Robotics' based solely on the provided data.**\n",
      "\n",
      "Response generated in 13.74 seconds.\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Starting PI Recommendation Process for Topic: 'AI in Robotics' ---\n",
      "Filtering DataFrame for PI IDs: ['270082637', '269726900', '270021884']...\n",
      "\n",
      "PI: In conclusion, while both Rodrigo O Spinola and Guido F Montufar Cuartas have relevant experience, **Guido F Montufar Cuartas** stands out as the most suitable PI due to his direct and strong expertise in Artificial Intelligence, proven experience as a Principal Investigator in multiple AI-focused projects, and indicators of leadership potential signified by the CAREER award. His background is more centrally aligned with the 'AI' aspect of 'AI in Robotics', making him ideally positioned to lead this collaborative project.\n",
      "\n",
      "Response generated in 12.61 seconds.\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Starting PI Recommendation Process for Topic: 'Algorithm' ---\n",
      "Filtering DataFrame for PI IDs: ['269934201', '269769382', '269911544']...\n",
      "\n",
      "PI: While both Michael Dinitz and Xiaohong Wang are strong candidates due to their Computer Science backgrounds and PI experience, **Michael Dinitz** is the most strongly recommended as the PI for the 'Algorithm' project because his past funded research is explicitly and directly in the area of \"Algorithmic Foundations\". This direct relevance, coupled with his PI experience, makes him the most suitable leader for a new collaborative project focused on 'Algorithm'.\n",
      "\n",
      "Response generated in 11.18 seconds.\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Starting PI Recommendation Process for Topic: 'Data Science' ---\n",
      "Filtering DataFrame for PI IDs: ['269721983', '269928133', '000171581']...\n",
      "\n",
      "PI: **Suggested Principal Investigator: Sofya Raskhodnikova**\n",
      "\n",
      "Response generated in 14.59 seconds.\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "candidate_sets = [\n",
    "    (['269948909', '000173003', '269886945'], 'STATISTICS'),\n",
    "    (['269807623', '269794080', '269879497'], 'AI Circuits design'),\n",
    "    (['269807623', '269794080', '269879497'], 'hardware software co-design'),\n",
    "    (['269677663', '269988546', '270021884'], 'Trustworthy AI'),\n",
    "    (['269677663', '269988546', '269814599'], 'Networking safety'),\n",
    "    (['269811881', '269958535', '270083608'], 'Bioinformatics'),\n",
    "    (['270082637', '269726900', '269963435'], 'Robotics'),\n",
    "    (['270082637', '269726900', '270021884'], 'AI in Robotics'),\n",
    "    (['269934201', '269769382', '269911544'], 'Algorithm'),\n",
    "    (['269721983', '269928133', '000171581'], 'Data Science')\n",
    "]\n",
    "\n",
    "for pi_ids, topic in candidate_sets:\n",
    "    recommendation_result = recommend_pi(df, model, pi_ids, topic) #recommend_pi(df, model, pi_ids_to_analyze, research_topic)\n",
    "    # print(\"Predicted PI:\", pi_candidate)\n",
    "    # print(\"Predicted Co-PIs:\", co_pi_candidates)\n",
    "    # print(\"Candidate Combined Scores:\", scores)\n",
    "    print(\"-\" * 50)\n",
    "    # break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Influencer - from a list of PI's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import textwrap\n",
    "from typing import List, Dict, Tuple, Optional # For type hinting\n",
    "import google.generativeai as genai # Assuming genai is already configured\n",
    "\n",
    "# --- Helper Function to get Collaborators for specific awards ---\n",
    "# (This is needed for format_influencer_data)\n",
    "def get_collaborators_for_awards(df: pd.DataFrame, award_titles: List[str]) -> Dict[str, List[str]]:\n",
    "    \"\"\"\n",
    "    Finds all PIs/Co-PIs associated with a list of award titles.\n",
    "\n",
    "    Args:\n",
    "        df: The main DataFrame.\n",
    "        award_titles: A list of award titles.\n",
    "\n",
    "    Returns:\n",
    "        A dictionary where keys are award titles and values are lists of\n",
    "        PI/Co-PI full names on that award.\n",
    "    \"\"\"\n",
    "    collaborators = {}\n",
    "    relevant_awards_df = df[df['award_title'].isin(award_titles)]\n",
    "    for title in award_titles:\n",
    "        # Filter for the specific award title and valid roles\n",
    "        award_pis = relevant_awards_df[\n",
    "            (relevant_awards_df['award_title'] == title) &\n",
    "            (relevant_awards_df['role'].isin(['Principal Investigator', 'Co-Principal Investigator']))\n",
    "        ]\n",
    "        # Get unique names, handling potential missing names\n",
    "        names = [name for name in award_pis['pi_full_name'].unique() if pd.notna(name)]\n",
    "        collaborators[title] = names\n",
    "    return collaborators\n",
    "\n",
    "# --- New Function 1: Format Data for Influencer Prompt ---\n",
    "def format_influencer_data(df: pd.DataFrame, pi_ids: List[str]) -> Tuple[str, Dict[str, str]]:\n",
    "    \"\"\"\n",
    "    Formats data for selected PIs to highlight connections and field diversity\n",
    "    suitable for an 'influencer' analysis prompt.\n",
    "\n",
    "    Args:\n",
    "        df: The main DataFrame containing award and PI information.\n",
    "        pi_ids: A list of PI IDs to format data for.\n",
    "\n",
    "    Returns:\n",
    "        A tuple containing:\n",
    "            - formatted_data_string: A string with formatted details for each PI,\n",
    "              focusing on connections and fields.\n",
    "            - pi_names_dict: A dictionary mapping PI ID to PI full name.\n",
    "    \"\"\"\n",
    "    print(f\"Formatting influencer data for PI IDs: {pi_ids}...\")\n",
    "    formatted_data = \"\"\n",
    "    pi_names = {} # Dictionary to store PI names\n",
    "\n",
    "    # Filter main df once for all relevant PIs to improve efficiency\n",
    "    filtered_df = df[df['pi_id'].isin(pi_ids)].copy()\n",
    "\n",
    "    if filtered_df.empty:\n",
    "        print(\"Warning: No data found for any specified PI IDs.\")\n",
    "        formatted_data = \"No data could be retrieved for the specified potential influencers.\\n\"\n",
    "        for pi_id in pi_ids:\n",
    "             pi_names[pi_id] = f\"PI ID {pi_id}\" # Use ID as placeholder name\n",
    "        return formatted_data, pi_names\n",
    "\n",
    "    # Iterate through the requested PI IDs\n",
    "    for pi_id in pi_ids:\n",
    "        pi_specific_data = filtered_df[filtered_df['pi_id'] == pi_id]\n",
    "\n",
    "        if not pi_specific_data.empty:\n",
    "            # Get consistent name from the first entry\n",
    "            full_name = pi_specific_data['pi_full_name'].iloc[0]\n",
    "            pi_names[pi_id] = full_name\n",
    "            print(f\"  Processing data for {full_name} ({pi_id})...\")\n",
    "\n",
    "            formatted_data += f\"--- Potential Influencer: {full_name} (ID: {pi_id}) ---\\n\"\n",
    "\n",
    "            # --- Project & Connection Analysis ---\n",
    "            unique_award_titles = pi_specific_data['award_title'].unique()\n",
    "            num_projects = len(unique_award_titles)\n",
    "            formatted_data += f\"Total Projects Involved In (as PI/Co-PI): {num_projects}\\n\"\n",
    "\n",
    "            # Get all collaborators across these projects\n",
    "            collaborators_by_award = get_collaborators_for_awards(df, list(unique_award_titles))\n",
    "            all_collaborators = set()\n",
    "            for title, names in collaborators_by_award.items():\n",
    "                # Add collaborators, excluding the PI themselves\n",
    "                all_collaborators.update(name for name in names if name != full_name)\n",
    "\n",
    "            num_unique_collaborators = len(all_collaborators)\n",
    "            formatted_data += f\"Total Unique Collaborators (excluding self): {num_unique_collaborators}\\n\"\n",
    "            # Optionally list some collaborators:\n",
    "            collaborators_preview = \", \".join(list(all_collaborators)[:5]) # Preview first 5\n",
    "            formatted_data += f\"  Collaborators Sample: {collaborators_preview}{'...' if num_unique_collaborators > 5 else ''}\\n\"\n",
    "\n",
    "            # --- Field Diversity Analysis ---\n",
    "            unique_elements = pi_specific_data['program_element'].dropna().unique()\n",
    "            unique_references = pi_specific_data['program_reference'].dropna().unique()\n",
    "            all_fields = set(unique_elements) | set(unique_references)\n",
    "            num_unique_fields = len(all_fields)\n",
    "            formatted_data += f\"Number of Unique Research Fields (Program Elements/References): {num_unique_fields}\\n\"\n",
    "            # Optionally list some fields:\n",
    "            fields_preview = \", \".join(list(all_fields)[:5]) # Preview first 5\n",
    "            formatted_data += f\"  Fields Sample: {fields_preview}{'...' if num_unique_fields > 5 else ''}\\n\\n\"\n",
    "\n",
    "            # --- Detailed Project List (Optional - can make prompt very long) ---\n",
    "            # formatted_data += \"  Projects Overview:\\n\"\n",
    "            # for title in unique_award_titles:\n",
    "            #    roles_on_project = pi_specific_data[pi_specific_data['award_title'] == title]['role'].unique()\n",
    "            #    formatted_data += f\"  - {title} (Roles: {', '.join(roles_on_project)})\\n\"\n",
    "            #    formatted_data += f\"    Collaborators on this project: {', '.join(c for c in collaborators_by_award.get(title, []) if c != full_name)}\\n\"\n",
    "            # formatted_data += \"\\n\"\n",
    "\n",
    "        else:\n",
    "            # Handle case where a specific PI ID from the list had no data\n",
    "            formatted_data += f\"--- Potential Influencer ID: {pi_id} ---\\n\"\n",
    "            formatted_data += \"No award data found in the provided dataset for this PI.\\n\\n\"\n",
    "            pi_names[pi_id] = f\"PI ID {pi_id}\" # Use ID as placeholder name\n",
    "\n",
    "    print(\"Influencer data formatting complete.\")\n",
    "    return formatted_data, pi_names\n",
    "\n",
    "\n",
    "# --- New Function 2: Generate Influencer Prompt ---\n",
    "def generate_influencer_prompt(formatted_data_string: str, pi_names_dict: Dict[str, str]) -> str:\n",
    "    \"\"\"\n",
    "    Generates the full prompt string for the Gemini model to identify influencers.\n",
    "\n",
    "    Args:\n",
    "        formatted_data_string: The formatted string containing PI details focused\n",
    "                               on connections and fields.\n",
    "        pi_names_dict: A dictionary mapping PI ID to PI name.\n",
    "\n",
    "    Returns:\n",
    "        The complete prompt string for influencer identification.\n",
    "    \"\"\"\n",
    "    print(\"Generating influencer prompt...\")\n",
    "    candidate_names_list = \", \".join(pi_names_dict.values())\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "        Context:\n",
    "        You are an AI assistant analyzing research collaboration data to identify 'influencers'. An influencer is defined as a researcher who has significant connections within the network, demonstrated by:\n",
    "        1.  Being involved (as PI or Co-PI) in a relatively high number of distinct projects/awards.\n",
    "        2.  Having collaborated with a relatively high number of unique individuals.\n",
    "        3.  Having experience across a diverse range of research fields (indicated by different Program Elements or Program References).\n",
    "\n",
    "        Below is summarized data for potential influencers ({candidate_names_list}):\n",
    "\n",
    "        {formatted_data_string}\n",
    "\n",
    "        Task:\n",
    "        Based *only* on the summarized information provided above, please analyze each researcher's profile according to the 'influencer' criteria (number of projects, number of unique collaborators, and field diversity).\n",
    "\n",
    "        Rank these individuals ({candidate_names_list}) from most influential to least influential based on the definition provided.\n",
    "\n",
    "        Provide a clear ranking and a concise justification for your ranking, referencing the specific metrics (project count, collaborator count, field count) for each researcher from the context provided.\n",
    "    \"\"\"\n",
    "    print(\"Influencer prompt generated.\")\n",
    "    return prompt\n",
    "\n",
    "# --- New Function 3: Identify Influencer using LLM ---\n",
    "def identify_influencer_llm(df: pd.DataFrame, model: genai.GenerativeModel, pi_ids: List[str]) -> Optional[str]:\n",
    "    \"\"\"\n",
    "    Orchestrates the process of formatting data, generating an influencer prompt,\n",
    "    and getting a ranking from the Gemini model.\n",
    "\n",
    "    Args:\n",
    "        df: The main DataFrame.\n",
    "        model: The configured Gemini model object.\n",
    "        pi_ids: A list of PI IDs to consider as potential influencers.\n",
    "\n",
    "    Returns:\n",
    "        The influencer ranking text from the model, or None if an error occurred.\n",
    "    \"\"\"\n",
    "    print(f\"\\n--- Starting Influencer Identification Process for PI IDs: {pi_ids} ---\")\n",
    "\n",
    "    # 1. Format Data for Influencer Analysis\n",
    "    # Note: This function now focuses on connections and diversity metrics\n",
    "    formatted_text, pi_names = format_influencer_data(df, pi_ids)\n",
    "\n",
    "    # Check if formatting yielded any usable data\n",
    "    if not pi_names or all(name.startswith(\"PI ID\") for name in pi_names.values()):\n",
    "         print(\"Stopping process as no valid data could be formatted.\")\n",
    "         return \"Could not generate influencer ranking due to lack of data for the specified PIs.\"\n",
    "\n",
    "    # 2. Generate Influencer Prompt\n",
    "    prompt_text = generate_influencer_prompt(formatted_text, pi_names)\n",
    "\n",
    "    # 3. Get Response (using the existing get_gemini_response function)\n",
    "    print(\"--- Sending Request to Gemini for Influencer Ranking ---\")\n",
    "    # Assuming get_gemini_response takes model and prompt, and returns (response_text, duration)\n",
    "    # You might need to adapt this call slightly if your get_gemini_response has different args/return values\n",
    "    ranking_result, duration = get_gemini_response(model, prompt_text) # Use your existing function\n",
    "\n",
    "    if ranking_result:\n",
    "        print(f\"--- Influencer Identification Complete ({duration:.2f}s) ---\")\n",
    "        # The result is already printed by get_gemini_response during streaming usually\n",
    "        return ranking_result\n",
    "    else:\n",
    "        print(\"--- Influencer Identification Failed ---\")\n",
    "        return \"Failed to get influencer ranking from the model.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Starting Influencer Identification Process for PI IDs: ['000025762', '269811881', '269807623', '270021884'] ---\n",
      "Formatting influencer data for PI IDs: ['000025762', '269811881', '269807623', '270021884']...\n",
      "  Processing data for Steven N MacEachern (000025762)...\n",
      "  Processing data for Jianlin   Cheng (269811881)...\n",
      "  Processing data for Dirk J Colbry (269807623)...\n",
      "  Processing data for Guido F Montufar Cuartas (270021884)...\n",
      "Influencer data formatting complete.\n",
      "Generating influencer prompt...\n",
      "Influencer prompt generated.\n",
      "--- Sending Request to Gemini for Influencer Ranking ---\n",
      "\n",
      "PI: **4. Jianlin Cheng:** Jianlin Cheng ranks last in this comparison. While he demonstrates a good diversity of research fields (4 fields, equal to Guido), he is tied for the lowest number of projects (2) and has the lowest number of unique collaborators (1). His limited collaborator network, with only 1 unique collaborator, is the primary factor placing him at the bottom of this ranking based on the given influencer criteria.\n",
      "\n",
      "Response generated in 8.75 seconds.\n",
      "--- Influencer Identification Complete (8.75s) ---\n",
      "\n",
      "--- Final Influencer Ranking Text ---\n",
      "**Ranking of Potential Influencers (Most to Least Influential):**\n",
      "\n",
      "1.  **Dirk J Colbry**\n",
      "2.  **Steven N MacEachern**\n",
      "3.  **Guido F Montufar Cuartas**\n",
      "4.  **Jianlin Cheng**\n",
      "\n",
      "**Justification:**\n",
      "\n",
      "**1. Dirk J Colbry:** Dirk J Colbry demonstrates the strongest profile as an influencer based on the provided criteria. He leads in two out of the three metrics and is strong in the third. Specifically, he is involved in the highest number of projects (3), has the highest number of unique collaborators (11), and also possesses the highest diversity in research fields (5). This combination clearly positions him as the most influential among the listed researchers.\n",
      "\n",
      "**2. Steven N MacEachern:** Steven N MacEachern ranks second primarily due to his relatively high number of unique collaborators (4), which is second only to Dirk J Colbry. While he is involved in a moderate number of projects (2, same as Jianlin and Guido), his main weakness is his limited diversity in research fields, with only 1 field listed (STATISTICS).  However, his strong collaborator network places him ahead of Guido and Jianlin.\n",
      "\n",
      "**3. Guido F Montufar Cuartas:** Guido F Montufar Cuartas comes in third. He is involved in 2 projects, similar to Steven and Jianlin.  He has a moderate number of unique collaborators (2), placing him ahead of Jianlin but behind Steven. His diversity in research fields is notable (4 fields), equal to Jianlin and significantly higher than Steven. However, his lower collaborator count compared to Steven places him slightly lower in the overall ranking.\n",
      "\n",
      "**4. Jianlin Cheng:** Jianlin Cheng ranks last in this comparison. While he demonstrates a good diversity of research fields (4 fields, equal to Guido), he is tied for the lowest number of projects (2) and has the lowest number of unique collaborators (1). His limited collaborator network, with only 1 unique collaborator, is the primary factor placing him at the bottom of this ranking based on the given influencer criteria.\n"
     ]
    }
   ],
   "source": [
    "# --- Example Usage ---\n",
    "# Assuming 'df' is your loaded DataFrame and 'model' is your configured Gemini model\n",
    "try:\n",
    "    # Example PI IDs known to have multiple projects/connections\n",
    "    # Replace with IDs relevant to your analysis\n",
    "    influencer_candidate_ids = ['000025762', '269811881', '269807623', '270021884'] # Example set\n",
    "\n",
    "    # --- Run the Influencer Identification Process ---\n",
    "    influencer_ranking_result = identify_influencer_llm(df, model, influencer_candidate_ids)\n",
    "\n",
    "    # Optional: Print the final result again if not fully captured by streaming print\n",
    "    if influencer_ranking_result:\n",
    "        print(\"\\n--- Final Influencer Ranking Text ---\")\n",
    "        print(influencer_ranking_result)\n",
    "    else:\n",
    "        print(\"\\nInfluencer ranking could not be generated.\")\n",
    "\n",
    "except NameError as e:\n",
    "    print(f\"Error: Required variable not defined (e.g., 'df' or 'model'). Details: {e}\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred during the influencer identification process: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Influencer by TOPIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "# Assuming SentenceTransformer 'embedder' and DataFrames 'df', 'df_grouped'\n",
    "# are already loaded and computed as in your notebook (cells 17 & 18)\n",
    "\n",
    "# --- New Function 1: Select Candidate PIs by Criterion ---\n",
    "def select_candidate_pis(\n",
    "    df: pd.DataFrame,\n",
    "    df_grouped: pd.DataFrame,\n",
    "    embedder, # Your SentenceTransformer model\n",
    "    criterion_type: str, # \"topic\" or \"department\"\n",
    "    criterion_value: str, # The actual topic or department name\n",
    "    top_k: int = 10 # Number of top candidates to select\n",
    ") -> List[str]:\n",
    "    \"\"\"\n",
    "    Selects a list of candidate PI IDs based on a research topic or department.\n",
    "\n",
    "    Args:\n",
    "        df: The main DataFrame.\n",
    "        df_grouped: DataFrame grouped by pi_id, containing aggregated info\n",
    "                    and 'text_embedding'.\n",
    "        embedder: The initialized SentenceTransformer model.\n",
    "        criterion_type: Either 'topic' or 'department'.\n",
    "        criterion_value: The specific topic string or department name.\n",
    "        top_k: The maximum number of candidate IDs to return.\n",
    "\n",
    "    Returns:\n",
    "        A list of candidate PI IDs.\n",
    "    \"\"\"\n",
    "    print(f\"Selecting top {top_k} candidates based on {criterion_type}: '{criterion_value}'...\")\n",
    "    candidate_ids = []\n",
    "\n",
    "    if criterion_type == \"topic\":\n",
    "        if 'text_embedding' not in df_grouped.columns or embedder is None:\n",
    "            print(\"Error: df_grouped with 'text_embedding' and embedder are required for topic search.\")\n",
    "            return []\n",
    "\n",
    "        # Compute embedding for the research topic\n",
    "        topic_emb = embedder.encode(criterion_value)\n",
    "\n",
    "        # Calculate similarity between topic and all PIs in df_grouped\n",
    "        all_embeddings = np.stack(df_grouped['text_embedding'].values)\n",
    "        similarities = cosine_similarity([topic_emb], all_embeddings)[0]\n",
    "\n",
    "        # Get indices of top k PIs sorted by similarity\n",
    "        top_indices = np.argsort(similarities)[::-1][:top_k]\n",
    "\n",
    "        # Get the corresponding PI IDs\n",
    "        candidate_ids = df_grouped.iloc[top_indices]['pi_id'].tolist()\n",
    "\n",
    "    elif criterion_type == \"department\":\n",
    "        # Filter the main df by department (case-insensitive partial match)\n",
    "        # You might want to refine this matching logic (e.g., exact match)\n",
    "        dept_match_df = df[df['department'].str.contains(criterion_value, case=False, na=False)]\n",
    "\n",
    "        if dept_match_df.empty:\n",
    "            print(f\"No PIs found matching department: '{criterion_value}'\")\n",
    "            return []\n",
    "\n",
    "        # Get unique PI IDs from the matching departments\n",
    "        unique_dept_pi_ids = dept_match_df['pi_id'].unique()\n",
    "\n",
    "        # If more than top_k PIs, we can optionally rank them (e.g., by award count)\n",
    "        # Here, we'll take the top_k based on award count from df_grouped\n",
    "        if len(unique_dept_pi_ids) > top_k:\n",
    "            candidate_subset = df_grouped[df_grouped['pi_id'].isin(unique_dept_pi_ids)]\n",
    "            # Sort by 'award_count' (requires 'award_count' column in df_grouped)\n",
    "            if 'award_count' in candidate_subset.columns:\n",
    "                 ranked_candidates = candidate_subset.sort_values(by='award_count', ascending=False)\n",
    "                 candidate_ids = ranked_candidates.head(top_k)['pi_id'].tolist()\n",
    "            else: # Fallback if award_count isn't available\n",
    "                 candidate_ids = list(unique_dept_pi_ids)[:top_k]\n",
    "            print(f\"  (Found {len(unique_dept_pi_ids)} PIs, selecting top {top_k} based on award count)\")\n",
    "        else:\n",
    "            candidate_ids = list(unique_dept_pi_ids)\n",
    "\n",
    "    else:\n",
    "        print(f\"Error: Invalid criterion_type '{criterion_type}'. Use 'topic' or 'department'.\")\n",
    "        return []\n",
    "\n",
    "    print(f\"Selected candidate PI IDs: {candidate_ids}\")\n",
    "    return candidate_ids\n",
    "\n",
    "# --- New Function 2: Orchestrator for Criterion-Based Search ---\n",
    "def find_influencers_by_criterion(\n",
    "    df: pd.DataFrame,\n",
    "    df_grouped: pd.DataFrame,\n",
    "    embedder, # Your SentenceTransformer model\n",
    "    model: genai.GenerativeModel, # Your Gemini model\n",
    "    criterion_type: str,\n",
    "    criterion_value: str,\n",
    "    top_k_candidates: int = 10 # How many initial candidates to select\n",
    ") -> Optional[str]:\n",
    "    \"\"\"\n",
    "    Finds and ranks influencers based on a topic or department criterion.\n",
    "\n",
    "    Args:\n",
    "        df: Main DataFrame.\n",
    "        df_grouped: Grouped DataFrame with embeddings and counts.\n",
    "        embedder: SentenceTransformer model.\n",
    "        model: Gemini model object.\n",
    "        criterion_type: 'topic' or 'department'.\n",
    "        criterion_value: The topic string or department name.\n",
    "        top_k_candidates: Max number of candidates to select initially.\n",
    "\n",
    "    Returns:\n",
    "        The influencer ranking text from the model, or None/error message.\n",
    "    \"\"\"\n",
    "    print(f\"\\n--- Starting Influencer Search by {criterion_type.capitalize()}: '{criterion_value}' ---\")\n",
    "\n",
    "    # 1. Select Candidate PIs based on the criterion\n",
    "    candidate_pi_ids = select_candidate_pis(\n",
    "        df, df_grouped, embedder, criterion_type, criterion_value, top_k=top_k_candidates\n",
    "    )\n",
    "\n",
    "    if not candidate_pi_ids:\n",
    "        print(\"No candidates found for the specified criterion.\")\n",
    "        return f\"Could not find potential influencers matching {criterion_type}: '{criterion_value}'.\"\n",
    "\n",
    "    # 2. Proceed with the LLM analysis using the selected candidates\n",
    "    # Reuse the 'identify_influencer_llm' logic (formatting, prompt, API call)\n",
    "    # We pass the dynamically selected candidate_pi_ids\n",
    "    print(f\"\\n--- Analyzing Selected Candidates for Influence ---\")\n",
    "    # (Assuming identify_influencer_llm structure remains similar)\n",
    "    # This reuses the formatting, prompt generation and LLM call logic from before\n",
    "    influencer_ranking_result = identify_influencer_llm(df, model, candidate_pi_ids)\n",
    "\n",
    "\n",
    "    return influencer_ranking_result\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Starting Influencer Search by Topic: 'AI Circuits design' ---\n",
      "Selecting top 5 candidates based on topic: 'AI Circuits design'...\n",
      "Selected candidate PI IDs: ['269757420', '000166285', '269951871', '269674418', '269738150']\n",
      "\n",
      "--- Analyzing Selected Candidates for Influence ---\n",
      "\n",
      "--- Starting Influencer Identification Process for PI IDs: ['269757420', '000166285', '269951871', '269674418', '269738150'] ---\n",
      "Formatting influencer data for PI IDs: ['269757420', '000166285', '269951871', '269674418', '269738150']...\n",
      "  Processing data for Peng   Li (269757420)...\n",
      "  Processing data for Andreas G Andreou (000166285)...\n",
      "  Processing data for Dorit S Hochbaum (269951871)...\n",
      "  Processing data for Alper   Atamturk (269674418)...\n",
      "  Processing data for Charles B Pierre (269738150)...\n",
      "Influencer data formatting complete.\n",
      "Generating influencer prompt...\n",
      "Influencer prompt generated.\n",
      "--- Sending Request to Gemini for Influencer Ranking ---\n",
      "\n",
      "PI: | **Charles B Pierre**    | 1                         | 4                          | 2                                 | Lowest project count and field diversity, moderate collaborator count. Tied with Dorit S Hochbaum and Alper Atamturk due to identical metrics across all criteria.                              |\n",
      "\n",
      "Response generated in 9.79 seconds.\n",
      "--- Influencer Identification Complete (9.79s) ---\n",
      "\n",
      "--- Final Influencer Ranking for Topic 'AI Circuits design' ---\n",
      "## Researcher Ranking based on Influencer Criteria\n",
      "\n",
      "Based on the provided data and the definition of an 'influencer', here is the ranking of the researchers from most to least influential:\n",
      "\n",
      "**Ranking:**\n",
      "\n",
      "1.  **Andreas G Andreou**\n",
      "2.  **Peng Li**\n",
      "3.  **Dorit S Hochbaum, Alper Atamturk, Charles B Pierre (Tie)**\n",
      "\n",
      "**Justification:**\n",
      "\n",
      "*   **1. Andreas G Andreou:**  Andreas G Andreou demonstrates a strong profile across all criteria. He is involved in a notable **3 projects**, has the **highest number of unique collaborators (8)**, and a substantial number of **unique research fields (6)**.  His high collaborator count especially sets him apart, indicating a broad network and significant connectivity.\n",
      "\n",
      "*   **2. Peng Li:** Peng Li is a strong contender due to his involvement in the **highest number of projects (4)** and the **highest diversity of research fields (7)**. While his **unique collaborator count is low (1)**, his strong performance in project involvement and field diversity suggests a significant breadth of research activity and knowledge across different areas.\n",
      "\n",
      "*   **3. Dorit S Hochbaum, Alper Atamturk, Charles B Pierre (Tie):** These three researchers show remarkably similar profiles and are ranked equally. They are all involved in the **lowest number of projects (1)** and have the **lowest diversity of research fields (2)**. While they share a moderate number of **unique collaborators (4)**, their limited project involvement and field diversity position them lower in terms of overall influence compared to Andreas G Andreou and Peng Li based on the provided criteria. They are tied because all three metrics (projects, collaborators, fields) are identical for these three individuals.\n",
      "\n",
      "**Summary Table of Metrics for Ranking Justification:**\n",
      "\n",
      "| Researcher             | Total Projects Involved In | Total Unique Collaborators | Number of Unique Research Fields | Ranking Justification                                                                                                                                                                        |\n",
      "| ---------------------- | ------------------------- | -------------------------- | --------------------------------- | ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |\n",
      "| **Andreas G Andreou**   | 3                         | 8                          | 6                                 | Highest collaborator count, strong project count and field diversity.                                                                                                                            |\n",
      "| **Peng Li**             | 4                         | 1                          | 7                                 | Highest project count and field diversity, but low collaborator count.                                                                                                                            |\n",
      "| **Dorit S Hochbaum**    | 1                         | 4                          | 2                                 | Lowest project count and field diversity, moderate collaborator count. Tied with Alper Atamturk and Charles B Pierre due to identical metrics across all criteria.                              |\n",
      "| **Alper Atamturk**      | 1                         | 4                          | 2                                 | Lowest project count and field diversity, moderate collaborator count. Tied with Dorit S Hochbaum and Charles B Pierre due to identical metrics across all criteria.                              |\n",
      "| **Charles B Pierre**    | 1                         | 4                          | 2                                 | Lowest project count and field diversity, moderate collaborator count. Tied with Dorit S Hochbaum and Alper Atamturk due to identical metrics across all criteria.                              |\n"
     ]
    }
   ],
   "source": [
    "# --- Example Usage ---\n",
    "try:\n",
    "    # --- Find Influencers by TOPIC ---\n",
    "    topic_to_search = \"AI Circuits design\"\n",
    "    topic_ranking = find_influencers_by_criterion(\n",
    "        df, df_grouped, embedder, model,\n",
    "        criterion_type=\"topic\",\n",
    "        criterion_value=topic_to_search,\n",
    "        top_k_candidates=5 # Select top 5 PIs based on topic similarity first\n",
    "    )\n",
    "    if topic_ranking:\n",
    "        print(f\"\\n--- Final Influencer Ranking for Topic '{topic_to_search}' ---\")\n",
    "        print(topic_ranking)\n",
    "\n",
    "except NameError as e:\n",
    "     print(f\"Error: Required variable not defined (e.g., 'df', 'df_grouped', 'embedder', 'model'). Details: {e}\")\n",
    "except Exception as e:\n",
    "     print(f\"An error occurred during the influencer search process: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Influencers by DEPARTMENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Starting Influencer Search by Department: 'Computer Science' ---\n",
      "Selecting top 10 candidates based on department: 'Computer Science'...\n",
      "  (Found 2938 PIs, selecting top 10 based on award count)\n",
      "Selected candidate PI IDs: ['269935164', '269779708', '269765937', '000235919', '270031750', '000207040', '270018850', '269779084', '269985475', '269680242']\n",
      "\n",
      "--- Analyzing Selected Candidates for Influence ---\n",
      "\n",
      "--- Starting Influencer Identification Process for PI IDs: ['269935164', '269779708', '269765937', '000235919', '270031750', '000207040', '270018850', '269779084', '269985475', '269680242'] ---\n",
      "Formatting influencer data for PI IDs: ['269935164', '269779708', '269765937', '000235919', '270031750', '000207040', '270018850', '269779084', '269985475', '269680242']...\n",
      "  Processing data for Yanfang   Ye (269935164)...\n",
      "  Processing data for Prasad   Calyam (269779708)...\n",
      "  Processing data for Tiffany M Barnes (269765937)...\n",
      "  Processing data for Sharad   Mehrotra (000235919)...\n",
      "  Processing data for Ferdinando   Fioretto (270031750)...\n",
      "  Processing data for Dhabaleswar K Panda (000207040)...\n",
      "  Processing data for Ravi Netravali (270018850)...\n",
      "  Processing data for Aditya   Akella (269779084)...\n",
      "  Processing data for Jiliang   Tang (269985475)...\n",
      "  Processing data for Mahmut T Kandemir (269680242)...\n",
      "Influencer data formatting complete.\n",
      "Generating influencer prompt...\n",
      "Influencer prompt generated.\n",
      "--- Sending Request to Gemini for Influencer Ranking ---\n",
      "\n",
      "PI: *Justification:* Ravi Netravali is ranked last. He has the lowest number of projects (5), the lowest number of unique collaborators (2), and a lower number of research fields (8). His metrics across all three criteria are significantly lower than the other researchers, indicating a lower level of influence based on the provided definition.\n",
      "\n",
      "Response generated in 10.11 seconds.\n",
      "--- Influencer Identification Complete (10.11s) ---\n",
      "\n",
      "--- Final Influencer Ranking for Department 'Computer Science' ---\n",
      "Based on the provided data and the definition of an 'influencer', here is the ranking of the researchers from most to least influential:\n",
      "\n",
      "**Ranking of Researchers (Most to Least Influential):**\n",
      "\n",
      "1.  **Prasad Calyam**\n",
      "    *Justification:* Prasad Calyam ranks highest due to his strong performance across all three criteria. He is involved in the highest number of projects (14), has the second-highest number of unique collaborators (25), and possesses the most diverse research field experience (22 unique fields).\n",
      "\n",
      "2.  **Tiffany M Barnes**\n",
      "    *Justification:* Tiffany M Barnes is ranked second. She has the highest number of unique collaborators (30) and a good number of projects (11) and research fields (13). While not topping all categories, her high collaborator count and solid numbers in other areas make her a strong influencer.\n",
      "\n",
      "3.  **Dhabaleswar K Panda**\n",
      "    *Justification:* Dhabaleswar K Panda is ranked third. He has a good number of projects (9), a high number of unique collaborators (20), and the second-highest number of unique research fields (15). His consistent performance across all metrics positions him as a significant influencer.\n",
      "\n",
      "4.  **Jiliang Tang**\n",
      "    *Justification:* Jiliang Tang is ranked fourth. He has a moderate number of projects (9), a high number of unique collaborators (21), and a good number of research fields (12). His strengths in collaborator count and field diversity contribute to his influencer status.\n",
      "\n",
      "5.  **Yanfang Ye**\n",
      "    *Justification:* Yanfang Ye is ranked fifth. She has a high number of projects (13), a moderate number of unique collaborators (11), and a good number of research fields (12). Her project count is strong, and she is reasonably diverse and collaborative.\n",
      "\n",
      "6.  **Sharad Mehrotra**\n",
      "    *Justification:* Sharad Mehrotra is ranked sixth. He has a moderate number of projects (10), a good number of unique collaborators (18), and a moderate number of research fields (11). He demonstrates a balanced profile across the criteria, placing him in the mid-range of influencers.\n",
      "\n",
      "7.  **Mahmut T Kandemir**\n",
      "    *Justification:* Mahmut T Kandemir is ranked seventh. He has a moderate number of projects (9), a good number of unique collaborators (17), and a moderate number of research fields (11). Similar to Sharad Mehrotra, his profile is balanced but slightly lower in overall metrics compared to the top researchers.\n",
      "\n",
      "8.  **Aditya Akella**\n",
      "    *Justification:* Aditya Akella is ranked eighth. He has a moderate number of projects (8), a moderate number of unique collaborators (13), and a lower number of research fields compared to others (8). While not low, his metrics are less compelling compared to the higher-ranked researchers.\n",
      "\n",
      "9.  **Ferdinando Fioretto**\n",
      "    *Justification:* Ferdinando Fioretto is ranked ninth. He has a lower number of projects (7) and unique collaborators (6) compared to most others, although he has a moderate number of research fields (11). His lower project and collaborator counts place him lower in the influencer ranking.\n",
      "\n",
      "10. **Ravi Netravali**\n",
      "    *Justification:* Ravi Netravali is ranked last. He has the lowest number of projects (5), the lowest number of unique collaborators (2), and a lower number of research fields (8). His metrics across all three criteria are significantly lower than the other researchers, indicating a lower level of influence based on the provided definition.\n"
     ]
    }
   ],
   "source": [
    "# --- Example Usage ---\n",
    "try:\n",
    "    # --- Find Influencers by DEPARTMENT ---\n",
    "    dept_to_search = \"Computer Science\"\n",
    "    dept_ranking = find_influencers_by_criterion(\n",
    "        df, df_grouped, embedder, model,\n",
    "        criterion_type=\"department\",\n",
    "        criterion_value=dept_to_search,\n",
    "        top_k_candidates=10 # Select top 10 PIs from this department (ranked by awards)\n",
    "    )\n",
    "    if dept_ranking:\n",
    "        print(f\"\\n--- Final Influencer Ranking for Department '{dept_to_search}' ---\")\n",
    "        print(dept_ranking)\n",
    "\n",
    "except NameError as e:\n",
    "     print(f\"Error: Required variable not defined (e.g., 'df', 'df_grouped', 'embedder', 'model'). Details: {e}\")\n",
    "except Exception as e:\n",
    "     print(f\"An error occurred during the influencer search process: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[df['pi_id'].isin(pi_ids_to_analyze)][['pi_full_name', 'pi_id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Prerequisite Imports and Setup ---\n",
    "# Make sure you have these imports and objects loaded from your notebook\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import google.generativeai as genai # Assuming 'model' is configured\n",
    "# from sentence_transformers import SentenceTransformer # Assuming 'embedder' is loaded\n",
    "import networkx as nx # For Method 7\n",
    "from typing import List, Dict, Tuple, Optional\n",
    "import collections # For Method 4 helper\n",
    "\n",
    "# Assuming 'df', 'df_grouped', 'embedder', 'model' are loaded and preprocessed\n",
    "# Assuming 'get_collaborators_for_awards', 'format_influencer_data',\n",
    "# 'generate_influencer_prompt', 'identify_influencer_llm',\n",
    "# 'select_candidate_pis', 'find_influencers_by_criterion',\n",
    "# 'get_gemini_response' functions exist as defined previously.\n",
    "\n",
    "# --- Method 4: Inter-Institutional Collaboration ---\n",
    "\n",
    "# Helper function to get collaborator institutions\n",
    "def get_collaborator_institutions(df: pd.DataFrame, pi_id: str, collaborators_names: List[str]) -> collections.Counter:\n",
    "    \"\"\"\n",
    "    Finds the institutions of a given list of collaborators.\n",
    "\n",
    "    Args:\n",
    "        df: The main DataFrame.\n",
    "        pi_id: The ID of the main PI (to exclude their own institution if needed).\n",
    "        collaborators_names: A list of full names of the collaborators.\n",
    "\n",
    "    Returns:\n",
    "        A Counter object mapping institution names to their frequency.\n",
    "    \"\"\"\n",
    "    if not collaborators_names:\n",
    "        return collections.Counter()\n",
    "\n",
    "    # Find entries for the collaborators\n",
    "    collaborator_df = df[df['pi_full_name'].isin(collaborators_names)]\n",
    "\n",
    "    # Get institutions, excluding NaNs and potentially the main PI's primary institution\n",
    "    # For simplicity here, we count all unique institutions associated with collaborators\n",
    "    institutions = collaborator_df['perf_inst_name'].dropna().unique()\n",
    "\n",
    "    # We can return a Counter of unique institutions found for collaborators\n",
    "    # For influence, we mostly care about the *number* of unique institutions\n",
    "    return collections.Counter(institutions)\n",
    "\n",
    "\n",
    "# Modify format_influencer_data to include institutional diversity\n",
    "def format_influencer_data_v2(df: pd.DataFrame, pi_ids: List[str]) -> Tuple[str, Dict[str, str]]:\n",
    "    \"\"\"\n",
    "    V2: Formats data including project/collaborator counts, field diversity,\n",
    "        AND inter-institutional collaboration breadth.\n",
    "    \"\"\"\n",
    "    print(f\"Formatting influencer data (v2) for PI IDs: {pi_ids}...\")\n",
    "    formatted_data = \"\"\n",
    "    pi_names = {}\n",
    "    filtered_df = df[df['pi_id'].isin(pi_ids)].copy()\n",
    "\n",
    "    if filtered_df.empty:\n",
    "         # (Same empty handling as before)\n",
    "         print(\"Warning: No data found for any specified PI IDs.\")\n",
    "         formatted_data = \"No data could be retrieved for the specified potential influencers.\\n\"\n",
    "         for pi_id in pi_ids:\n",
    "             pi_names[pi_id] = f\"PI ID {pi_id}\"\n",
    "         return formatted_data, pi_names\n",
    "\n",
    "    for pi_id in pi_ids:\n",
    "        pi_specific_data = filtered_df[filtered_df['pi_id'] == pi_id]\n",
    "\n",
    "        if not pi_specific_data.empty:\n",
    "            full_name = pi_specific_data['pi_full_name'].iloc[0]\n",
    "            pi_names[pi_id] = full_name\n",
    "            print(f\"  Processing data for {full_name} ({pi_id})...\")\n",
    "            formatted_data += f\"--- Potential Influencer: {full_name} (ID: {pi_id}) ---\\n\"\n",
    "\n",
    "            # --- Project & Connection Analysis ---\n",
    "            unique_award_titles = pi_specific_data['award_title'].unique()\n",
    "            num_projects = len(unique_award_titles)\n",
    "            formatted_data += f\"Total Projects Involved In: {num_projects}\\n\"\n",
    "            collaborators_by_award = get_collaborators_for_awards(df, list(unique_award_titles))\n",
    "            all_collaborators = set(name for names in collaborators_by_award.values() for name in names if name != full_name)\n",
    "            num_unique_collaborators = len(all_collaborators)\n",
    "            formatted_data += f\"Total Unique Collaborators: {num_unique_collaborators}\\n\"\n",
    "\n",
    "            # --- Field Diversity Analysis ---\n",
    "            unique_elements = pi_specific_data['program_element'].dropna().unique()\n",
    "            unique_references = pi_specific_data['program_reference'].dropna().unique()\n",
    "            all_fields = set(unique_elements) | set(unique_references)\n",
    "            num_unique_fields = len(all_fields)\n",
    "            formatted_data += f\"Number of Unique Research Fields: {num_unique_fields}\\n\"\n",
    "\n",
    "            # --- NEW: Inter-Institutional Collaboration ---\n",
    "            collaborator_institutions = get_collaborator_institutions(df, pi_id, list(all_collaborators))\n",
    "            num_unique_collab_institutions = len(collaborator_institutions)\n",
    "            formatted_data += f\"Number of Unique Collaborating Institutions: {num_unique_collab_institutions}\\n\"\n",
    "            # Optionally list some institutions\n",
    "            inst_preview = \", \".join(list(collaborator_institutions.keys())[:3])\n",
    "            formatted_data += f\"  Collaborating Institutions Sample: {inst_preview}{'...' if num_unique_collab_institutions > 3 else ''}\\n\\n\"\n",
    "\n",
    "        else:\n",
    "             # (Same handling for missing PI as before)\n",
    "             formatted_data += f\"--- Potential Influencer ID: {pi_id} ---\\n\"\n",
    "             formatted_data += \"No award data found...\\n\\n\"\n",
    "             pi_names[pi_id] = f\"PI ID {pi_id}\"\n",
    "\n",
    "    print(\"Influencer data formatting (v2) complete.\")\n",
    "    return formatted_data, pi_names\n",
    "\n",
    "# Modify generate_influencer_prompt to include the new criterion\n",
    "def generate_influencer_prompt_v2(formatted_data_string: str, pi_names_dict: Dict[str, str]) -> str:\n",
    "    \"\"\"\n",
    "    V2: Generates prompt asking LLM to consider projects, collaborators,\n",
    "        field diversity, AND institutional diversity.\n",
    "    \"\"\"\n",
    "    print(\"Generating influencer prompt (v2)...\")\n",
    "    candidate_names_list = \", \".join(pi_names_dict.values())\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "Context:\n",
    "You are an AI assistant analyzing research collaboration data to identify 'influencers'. An influencer is defined as a researcher who has significant connections and reach, demonstrated by:\n",
    "1.  High number of distinct projects/awards involved in.\n",
    "2.  High number of unique collaborators worked with.\n",
    "3.  Experience across a diverse range of research fields.\n",
    "4.  Collaboration with individuals from a wide range of different institutions.\n",
    "\n",
    "Below is summarized data for potential influencers ({candidate_names_list}):\n",
    "\n",
    "{formatted_data_string}\n",
    "\n",
    "Task:\n",
    "Based *only* on the summarized information provided above, please analyze each researcher's profile according to the 'influencer' criteria (project count, collaborator count, field count, AND collaborating institution count).\n",
    "\n",
    "Rank these individuals ({candidate_names_list}) from most influential to least influential based on this definition.\n",
    "\n",
    "Provide a clear ranking and a concise justification for your ranking, referencing the specific metrics provided for each researcher.\n",
    "\"\"\"\n",
    "    print(\"Influencer prompt (v2) generated.\")\n",
    "    return prompt\n",
    "\n",
    "# New Orchestrator using V2 functions\n",
    "def identify_influencer_llm_v2(df: pd.DataFrame, model: genai.GenerativeModel, pi_ids: List[str]) -> Optional[str]:\n",
    "    \"\"\" V2: Orchestrator using formatting and prompt that include institutional diversity. \"\"\"\n",
    "    print(f\"\\n--- Starting Influencer Identification Process (V2 - Incl. Institutions) for PI IDs: {pi_ids} ---\")\n",
    "    formatted_text, pi_names = format_influencer_data_v2(df, pi_ids) # Use V2 format\n",
    "    if not pi_names or all(name.startswith(\"PI ID\") for name in pi_names.values()):\n",
    "         # (Same error handling)\n",
    "         return \"Could not generate influencer ranking due to lack of data.\"\n",
    "\n",
    "    prompt_text = generate_influencer_prompt_v2(formatted_text, pi_names) # Use V2 prompt\n",
    "    print(\"--- Sending Request to Gemini for Influencer Ranking (V2) ---\")\n",
    "    ranking_result, duration = get_gemini_response(model, prompt_text)\n",
    "\n",
    "    if ranking_result:\n",
    "        print(f\"--- Influencer Identification (V2) Complete ({duration:.2f}s) ---\")\n",
    "        return ranking_result\n",
    "    else:\n",
    "        print(\"--- Influencer Identification (V2) Failed ---\")\n",
    "        return \"Failed to get influencer ranking (V2) from the model.\"\n",
    "\n",
    "# --- Method 5: Specific Award Types ---\n",
    "\n",
    "# Modify select_candidate_pis to handle 'award_type'\n",
    "def select_candidate_pis_v2(\n",
    "    df: pd.DataFrame,\n",
    "    df_grouped: pd.DataFrame,\n",
    "    embedder,\n",
    "    criterion_type: str, # topic, department, award_type\n",
    "    criterion_value: str,\n",
    "    top_k: int = 10\n",
    ") -> List[str]:\n",
    "    \"\"\" V2: Selects candidates based on topic, department, OR award_type. \"\"\"\n",
    "    print(f\"Selecting top {top_k} candidates based on {criterion_type}: '{criterion_value}'...\")\n",
    "    candidate_ids = []\n",
    "\n",
    "    if criterion_type == \"topic\":\n",
    "        # (Same logic as before)\n",
    "        if 'text_embedding' not in df_grouped.columns or embedder is None: return []\n",
    "        topic_emb = embedder.encode(criterion_value)\n",
    "        all_embeddings = np.stack(df_grouped['text_embedding'].values)\n",
    "        similarities = cosine_similarity([topic_emb], all_embeddings)[0]\n",
    "        top_indices = np.argsort(similarities)[::-1][:top_k]\n",
    "        candidate_ids = df_grouped.iloc[top_indices]['pi_id'].tolist()\n",
    "\n",
    "    elif criterion_type == \"department\":\n",
    "        # (Same logic as before)\n",
    "        dept_match_df = df[df['department'].str.contains(criterion_value, case=False, na=False)]\n",
    "        if dept_match_df.empty: return []\n",
    "        unique_dept_pi_ids = dept_match_df['pi_id'].unique()\n",
    "        if len(unique_dept_pi_ids) > top_k:\n",
    "            candidate_subset = df_grouped[df_grouped['pi_id'].isin(unique_dept_pi_ids)]\n",
    "            if 'award_count' in candidate_subset.columns:\n",
    "                 ranked_candidates = candidate_subset.sort_values(by='award_count', ascending=False)\n",
    "                 candidate_ids = ranked_candidates.head(top_k)['pi_id'].tolist()\n",
    "            else: candidate_ids = list(unique_dept_pi_ids)[:top_k]\n",
    "        else: candidate_ids = list(unique_dept_pi_ids)\n",
    "\n",
    "    # --- NEW: Award Type Logic ---\n",
    "    elif criterion_type == \"award_title\":\n",
    "        # Filter main df by the specific award type (case-insensitive partial match)\n",
    "        award_match_df = df[df['award_title'].str.contains(criterion_value, case=False, na=False)]\n",
    "        if award_match_df.empty:\n",
    "            print(f\"No PIs found associated with award type: '{criterion_value}'\")\n",
    "            return []\n",
    "        unique_award_pi_ids = award_match_df['pi_id'].unique()\n",
    "\n",
    "        # Rank by award count within this group if needed\n",
    "        if len(unique_award_pi_ids) > top_k:\n",
    "            candidate_subset = df_grouped[df_grouped['pi_id'].isin(unique_award_pi_ids)]\n",
    "            if 'award_count' in candidate_subset.columns:\n",
    "                 ranked_candidates = candidate_subset.sort_values(by='award_count', ascending=False)\n",
    "                 candidate_ids = ranked_candidates.head(top_k)['pi_id'].tolist()\n",
    "            else: candidate_ids = list(unique_award_pi_ids)[:top_k]\n",
    "            print(f\"  (Found {len(unique_award_pi_ids)} PIs, selecting top {top_k} based on award count)\")\n",
    "        else:\n",
    "            candidate_ids = list(unique_award_pi_ids)\n",
    "    # --- End New Logic ---\n",
    "\n",
    "    else:\n",
    "        print(f\"Error: Invalid criterion_type '{criterion_type}'. Use 'topic', 'department', or 'award_title'.\")\n",
    "        return []\n",
    "\n",
    "    print(f\"Selected candidate PI IDs: {candidate_ids}\")\n",
    "    return candidate_ids\n",
    "\n",
    "# Modify the main orchestrator to use the updated selector\n",
    "def find_influencers_by_criterion_v2(\n",
    "    df: pd.DataFrame,\n",
    "    df_grouped: pd.DataFrame,\n",
    "    embedder,\n",
    "    model: genai.GenerativeModel,\n",
    "    criterion_type: str, # topic, department, award_type\n",
    "    criterion_value: str,\n",
    "    top_k_candidates: int = 10\n",
    ") -> Optional[str]:\n",
    "    \"\"\" V2: Finds influencers based on topic, department, OR award_type criterion. \"\"\"\n",
    "    print(f\"\\n--- Starting Influencer Search (V2 Selector) by {criterion_type.capitalize()}: '{criterion_value}' ---\")\n",
    "\n",
    "    # 1. Select Candidate PIs using the V2 selector\n",
    "    candidate_pi_ids = select_candidate_pis_v2( # Use V2 selector\n",
    "        df, df_grouped, embedder, criterion_type, criterion_value, top_k=top_k_candidates\n",
    "    )\n",
    "\n",
    "    if not candidate_pi_ids:\n",
    "        # (Same error handling)\n",
    "        return f\"Could not find candidates matching {criterion_type}: '{criterion_value}'.\"\n",
    "\n",
    "    # 2. Proceed with LLM analysis (using V1 or V2 formatting/prompting as desired)\n",
    "    # Using V2 here to include institutional diversity analysis as well\n",
    "    print(f\"\\n--- Analyzing Selected Candidates for Influence (V2 - Incl. Institutions) ---\")\n",
    "    influencer_ranking_result = identify_influencer_llm_v2(df, model, candidate_pi_ids)\n",
    "\n",
    "    return influencer_ranking_result\n",
    "\n",
    "\n",
    "# --- Method 6: Hybrid Approach (Example: Topic + Institutions in Prompt) ---\n",
    "\n",
    "# We can reuse `find_influencers_by_criterion_v2` but need a modified prompt generator\n",
    "# that explicitly tells the LLM to weigh two factors.\n",
    "\n",
    "def generate_influencer_prompt_hybrid(\n",
    "    formatted_data_string: str,\n",
    "    pi_names_dict: Dict[str, str],\n",
    "    primary_criterion: str, # e.g., \"Topic Relevance to 'AI'\"\n",
    "    secondary_criterion: str # e.g., \"Breadth of Institutional Collaboration\"\n",
    "    ) -> str:\n",
    "    \"\"\" Hybrid: Asks LLM to rank based on two weighted criteria. \"\"\"\n",
    "    print(\"Generating influencer prompt (Hybrid)...\")\n",
    "    candidate_names_list = \", \".join(pi_names_dict.values())\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "Context:\n",
    "You are an AI assistant identifying 'influencers' based on multiple factors.\n",
    "Primary Factor: {primary_criterion}\n",
    "Secondary Factor: {secondary_criterion}\n",
    "\n",
    "Below is data for potential influencers ({candidate_names_list}), including metrics for projects, collaborators, fields, and collaborating institutions:\n",
    "\n",
    "{formatted_data_string}\n",
    "\n",
    "Task:\n",
    "Based *only* on the summarized information provided, please rank these individuals ({candidate_names_list}) from most influential to least influential.\n",
    "\n",
    "Your ranking should primarily consider the **Primary Factor ({primary_criterion})**. Then, among those who rank highly on the primary factor, give preference based on the **Secondary Factor ({secondary_criterion})**.\n",
    "\n",
    "Provide a clear ranking and justify your reasoning by referencing the specific metrics and how they relate to both factors.\n",
    "\"\"\"\n",
    "    print(\"Influencer prompt (Hybrid) generated.\")\n",
    "    return prompt\n",
    "\n",
    "# Orchestrator for Hybrid approach\n",
    "def find_influencers_hybrid(\n",
    "    df: pd.DataFrame,\n",
    "    df_grouped: pd.DataFrame,\n",
    "    embedder,\n",
    "    model: genai.GenerativeModel,\n",
    "    primary_criterion_type: str, # e.g., \"topic\"\n",
    "    primary_criterion_value: str, # e.g., \"STATISTICS\"\n",
    "    secondary_criterion_desc: str, # e.g., \"Breadth of Institutional Collaboration\"\n",
    "    top_k_candidates: int = 10\n",
    ") -> Optional[str]:\n",
    "    \"\"\" Hybrid: Selects on primary, then asks LLM to rank using primary+secondary factors. \"\"\"\n",
    "\n",
    "    primary_criterion_desc = f\"{primary_criterion_type.capitalize()} related to '{primary_criterion_value}'\"\n",
    "    print(f\"\\n--- Starting Hybrid Influencer Search ({primary_criterion_desc} + {secondary_criterion_desc}) ---\")\n",
    "\n",
    "    # 1. Select candidates based on the PRIMARY criterion\n",
    "    candidate_pi_ids = select_candidate_pis_v2(\n",
    "        df, df_grouped, embedder, primary_criterion_type, primary_criterion_value, top_k=top_k_candidates\n",
    "    )\n",
    "    if not candidate_pi_ids:\n",
    "        return f\"Could not find candidates matching primary criterion: {primary_criterion_desc}.\"\n",
    "\n",
    "    # 2. Format data (use V2 to ensure institutional data is included)\n",
    "    formatted_text, pi_names = format_influencer_data_v2(df, candidate_pi_ids)\n",
    "    if not pi_names or all(name.startswith(\"PI ID\") for name in pi_names.values()):\n",
    "         return \"Could not generate ranking due to lack of data for selected candidates.\"\n",
    "\n",
    "    # 3. Generate the HYBRID prompt\n",
    "    prompt_text = generate_influencer_prompt_hybrid(\n",
    "        formatted_text, pi_names, primary_criterion_desc, secondary_criterion_desc\n",
    "    )\n",
    "\n",
    "    # 4. Get LLM Response\n",
    "    print(\"--- Sending Request to Gemini for Influencer Ranking (Hybrid) ---\")\n",
    "    ranking_result, duration = get_gemini_response(model, prompt_text)\n",
    "\n",
    "    if ranking_result:\n",
    "        print(f\"--- Influencer Identification (Hybrid) Complete ({duration:.2f}s) ---\")\n",
    "        return ranking_result\n",
    "    else:\n",
    "        print(\"--- Influencer Identification (Hybrid) Failed ---\")\n",
    "        return \"Failed to get influencer ranking (Hybrid) from the model.\"\n",
    "\n",
    "\n",
    "# --- Method 7: Network Centrality (Requires NetworkX) ---\n",
    "\n",
    "def calculate_network_centrality(df: pd.DataFrame, top_n: int = 20) -> Optional[pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Calculates Degree and Betweenness Centrality for PIs based on co-awards.\n",
    "\n",
    "    Args:\n",
    "        df: The main DataFrame with 'award_title' and 'pi_id'.\n",
    "        top_n: Number of top influencers to return based on centrality.\n",
    "\n",
    "    Returns:\n",
    "        A DataFrame with PI IDs, names, degree, and betweenness centrality,\n",
    "        ranked by betweenness, then degree. Returns None if networkx is not installed.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        import networkx as nx\n",
    "    except ImportError:\n",
    "        print(\"Error: networkx library is required for network centrality analysis. Install using 'pip install networkx'\")\n",
    "        return None\n",
    "\n",
    "    print(\"\\n--- Calculating Network Centrality ---\")\n",
    "    # Create graph\n",
    "    G = nx.Graph()\n",
    "\n",
    "    # Group by award to find collaborators\n",
    "    awards = df.groupby('award_title')['pi_id'].apply(list)\n",
    "\n",
    "    # Add edges between collaborators on the same award\n",
    "    for award_id, collaborators in awards.items():\n",
    "        # Remove duplicates just in case\n",
    "        unique_collaborators = list(set(collaborators))\n",
    "        if len(unique_collaborators) > 1:\n",
    "            # Add edges between all pairs in this award group\n",
    "            import itertools\n",
    "            for pi1, pi2 in itertools.combinations(unique_collaborators, 2):\n",
    "                if G.has_edge(pi1, pi2):\n",
    "                    G[pi1][pi2]['weight'] = G[pi1][pi2].get('weight', 0) + 1\n",
    "                else:\n",
    "                    G.add_edge(pi1, pi2, weight=1)\n",
    "\n",
    "    if not G.nodes():\n",
    "        print(\"Graph contains no nodes. Cannot calculate centrality.\")\n",
    "        return pd.DataFrame(columns=['pi_id', 'pi_full_name', 'degree_centrality', 'betweenness_centrality'])\n",
    "\n",
    "\n",
    "    # Calculate centrality measures\n",
    "    print(\"Calculating Degree Centrality...\")\n",
    "    degree_centrality = nx.degree_centrality(G)\n",
    "    print(\"Calculating Betweenness Centrality (may take time)...\")\n",
    "    betweenness_centrality = nx.betweenness_centrality(G, normalized=True, weight='weight') # Consider edge weights\n",
    "\n",
    "    # Combine results into a DataFrame\n",
    "    pi_ids = list(G.nodes())\n",
    "    centrality_df = pd.DataFrame({\n",
    "        'pi_id': pi_ids,\n",
    "        'degree_centrality': [degree_centrality.get(pi, 0) for pi in pi_ids],\n",
    "        'betweenness_centrality': [betweenness_centrality.get(pi, 0) for pi in pi_ids]\n",
    "    })\n",
    "\n",
    "    # Merge with PI names (get the first name found for each PI ID)\n",
    "    pi_names_map = df[['pi_id', 'pi_full_name']].drop_duplicates(subset='pi_id').set_index('pi_id')\n",
    "    centrality_df = centrality_df.join(pi_names_map, on='pi_id')\n",
    "\n",
    "    # Rank: Prioritize betweenness, then degree\n",
    "    ranked_df = centrality_df.sort_values(\n",
    "        by=['betweenness_centrality', 'degree_centrality'],\n",
    "        ascending=[False, False]\n",
    "    ).reset_index(drop=True)\n",
    "\n",
    "    print(\"--- Network Centrality Calculation Complete ---\")\n",
    "    return ranked_df[['pi_id', 'pi_full_name', 'degree_centrality', 'betweenness_centrality']].head(top_n)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Influencers BASED ON range of institutional connections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== EXAMPLE: Influencers by Institutional Breadth ===\n",
      "\n",
      "--- Starting Influencer Identification Process (V2 - Incl. Institutions) for PI IDs: ['000025762', '269811881', '269807623', '270021884'] ---\n",
      "Formatting influencer data (v2) for PI IDs: ['000025762', '269811881', '269807623', '270021884']...\n",
      "  Processing data for Steven N MacEachern (000025762)...\n",
      "  Processing data for Jianlin   Cheng (269811881)...\n",
      "  Processing data for Dirk J Colbry (269807623)...\n",
      "  Processing data for Guido F Montufar Cuartas (270021884)...\n",
      "Influencer data formatting (v2) complete.\n",
      "Generating influencer prompt (v2)...\n",
      "Influencer prompt (v2) generated.\n",
      "--- Sending Request to Gemini for Influencer Ranking (V2) ---\n",
      "\n",
      "PI: In summary, Dirk J Colbry is clearly the most influential based on the provided metrics, excelling in project involvement, collaborator count, and institution diversity. Steven N MacEachern shows moderate influence across collaborators and institutions. Guido F Montufar Cuartas and Jianlin Cheng show lower overall influence, with Jianlin Cheng ranking lowest due to the lowest number of unique collaborators.\n",
      "\n",
      "Response generated in 6.91 seconds.\n",
      "--- Influencer Identification (V2) Complete (6.91s) ---\n",
      "Based on the provided data and the definition of an 'influencer', here is the ranking of the researchers from most to least influential, along with justifications:\n",
      "\n",
      "**Ranking:**\n",
      "\n",
      "1.  **Dirk J Colbry (ID: 269807623)**\n",
      "2.  **Steven N MacEachern (ID: 000025762)**\n",
      "3.  **Guido F Montufar Cuartas (ID: 270021884)**\n",
      "4.  **Jianlin Cheng (ID: 269811881)**\n",
      "\n",
      "**Justification:**\n",
      "\n",
      "*   **Dirk J Colbry** ranks as the most influential based on the data. He demonstrates the highest scores across three of the four criteria:\n",
      "    *   **Projects:** Involved in the most projects (3).\n",
      "    *   **Collaborators:** Has the highest number of unique collaborators (11), significantly more than any other researcher.\n",
      "    *   **Institutions:** Collaborated with the most unique institutions (7).\n",
      "    *   **Fields:**  Second highest number of unique research fields (5), only slightly less than the maximum.\n",
      "\n",
      "*   **Steven N MacEachern** is ranked second. He shows moderate influence across several criteria:\n",
      "    *   **Projects:** Involved in 2 projects, matching Jianlin and Guido.\n",
      "    *   **Collaborators:** Has the second-highest number of unique collaborators (4).\n",
      "    *   **Institutions:** Collaborated with the second-highest number of unique institutions (3).\n",
      "    *   **Fields:** Lowest number of unique research fields (1), which is his main weakness compared to others. However, his strong performance in collaborator and institution count places him above Guido and Jianlin.\n",
      "\n",
      "*   **Guido F Montufar Cuartas** is ranked third. He exhibits strength in research fields but lags in collaborators and institutions:\n",
      "    *   **Projects:** Involved in 2 projects, matching Steven and Jianlin.\n",
      "    *   **Collaborators:** Has a low number of unique collaborators (2), only slightly better than Jianlin.\n",
      "    *   **Fields:**  High number of unique research fields (4), matching Jianlin.\n",
      "    *   **Institutions:** Collaborated with a very low number of unique institutions (1), same as Jianlin.  His slightly higher collaborator count compared to Jianlin puts him slightly ahead.\n",
      "\n",
      "*   **Jianlin Cheng** is ranked last. While he demonstrates diversity in research fields, his reach in terms of collaborators and institutions is limited based on the data:\n",
      "    *   **Projects:** Involved in 2 projects, matching Steven and Guido.\n",
      "    *   **Collaborators:** Has the lowest number of unique collaborators (1).\n",
      "    *   **Fields:** High number of unique research fields (4), matching Guido.\n",
      "    *   **Institutions:** Collaborated with a very low number of unique institutions (1), same as Guido. His very low collaborator count is his primary weakness, placing him last in this ranking.\n",
      "\n",
      "In summary, Dirk J Colbry is clearly the most influential based on the provided metrics, excelling in project involvement, collaborator count, and institution diversity. Steven N MacEachern shows moderate influence across collaborators and institutions. Guido F Montufar Cuartas and Jianlin Cheng show lower overall influence, with Jianlin Cheng ranking lowest due to the lowest number of unique collaborators.\n"
     ]
    }
   ],
   "source": [
    "# Example 1: Find influencers based on institutional breadth (using V2)\n",
    "print(\"\\n=== EXAMPLE: Influencers by Institutional Breadth ===\")\n",
    "candidate_ids_for_inst = ['000025762', '269811881', '269807623', '270021884'] # Example list\n",
    "inst_ranking = identify_influencer_llm_v2(df, model, candidate_ids_for_inst)\n",
    "if inst_ranking: print(inst_ranking)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Influencers BASED ON Department"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== EXAMPLE: Influencers by Department (Computer Science) ===\n",
      "\n",
      "--- Starting Influencer Search (V2 Selector) by Department: 'Computer Science' ---\n",
      "Selecting top 10 candidates based on department: 'Computer Science'...\n",
      "Selected candidate PI IDs: ['269935164', '269779708', '269765937', '000235919', '270031750', '000207040', '270018850', '269779084', '269985475', '269680242']\n",
      "\n",
      "--- Analyzing Selected Candidates for Influence (V2 - Incl. Institutions) ---\n",
      "\n",
      "--- Starting Influencer Identification Process (V2 - Incl. Institutions) for PI IDs: ['269935164', '269779708', '269765937', '000235919', '270031750', '000207040', '270018850', '269779084', '269985475', '269680242'] ---\n",
      "Formatting influencer data (v2) for PI IDs: ['269935164', '269779708', '269765937', '000235919', '270031750', '000207040', '270018850', '269779084', '269985475', '269680242']...\n",
      "  Processing data for Yanfang   Ye (269935164)...\n",
      "  Processing data for Prasad   Calyam (269779708)...\n",
      "  Processing data for Tiffany M Barnes (269765937)...\n",
      "  Processing data for Sharad   Mehrotra (000235919)...\n",
      "  Processing data for Ferdinando   Fioretto (270031750)...\n",
      "  Processing data for Dhabaleswar K Panda (000207040)...\n",
      "  Processing data for Ravi Netravali (270018850)...\n",
      "  Processing data for Aditya   Akella (269779084)...\n",
      "  Processing data for Jiliang   Tang (269985475)...\n",
      "  Processing data for Mahmut T Kandemir (269680242)...\n",
      "Influencer data formatting (v2) complete.\n",
      "Generating influencer prompt (v2)...\n",
      "Influencer prompt (v2) generated.\n",
      "--- Sending Request to Gemini for Influencer Ranking (V2) ---\n",
      "\n",
      "PI: The ranking prioritizes breadth of collaboration and diverse experience as indicators of influence. Tiffany M Barnes and Prasad Calyam stand out as the top influencers due to their exceptional performance across multiple metrics, particularly in collaborator and institution counts (Barnes) and project and field counts (Calyam). The ranking then descends based on a combination of these factors, with those demonstrating broader networks and more diverse experiences positioned higher. Ravi Netravali, with consistently low metrics, is identified as the least influential within this group based on the provided data.\n",
      "\n",
      "Response generated in 13.58 seconds.\n",
      "--- Influencer Identification (V2) Complete (13.58s) ---\n",
      "Based on the provided data, here is the ranking of the researchers from most to least influential, along with justifications based on the given metrics:\n",
      "\n",
      "**Ranking (Most to Least Influential):**\n",
      "\n",
      "1.  **Tiffany M Barnes**\n",
      "2.  **Prasad Calyam**\n",
      "3.  **Sharad Mehrotra**\n",
      "4.  **Dhabaleswar K Panda**\n",
      "5.  **Jiliang Tang**\n",
      "6.  **Mahmut T Kandemir**\n",
      "7.  **Aditya Akella**\n",
      "8.  **Yanfang Ye**\n",
      "9.  **Ferdinando Fioretto**\n",
      "10. **Ravi Netravali**\n",
      "\n",
      "**Justification:**\n",
      "\n",
      "1.  **Tiffany M Barnes:**  Barnes ranks highest due to her **exceptional breadth of collaboration**. She has the **highest number of unique collaborators (30)** and the **highest number of unique collaborating institutions (22)**, significantly outperforming all others in these two key metrics. While her project count and field count are not the absolute highest, they are still strong (11 and 13 respectively), making her a clear leader in terms of network and reach across institutions.\n",
      "\n",
      "2.  **Prasad Calyam:** Calyam comes in second, demonstrating strong performance across all criteria. He has the **highest number of projects (14)** and the **highest number of unique research fields (22)**. His collaborator count (25) and institution count (12) are also very high, placing him consistently in the top tier across all four metrics.\n",
      "\n",
      "3.  **Sharad Mehrotra:** Mehrotra ranks third, showing a balanced profile of influence. He has a good number of unique collaborators (18) and projects (10), a decent number of research fields (11), and a strong number of unique collaborating institutions (15), placing him above average in all categories and particularly strong in institutional breadth.\n",
      "\n",
      "4.  **Dhabaleswar K Panda:** Panda is ranked fourth, primarily due to his strong collaborator count (20) and a good number of research fields (15).  He also has a reasonable project count (9) and a moderate number of collaborating institutions (10).  While slightly lower than Mehrotra in institution count, his higher field count and collaborator count contribute to his higher ranking within this group.\n",
      "\n",
      "5.  **Jiliang Tang:** Tang is fifth, showing solid performance across all metrics. He has a good number of unique collaborators (21), a decent number of projects (9), a good number of research fields (12), and a reasonable number of collaborating institutions (11).  He is consistently above average, making him a mid-range influencer.\n",
      "\n",
      "6.  **Mahmut T Kandemir:** Kandemir ranks sixth, demonstrating moderate influence. He has a reasonable number of collaborators (17) and projects (9), and a decent number of research fields (11). However, his number of collaborating institutions is lower compared to those ranked above him (7), which slightly reduces his overall influence score.\n",
      "\n",
      "7.  **Aditya Akella:** Akella is seventh, with moderate metrics across the board. He has a decent number of collaborators (13), projects (8), and collaborating institutions (10), but his number of research fields is lower (8) compared to many others, placing him in the lower half of this group.\n",
      "\n",
      "8.  **Yanfang Ye:** Ye is eighth, showing a mixed profile. While she has a high number of projects (13) and a good number of research fields (12), her number of unique collaborators is lower (11), and notably, she has the **lowest number of unique collaborating institutions (2)**, significantly limiting her institutional reach and thus her overall influence as defined.\n",
      "\n",
      "9.  **Ferdinando Fioretto:** Fioretto ranks ninth, showing lower numbers across all metrics. He has the **lowest number of projects (7)** and a very low number of unique collaborators (6).  While his field count (11) and institution count (8) are not the absolute lowest, they are still below average, indicating a less extensive network compared to others on this list.\n",
      "\n",
      "10. **Ravi Netravali:** Netravali is ranked last as he consistently has the **lowest or near-lowest scores across all metrics**. He has the **fewest unique collaborators (2)**, the **fewest projects (5)**, a low number of research fields (8), and a low number of collaborating institutions (6). This profile indicates the least influence among the researchers analyzed based on the defined criteria.\n",
      "\n",
      "**Summary:**\n",
      "\n",
      "The ranking prioritizes breadth of collaboration and diverse experience as indicators of influence. Tiffany M Barnes and Prasad Calyam stand out as the top influencers due to their exceptional performance across multiple metrics, particularly in collaborator and institution counts (Barnes) and project and field counts (Calyam). The ranking then descends based on a combination of these factors, with those demonstrating broader networks and more diverse experiences positioned higher. Ravi Netravali, with consistently low metrics, is identified as the least influential within this group based on the provided data.\n"
     ]
    }
   ],
   "source": [
    "# Example 2: Find influencers from 'Computer Science' dept (using V2 selector & V2 analysis)\n",
    "print(\"\\n=== EXAMPLE: Influencers by Department (Computer Science) ===\")\n",
    "cs_ranking = find_influencers_by_criterion_v2(\n",
    "    df, df_grouped, embedder, model,\n",
    "    criterion_type=\"department\",\n",
    "    criterion_value=\"Computer Science\",\n",
    "    top_k_candidates=10\n",
    ")\n",
    "if cs_ranking: print(cs_ranking)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Influencers BASED ON award title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== EXAMPLE: Influencers by Award Type (MRI) ===\n",
      "\n",
      "--- Starting Influencer Search (V2 Selector) by Award_title: 'NSF' ---\n",
      "Selecting top 5 candidates based on award_title: 'NSF'...\n",
      "  (Found 4235 PIs, selecting top 5 based on award count)\n",
      "Selected candidate PI IDs: ['269959504', '269935164', '270041430', '269772812', '269999971']\n",
      "\n",
      "--- Analyzing Selected Candidates for Influence (V2 - Incl. Institutions) ---\n",
      "\n",
      "--- Starting Influencer Identification Process (V2 - Incl. Institutions) for PI IDs: ['269959504', '269935164', '270041430', '269772812', '269999971'] ---\n",
      "Formatting influencer data (v2) for PI IDs: ['269959504', '269935164', '270041430', '269772812', '269999971']...\n",
      "  Processing data for Jerene   Shaheed (269959504)...\n",
      "  Processing data for Yanfang   Ye (269935164)...\n",
      "  Processing data for Jacqueline   El-Sayed (270041430)...\n",
      "  Processing data for Nicholas G Feamster (269772812)...\n",
      "  Processing data for Josiah D Hester (269999971)...\n",
      "Influencer data formatting (v2) complete.\n",
      "Generating influencer prompt (v2)...\n",
      "Influencer prompt (v2) generated.\n",
      "--- Sending Request to Gemini for Influencer Ranking (V2) ---\n",
      "\n",
      "PI: 5. **Jerene Shaheed**\n",
      "\n",
      "Response generated in 6.81 seconds.\n",
      "--- Influencer Identification (V2) Complete (6.81s) ---\n",
      "## Researcher Ranking by Influence\n",
      "\n",
      "Based on the provided data and the defined criteria for influence, here is the ranking of the researchers from most to least influential:\n",
      "\n",
      "**1. Jacqueline El-Sayed**\n",
      "\n",
      "**Justification:** Jacqueline El-Sayed demonstrates a strong profile across all influencer criteria. She has a good number of projects (16), a high number of unique collaborators (25), a high number of unique research fields (19), and a very high number of unique collaborating institutions (19). Her breadth across fields and institutions particularly stands out, indicating a wide network and diverse research experience.\n",
      "\n",
      "**2. Josiah D Hester**\n",
      "\n",
      "**Justification:** Josiah D Hester also presents a strong influencer profile, particularly excelling in unique collaborators (26) and research fields (18). He has a decent number of collaborating institutions (15) and projects (12). While slightly lower than Jacqueline in fields and institutions, his high collaborator count positions him as a highly connected researcher.\n",
      "\n",
      "**3. Nicholas G Feamster**\n",
      "\n",
      "**Justification:** Nicholas G Feamster shows a balanced profile, with medium to good scores across all categories. He has a moderate number of projects (13), unique collaborators (15), research fields (16), and collaborating institutions (15). He is consistently demonstrating connections and reach across different dimensions, placing him as moderately influential.\n",
      "\n",
      "**4. Yanfang Ye**\n",
      "\n",
      "**Justification:** Yanfang Ye has a good number of research fields (12) and a moderate number of projects (13) and unique collaborators (11). However, her number of unique collaborating institutions is very low (2). This limited institutional diversity weakens her overall influencer profile compared to the top three, suggesting a more concentrated network.\n",
      "\n",
      "**5. Jerene Shaheed**\n",
      "\n",
      "**Justification:** Jerene Shaheed, despite having the highest number of projects (30), scores extremely low or zero in all other influencer criteria.  She has zero unique collaborators, zero unique collaborating institutions, and a very low number of research fields (2). This profile suggests that while involved in many projects, her collaborations are likely within a very narrow scope, lacking the breadth and diverse connections characteristic of an influencer as defined.  Her lack of unique collaborators and institutions significantly diminishes her influence based on these metrics.\n",
      "\n",
      "**Ranking Summary (Most to Least Influential):**\n",
      "\n",
      "1. **Jacqueline El-Sayed**\n",
      "2. **Josiah D Hester**\n",
      "3. **Nicholas G Feamster**\n",
      "4. **Yanfang Ye**\n",
      "5. **Jerene Shaheed**\n"
     ]
    }
   ],
   "source": [
    "# Example 3: Find influencers associated with 'MRI' award type (using V2 selector & V2 analysis)\n",
    "print(\"\\n=== EXAMPLE: Influencers by Award Type (MRI) ===\")\n",
    "mri_ranking = find_influencers_by_criterion_v2(\n",
    "    df, df_grouped, embedder, model,\n",
    "    criterion_type=\"award_title\",\n",
    "    criterion_value=\"NSF\", # Major Research Instrumentation\n",
    "    top_k_candidates=5\n",
    ")\n",
    "if mri_ranking: print(mri_ranking)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topic & Institutional Breadth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== EXAMPLE: Hybrid Search (Topic: Robotics + Institutions) ===\n",
      "\n",
      "--- Starting Hybrid Influencer Search (Topic related to 'Robotics' + Breadth of Institutional Collaboration) ---\n",
      "Selecting top 10 candidates based on topic: 'Robotics'...\n",
      "Selected candidate PI IDs: ['269818291', '270031608', '269982422', '269693864', '270019686', '270057330', '270019331', '269999999', '269948584', '000182004']\n",
      "Formatting influencer data (v2) for PI IDs: ['269818291', '270031608', '269982422', '269693864', '270019686', '270057330', '270019331', '269999999', '269948584', '000182004']...\n",
      "  Processing data for Jason O'Kane (269818291)...\n",
      "  Processing data for Naomi T Fitter (270031608)...\n",
      "  Processing data for Aaron M Johnson (269982422)...\n",
      "  Processing data for William D Smart (269693864)...\n",
      "  Processing data for Berk   Calli (270019686)...\n",
      "  Processing data for Kaiyu Hang (270057330)...\n",
      "  Processing data for Stefanos   Nikolaidis (270019331)...\n",
      "  Processing data for Philip M Dames (269999999)...\n",
      "  Processing data for Ioannis   Rekleitis (269948584)...\n",
      "  Processing data for Seth   Hutchinson (000182004)...\n",
      "Influencer data formatting (v2) complete.\n",
      "Generating influencer prompt (Hybrid)...\n",
      "Influencer prompt (Hybrid) generated.\n",
      "--- Sending Request to Gemini for Influencer Ranking (Hybrid) ---\n",
      "\n",
      "PI: The ranking is primarily driven by the number of unique collaborating institutions, reflecting the breadth of influence across different research entities. Secondary metrics like the number of unique collaborators, research fields, and projects were used to break ties and refine the ranking within groups having the same number of collaborating institutions. Individuals with more institutional collaborations and broader research profiles are ranked higher as they demonstrate a wider reach and impact within the Robotics field based on the provided data.\n",
      "\n",
      "Response generated in 10.61 seconds.\n",
      "--- Influencer Identification (Hybrid) Complete (10.61s) ---\n",
      "Here is the ranking of the individuals from most to least influential, based on the provided data, along with justifications:\n",
      "\n",
      "**Ranking:**\n",
      "\n",
      "1.  **Ioannis Rekleitis**\n",
      "2.  **William D Smart**\n",
      "3.  **Stefanos Nikolaidis**\n",
      "4.  **Berk Calli**\n",
      "5.  **Naomi T Fitter**\n",
      "6.  **Seth Hutchinson**\n",
      "7.  **Philip M Dames**\n",
      "8.  **Kaiyu Hang**\n",
      "9.  **Jason O'Kane**\n",
      "10. **Aaron M Johnson**\n",
      "\n",
      "**Justification:**\n",
      "\n",
      "The ranking prioritizes the **Breadth of Institutional Collaboration** (Secondary Factor) as the primary differentiator, assuming all individuals are relevant to the **Topic of Robotics** (Primary Factor) as per the context.\n",
      "\n",
      "*   **1st: Ioannis Rekleitis** -  Ioannis Rekleitis stands out with the highest **Number of Unique Collaborating Institutions (5)**. This signifies the broadest reach and collaboration across different institutions, indicating a strong influence within the robotics field across various academic and research centers.\n",
      "\n",
      "*   **2nd: William D Smart** - William D Smart and Stefanos Nikolaidis both have **4 Unique Collaborating Institutions**. To differentiate, we consider other metrics. William D Smart has a higher number of **Unique Research Fields (8)** and **Total Unique Collaborators (7)** compared to Stefanos Nikolaidis (6 and 5 respectively). This suggests a slightly broader and more diverse research portfolio, hence ranking him higher.\n",
      "\n",
      "*   **3rd: Stefanos Nikolaidis** - As mentioned above, Stefanos Nikolaidis also has **4 Unique Collaborating Institutions**. While slightly lower than William D Smart in terms of research fields and collaborators, his institutional collaboration is still significant, placing him in the top tier of influence.\n",
      "\n",
      "*   **4th: Berk Calli** - Berk Calli has **3 Unique Collaborating Institutions**.  He also boasts the highest number of **Total Unique Collaborators (9)** among all individuals, indicating a strong network and collaborative nature, further supporting his position as a highly influential figure.\n",
      "\n",
      "*   **5th: Naomi T Fitter** - Naomi T Fitter, Seth Hutchinson, Philip M Dames, and Kaiyu Hang all have **2 Unique Collaborating Institutions**. To differentiate, we look at other metrics. Naomi T Fitter has the highest **Number of Unique Research Fields (6)** and **Total Unique Collaborators (5)** among this group, suggesting a broader influence compared to the others with the same number of institutions.\n",
      "\n",
      "*   **6th: Seth Hutchinson** - Seth Hutchinson also has **2 Unique Collaborating Institutions**. He has a decent number of **Unique Research Fields (4)** and **Total Unique Collaborators (3)**, placing him above Philip M Dames and Kaiyu Hang in this group due to broader research fields and collaborations.\n",
      "\n",
      "*   **7th: Philip M Dames** - Philip M Dames and Kaiyu Hang are tied with **2 Unique Collaborating Institutions**. They also have similar metrics in other categories. Philip M Dames is placed slightly higher primarily due to alphabetical order, as their metric profiles are very similar.\n",
      "\n",
      "*   **8th: Kaiyu Hang** - Kaiyu Hang, as mentioned above, is tied with Philip M Dames in terms of institutional collaboration and other metrics. Placed slightly lower than Philip M Dames due to alphabetical order.\n",
      "\n",
      "*   **9th: Jason O'Kane** - Jason O'Kane has only **1 Unique Collaborating Institution**. While he has a reasonable number of **Unique Research Fields (4)**, his limited institutional collaboration places him lower in the ranking.\n",
      "\n",
      "*   **10th: Aaron M Johnson** - Aaron M Johnson has **0 Unique Collaborating Institutions** and **0 Total Unique Collaborators**. This lack of collaboration across institutions and with other researchers, despite having some research fields, indicates a significantly lower level of influence based on the provided metrics.\n",
      "\n",
      "**Summary of Reasoning:**\n",
      "\n",
      "The ranking is primarily driven by the number of unique collaborating institutions, reflecting the breadth of influence across different research entities. Secondary metrics like the number of unique collaborators, research fields, and projects were used to break ties and refine the ranking within groups having the same number of collaborating institutions. Individuals with more institutional collaborations and broader research profiles are ranked higher as they demonstrate a wider reach and impact within the Robotics field based on the provided data.\n"
     ]
    }
   ],
   "source": [
    "# Example 4: Hybrid search - Topic: \"Robotics\" + Secondary: Institutional Breadth\n",
    "print(\"\\n=== EXAMPLE: Hybrid Search (Topic: Robotics + Institutions) ===\")\n",
    "hybrid_ranking = find_influencers_hybrid(\n",
    "    df, df_grouped, embedder, model,\n",
    "    primary_criterion_type=\"topic\",\n",
    "    primary_criterion_value=\"Robotics\",\n",
    "    secondary_criterion_desc=\"Breadth of Institutional Collaboration\",\n",
    "    top_k_candidates=10\n",
    ")\n",
    "if hybrid_ranking: print(hybrid_ranking)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network Centrality Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 5: Network Centrality Analysis\n",
    "print(\"\\n=== EXAMPLE: Network Centrality Analysis ===\")\n",
    "centrality_results = calculate_network_centrality(df, top_n=15)\n",
    "if centrality_results is not None:\n",
    "    print(centrality_results.to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PI classification rule based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from datetime import datetime\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Combine relevant text columns into one (you may adjust columns as needed)\n",
    "text_columns = [\n",
    "    \"award_type\", \"award_title\", \"abstract\", \n",
    "    \"org_name\", \"org_name2\", \"perf_inst_name\", \n",
    "    \"program_element\", \"program_reference\"\n",
    "]\n",
    "df[\"combined_text\"] = df[text_columns].astype(str).agg(\" \".join, axis=1)\n",
    "\n",
    "# a. Leadership indicator: 1 if role suggests prior leadership (e.g., contains \"Principal Investigator\")\n",
    "df[\"leadership\"] = df[\"role\"].apply(lambda x: 1 if \"Principal Investigator\" in str(x) else 0)\n",
    "\n",
    "# b. Experience in years: use start_date and a reference date (here we use today)\n",
    "df[\"start_date\"] = pd.to_datetime(df[\"start_date\"], errors='coerce')\n",
    "reference_date = datetime.now()  # or use a fixed project date\n",
    "df[\"experience_years\"] = (reference_date - df[\"start_date\"]).dt.days / 365.25\n",
    "\n",
    "# Load a pre-trained sentence transformer\n",
    "embedder = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "# Compute embedding for each award's combined text\n",
    "df[\"text_embedding\"] = df[\"combined_text\"].apply(lambda x: embedder.encode(x))\n",
    "\n",
    "# We assume each row has a researcher ID (\"pi_id\"). If a researcher has multiple rows, we aggregate.\n",
    "# For aggregated text, we average the embeddings; for numeric features, we use appropriate aggregation.\n",
    "award_counts = df.groupby(\"pi_id\").size().reset_index(name=\"award_count\")\n",
    "df_grouped = df.groupby(\"pi_id\").agg({\n",
    "    \"experience_years\": \"mean\",       # average experience across awards\n",
    "    \"leadership\": \"max\",              # if they have ever been a PI, mark as leadership\n",
    "    \"text_embedding\": lambda embs: np.mean(np.stack(embs), axis=0)\n",
    "}).reset_index()\n",
    "df_grouped = df_grouped.merge(award_counts, on=\"pi_id\", how=\"left\")\n",
    "\n",
    "# For later scoring, normalize the numeric features (experience and award_count)\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "df_grouped[[\"exp_norm\", \"award_norm\"]] = scaler.fit_transform(df_grouped[[\"experience_years\", \"award_count\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rank_candidates(research_topic, candidate_ids, base_weight=0.5, topic_weight=0.5):\n",
    "    # Compute embedding for the research topic\n",
    "    topic_emb = embedder.encode(research_topic)\n",
    "    \n",
    "    candidate_scores = []\n",
    "    for cid in candidate_ids:\n",
    "        candidate = df_grouped[df_grouped[\"pi_id\"] == cid].iloc[0]\n",
    "        \n",
    "        # Topic relevance score: cosine similarity between candidate's aggregated embedding and the topic\n",
    "        candidate_emb = candidate[\"text_embedding\"]\n",
    "        relevance_score = cosine_similarity([candidate_emb], [topic_emb])[0][0]\n",
    "        \n",
    "        # Base score: a simple weighted sum of normalized features plus a bonus for leadership\n",
    "        # Adjust weights as needed. Here, leadership gets a bonus of 1 if present.\n",
    "        base_score = candidate[\"exp_norm\"] + candidate[\"award_norm\"] + (1 if candidate[\"leadership\"] == 1 else 0)\n",
    "        \n",
    "        # Combined score: weighted combination of base score and topic relevance\n",
    "        combined_score = base_weight * base_score + topic_weight * relevance_score\n",
    "        candidate_scores.append(combined_score)\n",
    "    \n",
    "    candidate_scores = np.array(candidate_scores)\n",
    "    best_index = np.argmax(candidate_scores)\n",
    "    pi_candidate = candidate_ids[best_index]\n",
    "    co_pi_candidates = [cid for i, cid in enumerate(candidate_ids) if i != best_index]\n",
    "    \n",
    "    return pi_candidate, co_pi_candidates, candidate_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing with topic: knowledge graph\n",
      "Predicted PI: 000025762\n",
      "Predicted Co-PIs: ['000025017', '000030655']\n",
      "Candidate Combined Scores: [0.72689373 0.88944828 0.83865565]\n",
      "--------------------------------------------------\n",
      "Testing with topic: AI\n",
      "Predicted PI: 000025762\n",
      "Predicted Co-PIs: ['000025017', '000030655']\n",
      "Candidate Combined Scores: [0.74238132 0.88151991 0.83861753]\n",
      "--------------------------------------------------\n",
      "Testing with topic: Neuroscience\n",
      "Predicted PI: 000025762\n",
      "Predicted Co-PIs: ['000025017', '000030655']\n",
      "Candidate Combined Scores: [0.68108185 0.8349548  0.78906286]\n",
      "--------------------------------------------------\n",
      "Testing with topic: STATISTICS\n",
      "Predicted PI: 000025762\n",
      "Predicted Co-PIs: ['000025017', '000030655']\n",
      "Candidate Combined Scores: [0.73771358 0.92949853 0.86005208]\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Test with various topics dynamically.\n",
    "for test_topic in [\"knowledge graph\", \"AI\", \"Neuroscience\", \"STATISTICS\"]:\n",
    "    print(\"Testing with topic:\", test_topic)\n",
    "    pi_candidate, co_pi_candidates, scores = rank_candidates(test_topic, pi_ids_to_analyze)\n",
    "    print(\"Predicted PI:\", pi_candidate)\n",
    "    print(\"Predicted Co-PIs:\", co_pi_candidates)\n",
    "    print(\"Candidate Combined Scores:\", scores)\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[df.pi_id.isin(pi_ids_to_analyze)][['pi_id', 'pi_full_name', 'role', 'department', 'leadership', 'experience_years', 'program_element']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define the list of keywords for departments of interest,\n",
    "# # including alternative spellings (e.g., math and mathmatics, stat and statistics)\n",
    "# allowed_keywords = ['computer', 'electrical', 'biomedical', 'bioinformatics', 'math', 'mathmatics', 'stat', 'statistics']\n",
    "\n",
    "# # Filter the DataFrame to only include rows where the 'department' field contains one of the keywords (case insensitive)\n",
    "# qualified_df = df[df['department'].fillna('').str.lower().str.contains('|'.join(allowed_keywords))]\n",
    "\n",
    "# # Get unique PI IDs from the filtered DataFrame\n",
    "# unique_pi_ids = qualified_df['pi_id'].unique()\n",
    "\n",
    "# # Generate 15 sets, each containing 3 distinct PI IDs sampled without replacement\n",
    "# pi_id_sets = [list(np.random.choice(unique_pi_ids, 3, replace=False)) for _ in range(15)]\n",
    "\n",
    "# # Output the sets with department and program_element information\n",
    "# for idx, pi_set in enumerate(pi_id_sets, start=1):\n",
    "#     print(f\"Set {idx}:\")\n",
    "#     for pi in pi_set:\n",
    "#         info = qualified_df[qualified_df['pi_id'] == pi].iloc[0]\n",
    "#         print(f\"  PI: {pi} | Department: {info['department']} | Program Element: {info['program_element']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: STATISTICS\n",
      "Predicted PI: 000173003\n",
      "Predicted Co-PIs: ['269948909', '269886945']\n",
      "Candidate Combined Scores: [0.97993527 1.00498589 0.88427914]\n",
      "--------------------------------------------------\n",
      "Topic: AI Circuits design\n",
      "Predicted PI: 269794080\n",
      "Predicted Co-PIs: ['269807623', '269879497']\n",
      "Candidate Combined Scores: [0.89764881 1.03518402 0.91554893]\n",
      "--------------------------------------------------\n",
      "Topic: hardware software co-design\n",
      "Predicted PI: 269794080\n",
      "Predicted Co-PIs: ['269807623', '269879497']\n",
      "Candidate Combined Scores: [0.92971756 0.93638837 0.8663779 ]\n",
      "--------------------------------------------------\n",
      "Topic: Trustworthy AI\n",
      "Predicted PI: 270021884\n",
      "Predicted Co-PIs: ['269677663', '269988546']\n",
      "Candidate Combined Scores: [0.7858882  0.92252901 0.94673603]\n",
      "--------------------------------------------------\n",
      "Topic: Networking safety\n",
      "Predicted PI: 269814599\n",
      "Predicted Co-PIs: ['269677663', '269988546']\n",
      "Candidate Combined Scores: [0.83801364 0.85126384 0.9884872 ]\n",
      "--------------------------------------------------\n",
      "Topic: Bioinformatics\n",
      "Predicted PI: 269958535\n",
      "Predicted Co-PIs: ['269811881', '270083608']\n",
      "Candidate Combined Scores: [0.96514744 1.01065257 0.9150156 ]\n",
      "--------------------------------------------------\n",
      "Topic: Robotics\n",
      "Predicted PI: 270082637\n",
      "Predicted Co-PIs: ['269726900', '269963435']\n",
      "Candidate Combined Scores: [0.90651808 0.63886027 0.81413151]\n",
      "--------------------------------------------------\n",
      "Topic: AI in Robotics\n",
      "Predicted PI: 270021884\n",
      "Predicted Co-PIs: ['270082637', '269726900']\n",
      "Candidate Combined Scores: [0.87641741 0.65158571 0.95247926]\n",
      "--------------------------------------------------\n",
      "Topic: Algorithm\n",
      "Predicted PI: 269769382\n",
      "Predicted Co-PIs: ['269934201', '269911544']\n",
      "Candidate Combined Scores: [0.8769478  1.00673104 0.91600037]\n",
      "--------------------------------------------------\n",
      "Topic: Data Science\n",
      "Predicted PI: 269721983\n",
      "Predicted Co-PIs: ['269928133', '000171581']\n",
      "Candidate Combined Scores: [1.23958707 0.94786703 0.8647293 ]\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "candidate_sets = [\n",
    "    (['269948909', '000173003', '269886945'], 'STATISTICS'),\n",
    "    (['269807623', '269794080', '269879497'], 'AI Circuits design'),\n",
    "    (['269807623', '269794080', '269879497'], 'hardware software co-design'),\n",
    "    (['269677663', '269988546', '270021884'], 'Trustworthy AI'),\n",
    "    (['269677663', '269988546', '269814599'], 'Networking safety'),\n",
    "    (['269811881', '269958535', '270083608'], 'Bioinformatics'),\n",
    "    (['270082637', '269726900', '269963435'], 'Robotics'),\n",
    "    (['270082637', '269726900', '270021884'], 'AI in Robotics'),\n",
    "    (['269934201', '269769382', '269911544'], 'Algorithm'),\n",
    "    (['269721983', '269928133', '000171581'], 'Data Science')\n",
    "]\n",
    "\n",
    "for pi_ids, topic in candidate_sets:\n",
    "    print(f\"Topic: {topic}\")\n",
    "    pi_candidate, co_pi_candidates, scores = rank_candidates(topic, pi_ids)\n",
    "    print(\"Predicted PI:\", pi_candidate)\n",
    "    print(\"Predicted Co-PIs:\", co_pi_candidates)\n",
    "    print(\"Candidate Combined Scores:\", scores)\n",
    "    # display(df[df.pi_id.isin(pi_ids)][['pi_id', 'pi_full_name', 'role', 'department', 'leadership', 'experience_years', 'program_element']])\n",
    "    # display(df_grouped[df_grouped.pi_id.isin(pi_ids)][['pi_id', 'award_count', 'experience_years', 'leadership']])\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import random\n",
    "\n",
    "# for i in range(20):\n",
    "#     pi_ids = candidate_sets[random.randint(1, 10) - 1][0]\n",
    "#     topic = candidate_sets[random.randint(1, 10) - 1][1]\n",
    "#     print(f\"Topic: {topic}\")\n",
    "#     pi_candidate, co_pi_candidates, scores = rank_candidates(topic, pi_ids)\n",
    "#     print(\"Predicted PI:\", pi_candidate)\n",
    "#     print(\"Predicted Co-PIs:\", co_pi_candidates)\n",
    "#     print(\"Candidate Combined Scores:\", scores)\n",
    "#     print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# pi = [269948909, 000173003, 269886945], topic = 'STATISTICS'\n",
    "# pi = [269807623, 269794080, 269879497], topic = 'AI Circuits design'\n",
    "# pi = [269807623, 269794080, 269879497], topic = 'hardware software co-design'\n",
    "# pi = [269677663, 269988546, 270021884], topic = 'Trustworthy AI'\n",
    "# pi = [269677663, 269988546, 269814599], topic = 'Networking safety'\n",
    "# pi = [269811881, 269958535, 270083608], topic = 'Bioinformatics'\n",
    "# pi = [270082637, 269726900, 269963435], topic = 'Robotics'\n",
    "# pi = [270082637, 269726900, 270021884], topic = 'AI in Robotics'\n",
    "# pi = [269934201, 269769382, 269911544], topic = 'Algorithm'\n",
    "# pi = [269721983, 269928133, 000171581], topic = 'Data Science'\n",
    "# rank_candidates(research_topic, candidate_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[df['pi_id'] == '000173003'][['pi_full_name', 'pi_id', 'role', 'department', 'leadership', 'experience_years', 'program_element']]\n",
    "df[df.pi_id == '269769382']['pi_full_name'].to_list()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.pi_full_name == 'Xin Zhang']['pi_id'].to_list()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pi_ids_to_analyze = ['270082637', '269726900', '270021884']\n",
    "df[df.pi_id.isin(pi_ids_to_analyze)][['pi_id', 'pi_full_name', 'role', 'department', 'leadership', 'experience_years', 'program_element']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_r = [1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = [1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1]  # predicted\n",
    "y_true = [1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1]  # actual/ground truth\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "\n",
    "precision = precision_score(y_true, y_pred)\n",
    "recall = recall_score(y_true, y_pred)\n",
    "f1 = f1_score(y_true, y_pred)\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1 Score: {f1}\")\n",
    "print(f\"Accuracy: {accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample raw results (each as a string).\n",
    "raw_results = [\n",
    "    \"['269948909', '000173003', '269886945'] - STATISTICS - Xin Zhang - 269948909 - correct\",\n",
    "    \"['269807623', '269794080', '269879497'] - AI Circuits design - Azadeh Davoodi - 269794080 - correct\",\n",
    "    \"['269807623', '269794080', '269879497'] - hardware software co-design - Azadeh Davoodi - 269794080 - correct\",\n",
    "    \"['269677663', '269988546', '270021884'] - Trustworthy AI - Benjamin Fuller - 269988546 - wrong\",\n",
    "    \"['269677663', '269988546', '269814599'] - Networking safety - Benjamin Fuller - 269988546 - correct\",\n",
    "    \"['269811881', '269958535', '270083608'] - Bioinformatics - Jianlin Cheng - 269811881 - correct\",\n",
    "    \"['270082637', '269726900', '269963435'] - Robotics - Rodrigo O Spinola - 270082637 - correct\",\n",
    "    \"['270082637', '269726900', '270021884'] - AI in Robotics - Guido F Montufar Cuartas - 270021884 - wrong\",\n",
    "    \"['269934201', '269769382', '269911544'] - Algorithm - Michael Dinitz - 269934201 - correct\",\n",
    "    \"['269721983', '269928133', '000171581'] - Data Science - Sofya Raskhodnikova - 269721983 - correct\",\n",
    "    \"\",\n",
    "    \"['000025017', '000025762', '000030655'] - knowledge graph - Steven N MacEachern - 000025762 - correct\",\n",
    "    \"['000025017', '000025762', '000030655'] - AI - Steven N MacEachern - 000025762 - correct\",\n",
    "    \"['000025017', '000025762', '000030655'] - Neuroscience - Steven N MacEachern - 000025762 - correct\",\n",
    "    \"['000025017', '000025762', '000030655'] - STATISTICS - Steven N MacEachern - 000025762 - correct\"\n",
    "]\n",
    "\n",
    "# Initialize counters.\n",
    "tp = 0  # true positives\n",
    "fp = 0  # false positives\n",
    "fn = 0  # false negatives\n",
    "total = 0  # total evaluated samples\n",
    "\n",
    "# Loop through each line in the results.\n",
    "for line in raw_results:\n",
    "    # Skip empty lines (if any)\n",
    "    if not line.strip():\n",
    "        continue\n",
    "\n",
    "    total += 1\n",
    "    \n",
    "    # The label is the last token when splitting by ' - '\n",
    "    # We assume that the parts are separated by \" - \" and the last part is the status.\n",
    "    parts = line.split(\" - \")\n",
    "    status = parts[-1].strip().lower()  # e.g., 'correct', 'wrong', 'waiting'\n",
    "    \n",
    "    if status == \"correct\":\n",
    "        tp += 1\n",
    "    elif status == \"wrong\":\n",
    "        # A wrong prediction means the algorithm made a prediction but it did not match\n",
    "        # the true answer. This counts as a false positive and a missed correct answer (FN).\n",
    "        fp += 1\n",
    "        fn += 1\n",
    "    else:\n",
    "        print(f\"Unrecognized status: {status}\")\n",
    "\n",
    "# Calculate precision, recall, F1 and accuracy rate.\n",
    "if (tp + fp) > 0:\n",
    "    precision = tp / (tp + fp)\n",
    "else:\n",
    "    precision = 0\n",
    "\n",
    "if (tp + fn) > 0:\n",
    "    recall = tp / (tp + fn)\n",
    "else:\n",
    "    recall = 0\n",
    "\n",
    "if (precision + recall) > 0:\n",
    "    f1 = 2 * (precision * recall) / (precision + recall)\n",
    "else:\n",
    "    f1 = 0\n",
    "\n",
    "accuracy = tp / total if total > 0 else 0\n",
    "\n",
    "# Display the results.\n",
    "print(\"Evaluation metrics:\")\n",
    "print(\"-------------------\")\n",
    "print(f\"Total samples: {total}\")\n",
    "print(f\"Correct (TP): {tp}\")\n",
    "print(f\"Wrong (FP): {fp}\")\n",
    "print(f\"Waiting (FN): {fn}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall:    {recall:.4f}\")\n",
    "print(f\"F1 score:  {f1:.4f}\")\n",
    "print(f\"Accuracy:  {accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Updated raw results list.\n",
    "raw_results = [\n",
    "    \"['269948909', '000173003', '269886945'] - STATISTICS - 000173003 - Peter D Hislop - 2nd most optimal option\",\n",
    "    \"['269807623', '269794080', '269879497'] - AI Circuits design - 269794080 - Azadeh Davoodi - correct\",\n",
    "    \"['269807623', '269794080', '269879497'] - hardware software co-design - 269794080 - Azadeh Davoodi - correct\",\n",
    "    \"['269677663', '269988546', '270021884'] - Trustworthy AI - 270021884 - Guido F Montufar Cuartas - correct\",\n",
    "    \"['269677663', '269988546', '269814599'] - Networking safety - 269814599 - Srinivas Shakkottai - wrong\",\n",
    "    \"['269811881', '269958535', '270083608'] - Bioinformatics - 269958535 - HaiYing   Wang - wrong\",\n",
    "    \"['270082637', '269726900', '269963435'] - Robotics - 270082637 - Rodrigo O Spinola - correct\",\n",
    "    \"['270082637', '269726900', '270021884'] - AI in Robotics - 270021884 - Guido F Montufar Cuartas - wrong\",\n",
    "    \"['269934201', '269769382', '269911544'] - Algorithm - 269769382 - Susan D Nickerson - wrong\",\n",
    "    \"['269721983', '269928133', '000171581'] - Data Science - 269721983 - Sofya Raskhodnikova - correct\",\n",
    "    \"['000025017', '000025762', '000030655'] - knowledge graph - 000025762 - Steven N MacEachern - correct\",\n",
    "    \"['000025017', '000025762', '000030655'] - AI - 000025762 - Steven N MacEachern - correct\",\n",
    "    \"['000025017', '000025762', '000030655'] - Neuroscience - 000025762 - Steven N MacEachern - correct\",\n",
    "    \"['000025017', '000025762', '000030655'] - STATISTICS - 000025762 - Steven N MacEachern - correct\"\n",
    "]\n",
    "\n",
    "# Initialize counters.\n",
    "tp = 0  # true positives\n",
    "fp = 0  # false positives\n",
    "fn = 0  # false negatives\n",
    "total = 0  # total valid samples\n",
    "\n",
    "# Process each line in the results.\n",
    "for line in raw_results:\n",
    "    if not line.strip():\n",
    "        continue  # Skip empty lines.\n",
    "    \n",
    "    total += 1\n",
    "    parts = line.split(\" - \")\n",
    "    # The final token is the prediction label.\n",
    "    outcome = parts[-1].strip().lower()\n",
    "    \n",
    "    # Count outcomes; only exactly 'correct' is TP.\n",
    "    if outcome == \"correct\":\n",
    "        tp += 1\n",
    "    elif outcome in [\"wrong\", \"2nd most optimal option\"]:\n",
    "        fp += 1\n",
    "        fn += 1\n",
    "    else:\n",
    "        print(f\"Unrecognized status: {outcome}\")\n",
    "\n",
    "# Compute metrics.\n",
    "precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "recall    = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "f1        = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "accuracy  = tp / total if total > 0 else 0\n",
    "\n",
    "# Output the results.\n",
    "print(\"Evaluation metrics:\")\n",
    "print(\"-------------------\")\n",
    "print(f\"Total samples: {total}\")\n",
    "print(f\"Correct (TP): {tp}\")\n",
    "print(f\"Wrong (FP): {fp}\")\n",
    "print(f\"False Negatives (FN): {fn}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall:    {recall:.4f}\")\n",
    "print(f\"F1 score:  {f1:.4f}\")\n",
    "print(f\"Accuracy:  {accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agent",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
