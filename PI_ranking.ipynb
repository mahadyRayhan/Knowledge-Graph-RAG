{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/agent/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv() ## load all the environment variables from .env\n",
    "import glob\n",
    "# import streamlit as st\n",
    "import os\n",
    "from PIL import Image\n",
    "import google.generativeai as genai\n",
    "from IPython.display import display\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import textwrap\n",
    "from typing import List, Dict, Tuple, Optional # For type hinting\n",
    "import time\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "genai.configure(api_key=os.getenv(\"GOOGLE_API_KEY\"))\n",
    "\n",
    "## Load Gemini model\n",
    "model=genai.GenerativeModel('gemini-2.0-flash-thinking-exp-01-21')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gemini_response(input,image,user_prompt):\n",
    "    response=model.generate_content([input,image[0],user_prompt])\n",
    "    return response.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DATA Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading files in 2022...\n",
      "Reading files in 2024...\n",
      "Reading files in 2023...\n",
      "Reading files in 2021...\n",
      "Reading files in 2020...\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "data_directory = 'data/ranking_data/'\n",
    "records = []\n",
    "\n",
    "def safe_get(data, keys, default=None):\n",
    "    \"\"\"\n",
    "    Safely get a nested key from a dictionary using a list of keys.\n",
    "    Returns default if any key is missing.\n",
    "    \"\"\"\n",
    "    for key in keys:\n",
    "        if isinstance(data, dict) and key in data:\n",
    "            data = data[key]\n",
    "        else:\n",
    "            return default\n",
    "    return data\n",
    "\n",
    "for sub_dir in os.listdir(data_directory):\n",
    "    print(f\"Reading files in {sub_dir}...\")\n",
    "    sub_directory = os.path.join(data_directory, sub_dir)\n",
    "    for filename in os.listdir(sub_directory):\n",
    "        if filename.endswith('.json'):\n",
    "            filepath = os.path.join(sub_directory, filename)\n",
    "            try:\n",
    "                with open(filepath, 'r') as file:\n",
    "                    data = json.load(file)\n",
    "            except Exception as e:\n",
    "                print(f\"Error reading {filepath}: {e}\")\n",
    "                continue\n",
    "\n",
    "            # Extract award-level context information safely\n",
    "            award_type = data.get(\"awd_istr_txt\")\n",
    "            award_title = data.get(\"awd_titl_txt\")\n",
    "            abstract = data.get(\"abst_narr_txt\")\n",
    "            org_name = data.get(\"org_long_name\")\n",
    "            org_name2 = data.get(\"org_long_name2\")\n",
    "            perf_inst_name = safe_get(data, [\"perf_inst\", \"perf_inst_name\"])\n",
    "            \n",
    "            # Extract program element and reference safely (checking if list exists)\n",
    "            pgm_ele_list = data.get(\"pgm_ele\")\n",
    "            if isinstance(pgm_ele_list, list) and len(pgm_ele_list) > 0:\n",
    "                program_element = pgm_ele_list[0].get(\"pgm_ele_long_name\")\n",
    "            else:\n",
    "                program_element = None\n",
    "\n",
    "            pgm_ref_list = data.get(\"pgm_ref\")\n",
    "            if isinstance(pgm_ref_list, list) and len(pgm_ref_list) > 0:\n",
    "                program_reference = pgm_ref_list[0].get(\"pgm_ref_long_name\")\n",
    "            else:\n",
    "                program_reference = None\n",
    "\n",
    "            # Get investigator information, ensuring it's a list\n",
    "            pi_list = data.get(\"pi\")\n",
    "            if not isinstance(pi_list, list):\n",
    "                continue\n",
    "\n",
    "            # Loop through each investigator in the file\n",
    "            for pi in pi_list:\n",
    "                record = {\n",
    "                    \"award_type\": award_type,\n",
    "                    \"award_title\": award_title,\n",
    "                    \"abstract\": abstract,\n",
    "                    \"org_name\": org_name,\n",
    "                    \"org_name2\": org_name2,\n",
    "                    \"perf_inst_name\": perf_inst_name,\n",
    "                    \"program_element\": program_element,\n",
    "                    \"program_reference\": program_reference,\n",
    "                    \"pi_id\": pi.get(\"pi_id\"),\n",
    "                    \"pi_full_name\": pi.get(\"pi_full_name\", \"\").strip() if pi.get(\"pi_full_name\") else None,\n",
    "                    \"role\": pi.get(\"proj_role_code2\", \"\").strip() if pi.get(\"proj_role_code2\") else None,\n",
    "                    \"department\": pi.get(\"pi_dept_name\"),\n",
    "                    \"email\": pi.get(\"pi_email_addr\"),\n",
    "                    \"start_date\": pi.get(\"start_date\")\n",
    "                }\n",
    "                records.append(record)\n",
    "\n",
    "# Create a DataFrame from the records\n",
    "df = pd.DataFrame(records)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>award_type</th>\n",
       "      <th>award_title</th>\n",
       "      <th>abstract</th>\n",
       "      <th>org_name</th>\n",
       "      <th>org_name2</th>\n",
       "      <th>perf_inst_name</th>\n",
       "      <th>program_element</th>\n",
       "      <th>program_reference</th>\n",
       "      <th>pi_id</th>\n",
       "      <th>pi_full_name</th>\n",
       "      <th>role</th>\n",
       "      <th>department</th>\n",
       "      <th>email</th>\n",
       "      <th>start_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Standard Grant</td>\n",
       "      <td>MRI: Acquisition of a High-Performance Computa...</td>\n",
       "      <td>This project will acquire and deploy a high-pe...</td>\n",
       "      <td>Directorate for Computer and Information Scien...</td>\n",
       "      <td>Office of Advanced Cyberinfrastructure (OAC)</td>\n",
       "      <td>Oklahoma State University</td>\n",
       "      <td>Major Research Instrumentation</td>\n",
       "      <td>WOMEN, MINORITY, DISABLED, NEC</td>\n",
       "      <td>269967889</td>\n",
       "      <td>Terrance   Figy</td>\n",
       "      <td>Co-Principal Investigator</td>\n",
       "      <td>Mathematics, Statistics, and Physics</td>\n",
       "      <td>Terrance.Figy@wichita.edu</td>\n",
       "      <td>2024-08-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Standard Grant</td>\n",
       "      <td>MRI: Acquisition of a High-Performance Computa...</td>\n",
       "      <td>This project will acquire and deploy a high-pe...</td>\n",
       "      <td>Directorate for Computer and Information Scien...</td>\n",
       "      <td>Office of Advanced Cyberinfrastructure (OAC)</td>\n",
       "      <td>Oklahoma State University</td>\n",
       "      <td>Major Research Instrumentation</td>\n",
       "      <td>WOMEN, MINORITY, DISABLED, NEC</td>\n",
       "      <td>269758255</td>\n",
       "      <td>Pratul K Agarwal</td>\n",
       "      <td>Principal Investigator</td>\n",
       "      <td></td>\n",
       "      <td>pratul.agarwal@okstate.edu</td>\n",
       "      <td>2022-08-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Standard Grant</td>\n",
       "      <td>MRI: Acquisition of a High-Performance Computa...</td>\n",
       "      <td>This project will acquire and deploy a high-pe...</td>\n",
       "      <td>Directorate for Computer and Information Scien...</td>\n",
       "      <td>Office of Advanced Cyberinfrastructure (OAC)</td>\n",
       "      <td>Oklahoma State University</td>\n",
       "      <td>Major Research Instrumentation</td>\n",
       "      <td>WOMEN, MINORITY, DISABLED, NEC</td>\n",
       "      <td>000224099</td>\n",
       "      <td>Mickey   Slimp</td>\n",
       "      <td>Co-Principal Investigator</td>\n",
       "      <td>Department of Chemistry</td>\n",
       "      <td></td>\n",
       "      <td>2024-08-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Standard Grant</td>\n",
       "      <td>MRI: Acquisition of a High-Performance Computa...</td>\n",
       "      <td>This project will acquire and deploy a high-pe...</td>\n",
       "      <td>Directorate for Computer and Information Scien...</td>\n",
       "      <td>Office of Advanced Cyberinfrastructure (OAC)</td>\n",
       "      <td>Oklahoma State University</td>\n",
       "      <td>Major Research Instrumentation</td>\n",
       "      <td>WOMEN, MINORITY, DISABLED, NEC</td>\n",
       "      <td>269666332</td>\n",
       "      <td>William H Hsu</td>\n",
       "      <td>Co-Principal Investigator</td>\n",
       "      <td>Computer Science</td>\n",
       "      <td>bhsu@ksu.edu</td>\n",
       "      <td>2022-08-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Standard Grant</td>\n",
       "      <td>MRI: Acquisition of a High-Performance Computa...</td>\n",
       "      <td>This project will acquire and deploy a high-pe...</td>\n",
       "      <td>Directorate for Computer and Information Scien...</td>\n",
       "      <td>Office of Advanced Cyberinfrastructure (OAC)</td>\n",
       "      <td>Oklahoma State University</td>\n",
       "      <td>Major Research Instrumentation</td>\n",
       "      <td>WOMEN, MINORITY, DISABLED, NEC</td>\n",
       "      <td>270046494</td>\n",
       "      <td>Robert   Fleming</td>\n",
       "      <td>Co-Principal Investigator</td>\n",
       "      <td>Engineering</td>\n",
       "      <td>rofleming@AState.edu</td>\n",
       "      <td>2024-08-29</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       award_type                                        award_title  \\\n",
       "0  Standard Grant  MRI: Acquisition of a High-Performance Computa...   \n",
       "1  Standard Grant  MRI: Acquisition of a High-Performance Computa...   \n",
       "2  Standard Grant  MRI: Acquisition of a High-Performance Computa...   \n",
       "4  Standard Grant  MRI: Acquisition of a High-Performance Computa...   \n",
       "7  Standard Grant  MRI: Acquisition of a High-Performance Computa...   \n",
       "\n",
       "                                            abstract  \\\n",
       "0  This project will acquire and deploy a high-pe...   \n",
       "1  This project will acquire and deploy a high-pe...   \n",
       "2  This project will acquire and deploy a high-pe...   \n",
       "4  This project will acquire and deploy a high-pe...   \n",
       "7  This project will acquire and deploy a high-pe...   \n",
       "\n",
       "                                            org_name  \\\n",
       "0  Directorate for Computer and Information Scien...   \n",
       "1  Directorate for Computer and Information Scien...   \n",
       "2  Directorate for Computer and Information Scien...   \n",
       "4  Directorate for Computer and Information Scien...   \n",
       "7  Directorate for Computer and Information Scien...   \n",
       "\n",
       "                                      org_name2             perf_inst_name  \\\n",
       "0  Office of Advanced Cyberinfrastructure (OAC)  Oklahoma State University   \n",
       "1  Office of Advanced Cyberinfrastructure (OAC)  Oklahoma State University   \n",
       "2  Office of Advanced Cyberinfrastructure (OAC)  Oklahoma State University   \n",
       "4  Office of Advanced Cyberinfrastructure (OAC)  Oklahoma State University   \n",
       "7  Office of Advanced Cyberinfrastructure (OAC)  Oklahoma State University   \n",
       "\n",
       "                  program_element               program_reference      pi_id  \\\n",
       "0  Major Research Instrumentation  WOMEN, MINORITY, DISABLED, NEC  269967889   \n",
       "1  Major Research Instrumentation  WOMEN, MINORITY, DISABLED, NEC  269758255   \n",
       "2  Major Research Instrumentation  WOMEN, MINORITY, DISABLED, NEC  000224099   \n",
       "4  Major Research Instrumentation  WOMEN, MINORITY, DISABLED, NEC  269666332   \n",
       "7  Major Research Instrumentation  WOMEN, MINORITY, DISABLED, NEC  270046494   \n",
       "\n",
       "       pi_full_name                       role  \\\n",
       "0   Terrance   Figy  Co-Principal Investigator   \n",
       "1  Pratul K Agarwal     Principal Investigator   \n",
       "2    Mickey   Slimp  Co-Principal Investigator   \n",
       "4     William H Hsu  Co-Principal Investigator   \n",
       "7  Robert   Fleming  Co-Principal Investigator   \n",
       "\n",
       "                             department                       email  \\\n",
       "0  Mathematics, Statistics, and Physics   Terrance.Figy@wichita.edu   \n",
       "1                                        pratul.agarwal@okstate.edu   \n",
       "2               Department of Chemistry                               \n",
       "4                      Computer Science                bhsu@ksu.edu   \n",
       "7                           Engineering        rofleming@AState.edu   \n",
       "\n",
       "   start_date  \n",
       "0  2024-08-29  \n",
       "1  2022-08-03  \n",
       "2  2024-08-29  \n",
       "4  2022-08-03  \n",
       "7  2024-08-29  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[df['role'].isin(['Co-Principal Investigator', 'Principal Investigator'])]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(83112, 14)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_csv('combined_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scholer Identifier LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_data_by_pi(df: pd.DataFrame, pi_ids: List[str]) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Filters the DataFrame to include only rows matching the provided PI IDs.\n",
    "\n",
    "    Args:\n",
    "        df: The input DataFrame.\n",
    "        pi_ids: A list of PI IDs (strings) to filter by.\n",
    "\n",
    "    Returns:\n",
    "        A DataFrame containing only the rows for the specified PI IDs.\n",
    "    \"\"\"\n",
    "    print(f\"Filtering DataFrame for PI IDs: {pi_ids}...\")\n",
    "    filtered = df[df['pi_id'].isin(pi_ids)].copy()\n",
    "    # print(f\"Found {len(filtered)} relevant entries.\")\n",
    "    return filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_pi_data_for_prompt(filtered_df: pd.DataFrame, pi_ids_to_format: List[str]) -> Tuple[str, Dict[str, str]]:\n",
    "    \"\"\"\n",
    "    Formats the filtered PI data into a string suitable for the prompt context.\n",
    "\n",
    "    Args:\n",
    "        filtered_df: The DataFrame already filtered for relevant PIs.\n",
    "        pi_ids_to_format: The original list of PI IDs requested, to ensure all are mentioned.\n",
    "\n",
    "\n",
    "    Returns:\n",
    "        A tuple containing:\n",
    "            - formatted_data_string: A string with formatted details for each PI.\n",
    "            - pi_names_dict: A dictionary mapping PI ID to PI full name.\n",
    "    \"\"\"\n",
    "    # print(\"Formatting data for prompt...\")\n",
    "    formatted_data = \"\"\n",
    "    pi_names = {} # Dictionary to store PI names\n",
    "\n",
    "    if filtered_df.empty:\n",
    "        print(\"Warning: Filtered DataFrame is empty. Formatting 'no data' message.\")\n",
    "        formatted_data = \"No data could be retrieved for the specified potential collaborators.\\n\"\n",
    "        for pi_id in pi_ids_to_format:\n",
    "             pi_names[pi_id] = f\"PI ID {pi_id}\" # Use ID as placeholder name\n",
    "        return formatted_data, pi_names\n",
    "\n",
    "    # Iterate through the original list to ensure all requested PIs are accounted for\n",
    "    for pi_id in pi_ids_to_format:\n",
    "        pi_specific_data = filtered_df[filtered_df['pi_id'] == pi_id]\n",
    "\n",
    "        if not pi_specific_data.empty:\n",
    "            # Get consistent name and department from the first entry\n",
    "            full_name = pi_specific_data['pi_full_name'].iloc[0]\n",
    "            department = pi_specific_data['department'].iloc[0]\n",
    "            pi_names[pi_id] = full_name\n",
    "\n",
    "            formatted_data += f\"--- Researcher: {full_name} (ID: {pi_id}) ---\\n\"\n",
    "            formatted_data += f\"Department: {department}\\n\"\n",
    "            formatted_data += \"Relevant Roles & Awards Found:\\n\"\n",
    "\n",
    "            for index, row in pi_specific_data.iterrows():\n",
    "                formatted_data += f\"- Role: {row.get('role', 'N/A')}\\n\"\n",
    "                formatted_data += f\"  Award Title: {row.get('award_title', 'N/A')}\\n\"\n",
    "                formatted_data += f\"  Start Date: {row.get('start_date', 'N/A')}\\n\"\n",
    "                abstract_preview = textwrap.shorten(row.get('abstract', 'N/A'), width=200, placeholder=\"...\")\n",
    "                formatted_data += f\"  Abstract Snippet: {abstract_preview}\\n\"\n",
    "                formatted_data += f\"  Program Element/Reference: {row.get('program_element', 'N/A')} / {row.get('program_reference', 'N/A')}\\n\\n\"\n",
    "        else:\n",
    "            # Handle case where a specific PI ID from the list had no data in the filtered df\n",
    "            formatted_data += f\"--- Researcher ID: {pi_id} ---\\n\"\n",
    "            formatted_data += \"No award data found in the provided dataset for this PI.\\n\\n\"\n",
    "            pi_names[pi_id] = f\"PI ID {pi_id}\" # Use ID as placeholder name\n",
    "\n",
    "    # print(\"Data formatting complete.\")\n",
    "    return formatted_data, pi_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_recommendation_prompt(formatted_data_string: str, pi_names_dict: Dict[str, str], research_topic: str) -> str:\n",
    "    \"\"\"\n",
    "    Generates the full prompt string for the Gemini model.\n",
    "\n",
    "    Args:\n",
    "        formatted_data_string: The formatted string containing PI details.\n",
    "        pi_names_dict: A dictionary mapping PI ID to PI name.\n",
    "        research_topic: The research topic for collaboration.\n",
    "\n",
    "    Returns:\n",
    "        The complete prompt string.\n",
    "    \"\"\"\n",
    "    # print(\"Generating prompt...\")\n",
    "    collaborator_names_list = \", \".join(pi_names_dict.values())\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "        Context:\n",
    "        The following researchers ({collaborator_names_list}) are considering collaborating on a new research project focused on the topic '{research_topic}'. Below is information extracted from a database about their previous grants and roles:\n",
    "\n",
    "        {formatted_data_string}\n",
    "\n",
    "        Task:\n",
    "        Based *only* on the information provided above, please analyze the qualifications, experience, and relevance of past work for each researcher ({collaborator_names_list}). Recommend which of these individuals would be the most suitable Principal Investigator (PI) to lead this new collaborative project on '{research_topic}'.\n",
    "\n",
    "        Provide a detailed explanation for your recommendation. Consider factors apparent from the data, such as:\n",
    "        - Direct relevance of their past research (award titles, abstracts, program elements) to the topic '{research_topic}'.\n",
    "        - Demonstrated experience (e.g., number of awards listed, roles held like 'Principal Investigator').\n",
    "        - Any indicators of leadership or seniority (e.g., award types like 'Career Award' if present, consistent PI roles).\n",
    "\n",
    "        Please identify the suggested PI clearly by name.\n",
    "        \"\"\"\n",
    "    # print(\"Prompt generated.\")\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Please identify the suggested PI clearly by name and justify your choice thoroughly using specific evidence from the provided context. If the data is insufficient to make a strong recommendation for any particular candidate, please state that clearly as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gemini_response(model: genai.GenerativeModel, prompt: str) -> Tuple[Optional[str], float]:\n",
    "    \"\"\"\n",
    "    Sends the prompt to the Gemini model, streams the response, and measures time.\n",
    "\n",
    "    Args:\n",
    "        model: The configured Gemini model object.\n",
    "        prompt: The prompt string to send to the model.\n",
    "\n",
    "    Returns:\n",
    "        A tuple containing:\n",
    "            - The full response text as a string (or None if an error occurs).\n",
    "            - The time taken for the API call in seconds.\n",
    "    \"\"\"\n",
    "    # print(\"--- Sending Request to Gemini ---\")\n",
    "    start_time = time.time()\n",
    "    full_response_text = \"\"\n",
    "    contents = [prompt] # Prepare contents for the API\n",
    "\n",
    "    try:\n",
    "        responses = model.generate_content(contents, stream=True)\n",
    "        # responses = model.generate_content(contents)\n",
    "\n",
    "        # print(\"\\n-------Response--------\")\n",
    "        for response in responses:\n",
    "            # print(response.text, end=\"\")\n",
    "            full_response_text += response.text\n",
    "        # print(\"\\n-----------------------\")\n",
    "        PI_NAME = full_response_text.split('\\n')[-1].strip()\n",
    "        print(f\"\\nPI: {PI_NAME}\")\n",
    "\n",
    "        response_time = time.time() - start_time\n",
    "        print(f\"\\nResponse generated in {response_time:.2f} seconds.\")\n",
    "        return full_response_text, response_time\n",
    "\n",
    "    except AttributeError:\n",
    "        response_time = time.time() - start_time\n",
    "        print(\"\\nError: 'model' object not found or not configured correctly.\")\n",
    "        print(\"Please ensure the 'model' variable holds your loaded Gemini model.\")\n",
    "        return None, response_time\n",
    "    except Exception as e:\n",
    "        response_time = time.time() - start_time\n",
    "        print(f\"\\nAn error occurred during the API call: {e}\")\n",
    "        print(f\"Attempt failed after {response_time:.2f} seconds.\")\n",
    "        return None, response_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_pi(df: pd.DataFrame, model: genai.GenerativeModel, pi_ids: List[str], research_topic: str) -> Optional[str]:\n",
    "    \"\"\"\n",
    "    Orchestrates the process of filtering data, formatting, generating prompt,\n",
    "    and getting a PI recommendation from the Gemini model.\n",
    "\n",
    "    Args:\n",
    "        df: The main DataFrame.\n",
    "        model: The configured Gemini model object.\n",
    "        pi_ids: A list of PI IDs to consider.\n",
    "        research_topic: The topic for collaboration.\n",
    "\n",
    "    Returns:\n",
    "        The recommendation text from the model, or None if an error occurred\n",
    "        or essential steps failed.\n",
    "    \"\"\"\n",
    "    print(f\"\\n--- Starting PI Recommendation Process for Topic: '{research_topic}' ---\")\n",
    "\n",
    "    # 1. Filter Data\n",
    "    filtered_data = filter_data_by_pi(df, pi_ids)\n",
    "    # Optional: Add a check here if you want to stop if no data is found at all\n",
    "    # if filtered_data.empty:\n",
    "    #     print(\"Stopping process as no data was found for any specified PI.\")\n",
    "    #     return None\n",
    "\n",
    "    # 2. Format Data\n",
    "    # Pass the original pi_ids list to ensure all are mentioned in formatting\n",
    "    formatted_text, pi_names = format_pi_data_for_prompt(filtered_data, pi_ids)\n",
    "\n",
    "    # 3. Generate Prompt\n",
    "    prompt_text = generate_recommendation_prompt(formatted_text, pi_names, research_topic)\n",
    "\n",
    "    # 4. Get Response\n",
    "    recommendation, duration = get_gemini_response(model, prompt_text)\n",
    "\n",
    "    # print(f\"--- PI Recommendation Process Complete ({duration:.2f}s) ---\")\n",
    "    return recommendation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Starting PI Recommendation Process for Topic: 'STATISTICS' ---\n",
      "Filtering DataFrame for PI IDs: ['000025017', '000025762', '000030655']...\n",
      "\n",
      "PI: In conclusion, while Howard B Bluestein has more overall research experience and leadership in meteorological projects, **Steven N MacEachern's** direct expertise, departmental affiliation, and proven leadership in statistics-related research make him the most appropriate and qualified individual to serve as the Principal Investigator for a new collaborative project specifically focused on 'STATISTICS'.\n",
      "\n",
      "Response generated in 27.97 seconds.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    pi_ids_to_analyze = ['000025017', '000025762', '000030655']\n",
    "    research_topic = 'STATISTICS'\n",
    "\n",
    "    # --- Run the Recommendation Process ---\n",
    "    recommendation_result = recommend_pi(df, model, pi_ids_to_analyze, research_topic)\n",
    "\n",
    "    # Optional: Do something with the result\n",
    "    if recommendation_result:\n",
    "        # print(\"\\n--- Final Recommendation Text ---\")\n",
    "        # print(recommendation_result) # Already printed during streaming\n",
    "        pass # Result is already printed by get_gemini_response\n",
    "    else:\n",
    "        print(\"\\nRecommendation could not be generated.\")\n",
    "\n",
    "except ImportError:\n",
    "    print(\"Please install required libraries: pip install pandas google-generativeai\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred during setup or execution: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing with topic: knowledge graph\n",
      "\n",
      "--- Starting PI Recommendation Process for Topic: 'knowledge graph' ---\n",
      "Filtering DataFrame for PI IDs: ['000025017', '000025762', '000030655']...\n",
      "\n",
      "PI: **In conclusion, despite Bluestein having more overall research experience and PI roles, MacEachern's statistical background and the keywords associated with his research (data-driven, actionable knowledge) suggest a more conceptually aligned foundation for leading a project on 'knowledge graph' within the constraints of the provided information.** It is crucial to acknowledge that this recommendation is based *only* on the limited data provided. Further information about the specific nature of the 'knowledge graph' project and the researchers' broader skill sets might alter this assessment.\n",
      "\n",
      "Response generated in 11.53 seconds.\n",
      "--------------------------------------------------\n",
      "Testing with topic: AI\n",
      "\n",
      "--- Starting PI Recommendation Process for Topic: 'AI' ---\n",
      "Filtering DataFrame for PI IDs: ['000025017', '000025762', '000030655']...\n",
      "\n",
      "PI: **Therefore, Steven N MacEachern is recommended as the most suitable Principal Investigator for this 'AI' collaborative project based on the information provided.**\n",
      "\n",
      "Response generated in 11.13 seconds.\n",
      "--------------------------------------------------\n",
      "Testing with topic: Neuroscience\n",
      "\n",
      "--- Starting PI Recommendation Process for Topic: 'Neuroscience' ---\n",
      "Filtering DataFrame for PI IDs: ['000025017', '000025762', '000030655']...\n",
      "\n",
      "PI: **In conclusion, while ideally a PI for a Neuroscience project would have direct experience in the field, among the provided researchers, Steven N MacEachern is the *most* suitable choice based on his demonstrated leadership as a PI and the *potential*, albeit weak, indirect relevance of his statistical expertise to data-driven scientific research, including potentially some areas within Neuroscience. However, it is crucial to acknowledge that none of them are ideal candidates based purely on the provided information and their past work.**\n",
      "\n",
      "Response generated in 18.82 seconds.\n",
      "--------------------------------------------------\n",
      "Testing with topic: STATISTICS\n",
      "\n",
      "--- Starting PI Recommendation Process for Topic: 'STATISTICS' ---\n",
      "Filtering DataFrame for PI IDs: ['000025017', '000025762', '000030655']...\n",
      "\n",
      "PI: **In summary, Steven N MacEachern's direct expertise in statistics, evidenced by his department, project titles, abstracts, program elements, and PI experience in the field, makes him the most qualified and recommended individual to serve as the Principal Investigator for a new collaborative project on 'STATISTICS'.**\n",
      "\n",
      "Response generated in 12.89 seconds.\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Test with various topics dynamically.\n",
    "for test_topic in [\"knowledge graph\", \"AI\", \"Neuroscience\", \"STATISTICS\"]:\n",
    "    print(\"Testing with topic:\", test_topic)\n",
    "    recommendation_result = recommend_pi(df, model, pi_ids_to_analyze, test_topic)\n",
    "    # print(\"Predicted PI:\", pi_candidate)\n",
    "    # print(\"Predicted Co-PIs:\", co_pi_candidates)\n",
    "    # print(\"Candidate Combined Scores:\", scores)\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "candidate_sets = [\n",
    "    (['269948909', '000173003', '269886945'], 'STATISTICS'),\n",
    "    (['269807623', '269794080', '269879497'], 'AI Circuits design'),\n",
    "    (['269807623', '269794080', '269879497'], 'hardware software co-design'),\n",
    "    (['269677663', '269988546', '270021884'], 'Trustworthy AI'),\n",
    "    (['269677663', '269988546', '269814599'], 'Networking safety'),\n",
    "    (['269811881', '269958535', '270083608'], 'Bioinformatics'),\n",
    "    (['270082637', '269726900', '269963435'], 'Robotics'),\n",
    "    (['270082637', '269726900', '270021884'], 'AI in Robotics'),\n",
    "    (['269934201', '269769382', '269911544'], 'Algorithm'),\n",
    "    (['269721983', '269928133', '000171581'], 'Data Science')\n",
    "]\n",
    "\n",
    "for pi_ids, topic in candidate_sets:\n",
    "    recommendation_result = recommend_pi(df, model, pi_ids, topic) #recommend_pi(df, model, pi_ids_to_analyze, research_topic)\n",
    "    # print(\"Predicted PI:\", pi_candidate)\n",
    "    # print(\"Predicted Co-PIs:\", co_pi_candidates)\n",
    "    # print(\"Candidate Combined Scores:\", scores)\n",
    "    print(\"-\" * 50)\n",
    "    # break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Influencer - from a list of PI's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import textwrap\n",
    "from typing import List, Dict, Tuple, Optional # For type hinting\n",
    "import google.generativeai as genai # Assuming genai is already configured\n",
    "\n",
    "# --- Helper Function to get Collaborators for specific awards ---\n",
    "# (This is needed for format_influencer_data)\n",
    "def get_collaborators_for_awards(df: pd.DataFrame, award_titles: List[str]) -> Dict[str, List[str]]:\n",
    "    \"\"\"\n",
    "    Finds all PIs/Co-PIs associated with a list of award titles.\n",
    "\n",
    "    Args:\n",
    "        df: The main DataFrame.\n",
    "        award_titles: A list of award titles.\n",
    "\n",
    "    Returns:\n",
    "        A dictionary where keys are award titles and values are lists of\n",
    "        PI/Co-PI full names on that award.\n",
    "    \"\"\"\n",
    "    collaborators = {}\n",
    "    relevant_awards_df = df[df['award_title'].isin(award_titles)]\n",
    "    for title in award_titles:\n",
    "        # Filter for the specific award title and valid roles\n",
    "        award_pis = relevant_awards_df[\n",
    "            (relevant_awards_df['award_title'] == title) &\n",
    "            (relevant_awards_df['role'].isin(['Principal Investigator', 'Co-Principal Investigator']))\n",
    "        ]\n",
    "        # Get unique names, handling potential missing names\n",
    "        names = [name for name in award_pis['pi_full_name'].unique() if pd.notna(name)]\n",
    "        collaborators[title] = names\n",
    "    return collaborators\n",
    "\n",
    "# --- New Function 1: Format Data for Influencer Prompt ---\n",
    "def format_influencer_data(df: pd.DataFrame, pi_ids: List[str]) -> Tuple[str, Dict[str, str]]:\n",
    "    \"\"\"\n",
    "    Formats data for selected PIs to highlight connections and field diversity\n",
    "    suitable for an 'influencer' analysis prompt.\n",
    "\n",
    "    Args:\n",
    "        df: The main DataFrame containing award and PI information.\n",
    "        pi_ids: A list of PI IDs to format data for.\n",
    "\n",
    "    Returns:\n",
    "        A tuple containing:\n",
    "            - formatted_data_string: A string with formatted details for each PI,\n",
    "              focusing on connections and fields.\n",
    "            - pi_names_dict: A dictionary mapping PI ID to PI full name.\n",
    "    \"\"\"\n",
    "    print(f\"Formatting influencer data for PI IDs: {pi_ids}...\")\n",
    "    formatted_data = \"\"\n",
    "    pi_names = {} # Dictionary to store PI names\n",
    "\n",
    "    # Filter main df once for all relevant PIs to improve efficiency\n",
    "    filtered_df = df[df['pi_id'].isin(pi_ids)].copy()\n",
    "\n",
    "    if filtered_df.empty:\n",
    "        print(\"Warning: No data found for any specified PI IDs.\")\n",
    "        formatted_data = \"No data could be retrieved for the specified potential influencers.\\n\"\n",
    "        for pi_id in pi_ids:\n",
    "             pi_names[pi_id] = f\"PI ID {pi_id}\" # Use ID as placeholder name\n",
    "        return formatted_data, pi_names\n",
    "\n",
    "    # Iterate through the requested PI IDs\n",
    "    for pi_id in pi_ids:\n",
    "        pi_specific_data = filtered_df[filtered_df['pi_id'] == pi_id]\n",
    "\n",
    "        if not pi_specific_data.empty:\n",
    "            # Get consistent name from the first entry\n",
    "            full_name = pi_specific_data['pi_full_name'].iloc[0]\n",
    "            pi_names[pi_id] = full_name\n",
    "            print(f\"  Processing data for {full_name} ({pi_id})...\")\n",
    "\n",
    "            formatted_data += f\"--- Potential Influencer: {full_name} (ID: {pi_id}) ---\\n\"\n",
    "\n",
    "            # --- Project & Connection Analysis ---\n",
    "            unique_award_titles = pi_specific_data['award_title'].unique()\n",
    "            num_projects = len(unique_award_titles)\n",
    "            formatted_data += f\"Total Projects Involved In (as PI/Co-PI): {num_projects}\\n\"\n",
    "\n",
    "            # Get all collaborators across these projects\n",
    "            collaborators_by_award = get_collaborators_for_awards(df, list(unique_award_titles))\n",
    "            all_collaborators = set()\n",
    "            for title, names in collaborators_by_award.items():\n",
    "                # Add collaborators, excluding the PI themselves\n",
    "                all_collaborators.update(name for name in names if name != full_name)\n",
    "\n",
    "            num_unique_collaborators = len(all_collaborators)\n",
    "            formatted_data += f\"Total Unique Collaborators (excluding self): {num_unique_collaborators}\\n\"\n",
    "            # Optionally list some collaborators:\n",
    "            collaborators_preview = \", \".join(list(all_collaborators)[:5]) # Preview first 5\n",
    "            formatted_data += f\"  Collaborators Sample: {collaborators_preview}{'...' if num_unique_collaborators > 5 else ''}\\n\"\n",
    "\n",
    "            # --- Field Diversity Analysis ---\n",
    "            unique_elements = pi_specific_data['program_element'].dropna().unique()\n",
    "            unique_references = pi_specific_data['program_reference'].dropna().unique()\n",
    "            all_fields = set(unique_elements) | set(unique_references)\n",
    "            num_unique_fields = len(all_fields)\n",
    "            formatted_data += f\"Number of Unique Research Fields (Program Elements/References): {num_unique_fields}\\n\"\n",
    "            # Optionally list some fields:\n",
    "            fields_preview = \", \".join(list(all_fields)[:5]) # Preview first 5\n",
    "            formatted_data += f\"  Fields Sample: {fields_preview}{'...' if num_unique_fields > 5 else ''}\\n\\n\"\n",
    "\n",
    "            # --- Detailed Project List (Optional - can make prompt very long) ---\n",
    "            # formatted_data += \"  Projects Overview:\\n\"\n",
    "            # for title in unique_award_titles:\n",
    "            #    roles_on_project = pi_specific_data[pi_specific_data['award_title'] == title]['role'].unique()\n",
    "            #    formatted_data += f\"  - {title} (Roles: {', '.join(roles_on_project)})\\n\"\n",
    "            #    formatted_data += f\"    Collaborators on this project: {', '.join(c for c in collaborators_by_award.get(title, []) if c != full_name)}\\n\"\n",
    "            # formatted_data += \"\\n\"\n",
    "\n",
    "        else:\n",
    "            # Handle case where a specific PI ID from the list had no data\n",
    "            formatted_data += f\"--- Potential Influencer ID: {pi_id} ---\\n\"\n",
    "            formatted_data += \"No award data found in the provided dataset for this PI.\\n\\n\"\n",
    "            pi_names[pi_id] = f\"PI ID {pi_id}\" # Use ID as placeholder name\n",
    "\n",
    "    print(\"Influencer data formatting complete.\")\n",
    "    return formatted_data, pi_names\n",
    "\n",
    "\n",
    "# --- New Function 2: Generate Influencer Prompt ---\n",
    "def generate_influencer_prompt(formatted_data_string: str, pi_names_dict: Dict[str, str]) -> str:\n",
    "    \"\"\"\n",
    "    Generates the full prompt string for the Gemini model to identify influencers.\n",
    "\n",
    "    Args:\n",
    "        formatted_data_string: The formatted string containing PI details focused\n",
    "                               on connections and fields.\n",
    "        pi_names_dict: A dictionary mapping PI ID to PI name.\n",
    "\n",
    "    Returns:\n",
    "        The complete prompt string for influencer identification.\n",
    "    \"\"\"\n",
    "    print(\"Generating influencer prompt...\")\n",
    "    candidate_names_list = \", \".join(pi_names_dict.values())\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "        Context:\n",
    "        You are an AI assistant analyzing research collaboration data to identify 'influencers'. An influencer is defined as a researcher who has significant connections within the network, demonstrated by:\n",
    "        1.  Being involved (as PI or Co-PI) in a relatively high number of distinct projects/awards.\n",
    "        2.  Having collaborated with a relatively high number of unique individuals.\n",
    "        3.  Having experience across a diverse range of research fields (indicated by different Program Elements or Program References).\n",
    "\n",
    "        Below is summarized data for potential influencers ({candidate_names_list}):\n",
    "\n",
    "        {formatted_data_string}\n",
    "\n",
    "        Task:\n",
    "        Based *only* on the summarized information provided above, please analyze each researcher's profile according to the 'influencer' criteria (number of projects, number of unique collaborators, and field diversity).\n",
    "\n",
    "        Rank these individuals ({candidate_names_list}) from most influential to least influential based on the definition provided.\n",
    "\n",
    "        Provide a clear ranking and a concise justification for your ranking, referencing the specific metrics (project count, collaborator count, field count) for each researcher from the context provided.\n",
    "    \"\"\"\n",
    "    print(\"Influencer prompt generated.\")\n",
    "    return prompt\n",
    "\n",
    "# --- New Function 3: Identify Influencer using LLM ---\n",
    "def identify_influencer_llm(df: pd.DataFrame, model: genai.GenerativeModel, pi_ids: List[str]) -> Optional[str]:\n",
    "    \"\"\"\n",
    "    Orchestrates the process of formatting data, generating an influencer prompt,\n",
    "    and getting a ranking from the Gemini model.\n",
    "\n",
    "    Args:\n",
    "        df: The main DataFrame.\n",
    "        model: The configured Gemini model object.\n",
    "        pi_ids: A list of PI IDs to consider as potential influencers.\n",
    "\n",
    "    Returns:\n",
    "        The influencer ranking text from the model, or None if an error occurred.\n",
    "    \"\"\"\n",
    "    print(f\"\\n--- Starting Influencer Identification Process for PI IDs: {pi_ids} ---\")\n",
    "\n",
    "    # 1. Format Data for Influencer Analysis\n",
    "    # Note: This function now focuses on connections and diversity metrics\n",
    "    formatted_text, pi_names = format_influencer_data(df, pi_ids)\n",
    "\n",
    "    # Check if formatting yielded any usable data\n",
    "    if not pi_names or all(name.startswith(\"PI ID\") for name in pi_names.values()):\n",
    "         print(\"Stopping process as no valid data could be formatted.\")\n",
    "         return \"Could not generate influencer ranking due to lack of data for the specified PIs.\"\n",
    "\n",
    "    # 2. Generate Influencer Prompt\n",
    "    prompt_text = generate_influencer_prompt(formatted_text, pi_names)\n",
    "\n",
    "    # 3. Get Response (using the existing get_gemini_response function)\n",
    "    print(\"--- Sending Request to Gemini for Influencer Ranking ---\")\n",
    "    # Assuming get_gemini_response takes model and prompt, and returns (response_text, duration)\n",
    "    # You might need to adapt this call slightly if your get_gemini_response has different args/return values\n",
    "    ranking_result, duration = get_gemini_response(model, prompt_text) # Use your existing function\n",
    "\n",
    "    if ranking_result:\n",
    "        print(f\"--- Influencer Identification Complete ({duration:.2f}s) ---\")\n",
    "        # The result is already printed by get_gemini_response during streaming usually\n",
    "        return ranking_result\n",
    "    else:\n",
    "        print(\"--- Influencer Identification Failed ---\")\n",
    "        return \"Failed to get influencer ranking from the model.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Starting Influencer Identification Process for PI IDs: ['000025762', '269811881', '269807623', '270021884'] ---\n",
      "Formatting influencer data for PI IDs: ['000025762', '269811881', '269807623', '270021884']...\n",
      "  Processing data for Steven N MacEachern (000025762)...\n",
      "  Processing data for Jianlin   Cheng (269811881)...\n",
      "  Processing data for Dirk J Colbry (269807623)...\n",
      "  Processing data for Guido F Montufar Cuartas (270021884)...\n",
      "Influencer data formatting complete.\n",
      "Generating influencer prompt...\n",
      "Influencer prompt generated.\n",
      "--- Sending Request to Gemini for Influencer Ranking ---\n",
      "\n",
      "PI: **In summary:** The ranking prioritizes researchers with higher numbers in all three key metrics. Dirk J Colbry excels in all, making him the top influencer. Steven N MacEachern's collaborator count gives him an edge for the second position. Guido F Montufar Cuartas and Jianlin Cheng are ranked lower due to lower collaborator counts, with Guido F Montufar Cuartas slightly edging out Jianlin Cheng due to a marginally better collaborator count.\n",
      "\n",
      "Response generated in 7.93 seconds.\n",
      "--- Influencer Identification Complete (7.93s) ---\n",
      "\n",
      "--- Final Influencer Ranking Text ---\n",
      "## Ranking of Potential Influencers:\n",
      "\n",
      "Here is the ranking of the researchers from most to least influential based on the provided data and criteria:\n",
      "\n",
      "**Ranking:**\n",
      "\n",
      "1.  **Dirk J Colbry (ID: 269807623)**\n",
      "2.  **Steven N MacEachern (ID: 000025762)**\n",
      "3.  **Guido F Montufar Cuartas (ID: 270021884)**\n",
      "4.  **Jianlin Cheng (ID: 269811881)**\n",
      "\n",
      "**Justification:**\n",
      "\n",
      "**1. Dirk J Colbry:**  Dirk J Colbry demonstrates the strongest profile as an influencer across all criteria. He is involved in the highest number of projects (3), has the largest number of unique collaborators (11), and possesses the greatest diversity of research fields (5).  His high scores in all three metrics clearly position him as the most influential researcher among the four based on the given definition.\n",
      "\n",
      "**2. Steven N MacEachern:** Steven N MacEachern ranks second due to a moderate number of projects (2) and a relatively good number of unique collaborators (4). While he has the lowest field diversity (1), his stronger collaborator network compared to Guido F Montufar Cuartas and Jianlin Cheng places him higher overall.\n",
      "\n",
      "**3. Guido F Montufar Cuartas:** Guido F Montufar Cuartas comes in third.  He is involved in 2 projects, similar to Steven N MacEachern and Jianlin Cheng. He has a moderate number of unique research fields (4), equal to Jianlin Cheng. However, he has a slightly higher number of unique collaborators (2) compared to Jianlin Cheng (1), which gives him a slight edge in influence compared to Jianlin.\n",
      "\n",
      "**4. Jianlin Cheng:** Jianlin Cheng is ranked last. While he possesses a good diversity of research fields (4), equal to Guido F Montufar Cuartas, he has the lowest number of unique collaborators (1) and is involved in 2 projects. His limited collaborator network, based on the provided data, suggests a lower level of influence compared to the other researchers in this analysis.\n",
      "\n",
      "**In summary:** The ranking prioritizes researchers with higher numbers in all three key metrics. Dirk J Colbry excels in all, making him the top influencer. Steven N MacEachern's collaborator count gives him an edge for the second position. Guido F Montufar Cuartas and Jianlin Cheng are ranked lower due to lower collaborator counts, with Guido F Montufar Cuartas slightly edging out Jianlin Cheng due to a marginally better collaborator count.\n"
     ]
    }
   ],
   "source": [
    "# --- Example Usage ---\n",
    "# Assuming 'df' is your loaded DataFrame and 'model' is your configured Gemini model\n",
    "try:\n",
    "    # Example PI IDs known to have multiple projects/connections\n",
    "    # Replace with IDs relevant to your analysis\n",
    "    influencer_candidate_ids = ['000025762', '269811881', '269807623', '270021884'] # Example set\n",
    "\n",
    "    # --- Run the Influencer Identification Process ---\n",
    "    influencer_ranking_result = identify_influencer_llm(df, model, influencer_candidate_ids)\n",
    "\n",
    "    # Optional: Print the final result again if not fully captured by streaming print\n",
    "    if influencer_ranking_result:\n",
    "        print(\"\\n--- Final Influencer Ranking Text ---\")\n",
    "        print(influencer_ranking_result)\n",
    "    else:\n",
    "        print(\"\\nInfluencer ranking could not be generated.\")\n",
    "\n",
    "except NameError as e:\n",
    "    print(f\"Error: Required variable not defined (e.g., 'df' or 'model'). Details: {e}\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred during the influencer identification process: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Embading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from datetime import datetime\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Combine relevant text columns into one (you may adjust columns as needed)\n",
    "text_columns = [\n",
    "    \"award_type\", \"award_title\", \"abstract\", \n",
    "    \"org_name\", \"org_name2\", \"perf_inst_name\", \n",
    "    \"program_element\", \"program_reference\"\n",
    "]\n",
    "df[\"combined_text\"] = df[text_columns].astype(str).agg(\" \".join, axis=1)\n",
    "\n",
    "# a. Leadership indicator: 1 if role suggests prior leadership (e.g., contains \"Principal Investigator\")\n",
    "df[\"leadership\"] = df[\"role\"].apply(lambda x: 1 if \"Principal Investigator\" in str(x) else 0)\n",
    "\n",
    "# b. Experience in years: use start_date and a reference date (here we use today)\n",
    "df[\"start_date\"] = pd.to_datetime(df[\"start_date\"], errors='coerce')\n",
    "reference_date = datetime.now()  # or use a fixed project date\n",
    "df[\"experience_years\"] = (reference_date - df[\"start_date\"]).dt.days / 365.25\n",
    "\n",
    "# Load a pre-trained sentence transformer\n",
    "embedder = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "# Compute embedding for each award's combined text\n",
    "df[\"text_embedding\"] = df[\"combined_text\"].apply(lambda x: embedder.encode(x))\n",
    "\n",
    "# We assume each row has a researcher ID (\"pi_id\"). If a researcher has multiple rows, we aggregate.\n",
    "# For aggregated text, we average the embeddings; for numeric features, we use appropriate aggregation.\n",
    "award_counts = df.groupby(\"pi_id\").size().reset_index(name=\"award_count\")\n",
    "df_grouped = df.groupby(\"pi_id\").agg({\n",
    "    \"experience_years\": \"mean\",       # average experience across awards\n",
    "    \"leadership\": \"max\",              # if they have ever been a PI, mark as leadership\n",
    "    \"text_embedding\": lambda embs: np.mean(np.stack(embs), axis=0)\n",
    "}).reset_index()\n",
    "df_grouped = df_grouped.merge(award_counts, on=\"pi_id\", how=\"left\")\n",
    "\n",
    "# For later scoring, normalize the numeric features (experience and award_count)\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "df_grouped[[\"exp_norm\", \"award_norm\"]] = scaler.fit_transform(df_grouped[[\"experience_years\", \"award_count\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Influencer by TOPIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "# Assuming SentenceTransformer 'embedder' and DataFrames 'df', 'df_grouped'\n",
    "# are already loaded and computed as in your notebook (cells 17 & 18)\n",
    "\n",
    "# --- New Function 1: Select Candidate PIs by Criterion ---\n",
    "def select_candidate_pis(\n",
    "    df: pd.DataFrame,\n",
    "    df_grouped: pd.DataFrame,\n",
    "    embedder, # Your SentenceTransformer model\n",
    "    criterion_type: str, # \"topic\" or \"department\"\n",
    "    criterion_value: str, # The actual topic or department name\n",
    "    top_k: int = 10 # Number of top candidates to select\n",
    ") -> List[str]:\n",
    "    \"\"\"\n",
    "    Selects a list of candidate PI IDs based on a research topic or department.\n",
    "\n",
    "    Args:\n",
    "        df: The main DataFrame.\n",
    "        df_grouped: DataFrame grouped by pi_id, containing aggregated info\n",
    "                    and 'text_embedding'.\n",
    "        embedder: The initialized SentenceTransformer model.\n",
    "        criterion_type: Either 'topic' or 'department'.\n",
    "        criterion_value: The specific topic string or department name.\n",
    "        top_k: The maximum number of candidate IDs to return.\n",
    "\n",
    "    Returns:\n",
    "        A list of candidate PI IDs.\n",
    "    \"\"\"\n",
    "    print(f\"Selecting top {top_k} candidates based on {criterion_type}: '{criterion_value}'...\")\n",
    "    candidate_ids = []\n",
    "\n",
    "    if criterion_type == \"topic\":\n",
    "        if 'text_embedding' not in df_grouped.columns or embedder is None:\n",
    "            print(\"Error: df_grouped with 'text_embedding' and embedder are required for topic search.\")\n",
    "            return []\n",
    "\n",
    "        # Compute embedding for the research topic\n",
    "        topic_emb = embedder.encode(criterion_value)\n",
    "\n",
    "        # Calculate similarity between topic and all PIs in df_grouped\n",
    "        all_embeddings = np.stack(df_grouped['text_embedding'].values)\n",
    "        similarities = cosine_similarity([topic_emb], all_embeddings)[0]\n",
    "\n",
    "        # Get indices of top k PIs sorted by similarity\n",
    "        top_indices = np.argsort(similarities)[::-1][:top_k]\n",
    "\n",
    "        # Get the corresponding PI IDs\n",
    "        candidate_ids = df_grouped.iloc[top_indices]['pi_id'].tolist()\n",
    "\n",
    "    elif criterion_type == \"department\":\n",
    "        # Filter the main df by department (case-insensitive partial match)\n",
    "        # You might want to refine this matching logic (e.g., exact match)\n",
    "        dept_match_df = df[df['department'].str.contains(criterion_value, case=False, na=False)]\n",
    "\n",
    "        if dept_match_df.empty:\n",
    "            print(f\"No PIs found matching department: '{criterion_value}'\")\n",
    "            return []\n",
    "\n",
    "        # Get unique PI IDs from the matching departments\n",
    "        unique_dept_pi_ids = dept_match_df['pi_id'].unique()\n",
    "\n",
    "        # If more than top_k PIs, we can optionally rank them (e.g., by award count)\n",
    "        # Here, we'll take the top_k based on award count from df_grouped\n",
    "        if len(unique_dept_pi_ids) > top_k:\n",
    "            candidate_subset = df_grouped[df_grouped['pi_id'].isin(unique_dept_pi_ids)]\n",
    "            # Sort by 'award_count' (requires 'award_count' column in df_grouped)\n",
    "            if 'award_count' in candidate_subset.columns:\n",
    "                 ranked_candidates = candidate_subset.sort_values(by='award_count', ascending=False)\n",
    "                 candidate_ids = ranked_candidates.head(top_k)['pi_id'].tolist()\n",
    "            else: # Fallback if award_count isn't available\n",
    "                 candidate_ids = list(unique_dept_pi_ids)[:top_k]\n",
    "            print(f\"  (Found {len(unique_dept_pi_ids)} PIs, selecting top {top_k} based on award count)\")\n",
    "        else:\n",
    "            candidate_ids = list(unique_dept_pi_ids)\n",
    "\n",
    "    else:\n",
    "        print(f\"Error: Invalid criterion_type '{criterion_type}'. Use 'topic' or 'department'.\")\n",
    "        return []\n",
    "\n",
    "    print(f\"Selected candidate PI IDs: {candidate_ids}\")\n",
    "    return candidate_ids\n",
    "\n",
    "# --- New Function 2: Orchestrator for Criterion-Based Search ---\n",
    "def find_influencers_by_criterion(\n",
    "    df: pd.DataFrame,\n",
    "    df_grouped: pd.DataFrame,\n",
    "    embedder, # Your SentenceTransformer model\n",
    "    model: genai.GenerativeModel, # Your Gemini model\n",
    "    criterion_type: str,\n",
    "    criterion_value: str,\n",
    "    top_k_candidates: int = 10 # How many initial candidates to select\n",
    ") -> Optional[str]:\n",
    "    \"\"\"\n",
    "    Finds and ranks influencers based on a topic or department criterion.\n",
    "\n",
    "    Args:\n",
    "        df: Main DataFrame.\n",
    "        df_grouped: Grouped DataFrame with embeddings and counts.\n",
    "        embedder: SentenceTransformer model.\n",
    "        model: Gemini model object.\n",
    "        criterion_type: 'topic' or 'department'.\n",
    "        criterion_value: The topic string or department name.\n",
    "        top_k_candidates: Max number of candidates to select initially.\n",
    "\n",
    "    Returns:\n",
    "        The influencer ranking text from the model, or None/error message.\n",
    "    \"\"\"\n",
    "    print(f\"\\n--- Starting Influencer Search by {criterion_type.capitalize()}: '{criterion_value}' ---\")\n",
    "\n",
    "    # 1. Select Candidate PIs based on the criterion\n",
    "    candidate_pi_ids = select_candidate_pis(\n",
    "        df, df_grouped, embedder, criterion_type, criterion_value, top_k=top_k_candidates\n",
    "    )\n",
    "\n",
    "    if not candidate_pi_ids:\n",
    "        print(\"No candidates found for the specified criterion.\")\n",
    "        return f\"Could not find potential influencers matching {criterion_type}: '{criterion_value}'.\"\n",
    "\n",
    "    # 2. Proceed with the LLM analysis using the selected candidates\n",
    "    # Reuse the 'identify_influencer_llm' logic (formatting, prompt, API call)\n",
    "    # We pass the dynamically selected candidate_pi_ids\n",
    "    print(f\"\\n--- Analyzing Selected Candidates for Influence ---\")\n",
    "    # (Assuming identify_influencer_llm structure remains similar)\n",
    "    # This reuses the formatting, prompt generation and LLM call logic from before\n",
    "    influencer_ranking_result = identify_influencer_llm(df, model, candidate_pi_ids)\n",
    "\n",
    "\n",
    "    return influencer_ranking_result\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Starting Influencer Search by Topic: 'AI Circuits design' ---\n",
      "Selecting top 5 candidates based on topic: 'AI Circuits design'...\n",
      "Selected candidate PI IDs: ['269757420', '000166285', '269951871', '269674418', '269738150']\n",
      "\n",
      "--- Analyzing Selected Candidates for Influence ---\n",
      "\n",
      "--- Starting Influencer Identification Process for PI IDs: ['269757420', '000166285', '269951871', '269674418', '269738150'] ---\n",
      "Formatting influencer data for PI IDs: ['269757420', '000166285', '269951871', '269674418', '269738150']...\n",
      "  Processing data for Peng   Li (269757420)...\n",
      "  Processing data for Andreas G Andreou (000166285)...\n",
      "  Processing data for Dorit S Hochbaum (269951871)...\n",
      "  Processing data for Alper   Atamturk (269674418)...\n",
      "  Processing data for Charles B Pierre (269738150)...\n",
      "Influencer data formatting complete.\n",
      "Generating influencer prompt...\n",
      "Influencer prompt generated.\n",
      "--- Sending Request to Gemini for Influencer Ranking ---\n",
      "\n",
      "PI: 3. **Dorit S Hochbaum, Alper Atamturk, Charles B Pierre (Tie)**\n",
      "\n",
      "Response generated in 6.14 seconds.\n",
      "--- Influencer Identification Complete (6.14s) ---\n",
      "\n",
      "--- Final Influencer Ranking for Topic 'AI Circuits design' ---\n",
      "## Researcher Influence Ranking:\n",
      "\n",
      "Based on the provided data and the definition of an 'influencer' researcher, here is the ranking from most to least influential:\n",
      "\n",
      "**1. Andreas G Andreou:**\n",
      "\n",
      "* **Justification:** Andreas G Andreou demonstrates the strongest influencer profile overall.  He has the highest number of **unique collaborators (8)**, significantly exceeding all other researchers. While his **project count (3)** is second highest, it is still substantial. His **field diversity (6 unique fields)** is also strong, placing him second in this metric.  His high collaborator count particularly emphasizes his broad network and potential influence within the research community.\n",
      "\n",
      "**2. Peng Li:**\n",
      "\n",
      "* **Justification:** Peng Li ranks second due to excelling in two key criteria. He is involved in the highest number of **projects (4)** and has the most diverse range of **research fields (7)**.  However, his relatively low number of **unique collaborators (1)** compared to Andreas G Andreou and others significantly reduces his overall influence score.  While diverse and project-rich, his limited collaboration network suggests a potentially less widespread influence than Andreas G Andreou.\n",
      "\n",
      "**3. Dorit S Hochbaum, Alper Atamturk, Charles B Pierre (Tie):**\n",
      "\n",
      "* **Justification:** Dorit S Hochbaum, Alper Atamturk, and Charles B Pierre are ranked equally as they have identical metrics across all three criteria. They each have a low number of **projects (1)**, a moderate number of **unique collaborators (4)**, and a limited number of **research fields (2)**.  While they show a similar level of collaboration among themselves, their lower project involvement and limited field diversity compared to Andreas G Andreou and Peng Li place them lower in the influence ranking.  Their profiles suggest a more focused or recently established network compared to the top two researchers.\n",
      "\n",
      "**Summary Ranking (Most to Least Influential):**\n",
      "\n",
      "1. **Andreas G Andreou**\n",
      "2. **Peng Li**\n",
      "3. **Dorit S Hochbaum, Alper Atamturk, Charles B Pierre (Tie)**\n"
     ]
    }
   ],
   "source": [
    "# --- Example Usage ---\n",
    "try:\n",
    "    # --- Find Influencers by TOPIC ---\n",
    "    topic_to_search = \"AI Circuits design\"\n",
    "    topic_ranking = find_influencers_by_criterion(\n",
    "        df, df_grouped, embedder, model,\n",
    "        criterion_type=\"topic\",\n",
    "        criterion_value=topic_to_search,\n",
    "        top_k_candidates=5 # Select top 5 PIs based on topic similarity first\n",
    "    )\n",
    "    if topic_ranking:\n",
    "        print(f\"\\n--- Final Influencer Ranking for Topic '{topic_to_search}' ---\")\n",
    "        print(topic_ranking)\n",
    "\n",
    "except NameError as e:\n",
    "     print(f\"Error: Required variable not defined (e.g., 'df', 'df_grouped', 'embedder', 'model'). Details: {e}\")\n",
    "except Exception as e:\n",
    "     print(f\"An error occurred during the influencer search process: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Influencers by DEPARTMENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Starting Influencer Search by Department: 'Computer Science' ---\n",
      "Selecting top 10 candidates based on department: 'Computer Science'...\n",
      "  (Found 2938 PIs, selecting top 10 based on award count)\n",
      "Selected candidate PI IDs: ['269935164', '269779708', '269765937', '000235919', '270031750', '000207040', '270018850', '269779084', '269985475', '269680242']\n",
      "\n",
      "--- Analyzing Selected Candidates for Influence ---\n",
      "\n",
      "--- Starting Influencer Identification Process for PI IDs: ['269935164', '269779708', '269765937', '000235919', '270031750', '000207040', '270018850', '269779084', '269985475', '269680242'] ---\n",
      "Formatting influencer data for PI IDs: ['269935164', '269779708', '269765937', '000235919', '270031750', '000207040', '270018850', '269779084', '269985475', '269680242']...\n",
      "  Processing data for Yanfang   Ye (269935164)...\n",
      "  Processing data for Prasad   Calyam (269779708)...\n",
      "  Processing data for Tiffany M Barnes (269765937)...\n",
      "  Processing data for Sharad   Mehrotra (000235919)...\n",
      "  Processing data for Ferdinando   Fioretto (270031750)...\n",
      "  Processing data for Dhabaleswar K Panda (000207040)...\n",
      "  Processing data for Ravi Netravali (270018850)...\n",
      "  Processing data for Aditya   Akella (269779084)...\n",
      "  Processing data for Jiliang   Tang (269985475)...\n",
      "  Processing data for Mahmut T Kandemir (269680242)...\n",
      "Influencer data formatting complete.\n",
      "Generating influencer prompt...\n",
      "Influencer prompt generated.\n",
      "--- Sending Request to Gemini for Influencer Ranking ---\n",
      "\n",
      "PI: 10. Ravi Netravali\n",
      "\n",
      "Response generated in 10.01 seconds.\n",
      "--- Influencer Identification Complete (10.01s) ---\n",
      "\n",
      "--- Final Influencer Ranking for Department 'Computer Science' ---\n",
      "**Researcher Ranking based on Influence:**\n",
      "\n",
      "Here is the ranking of the researchers from most to least influential, based on the provided criteria and data:\n",
      "\n",
      "**Rank 1: Prasad Calyam**\n",
      "* **Justification:** Prasad Calyam consistently ranks high across all criteria. He is involved in the highest number of projects (14), has the second-highest number of unique collaborators (25), and the highest number of unique research fields (22). His strong performance across all three metrics positions him as the most influential based on this data.\n",
      "\n",
      "**Rank 2: Tiffany M Barnes**\n",
      "* **Justification:** Tiffany M Barnes stands out with the highest number of unique collaborators (30).  She also has a strong number of unique research fields (13) and a good number of projects (11). While not topping every category, her high collaborator count and solid performance in other areas make her a strong influencer.\n",
      "\n",
      "**Rank 3: Dhabaleswar K Panda**\n",
      "* **Justification:** Dhabaleswar K Panda demonstrates a good balance. He has a high number of unique research fields (15) and a substantial number of unique collaborators (20). His project count is also respectable (9).  His strength lies in field diversity and collaborator network size.\n",
      "\n",
      "**Rank 4: Jiliang Tang**\n",
      "* **Justification:** Jiliang Tang also shows a well-rounded profile. He has a high number of unique collaborators (21) and a good number of unique research fields (12).  His project count is also decent (9). His strengths are in collaboration and field diversity, placing him high in influence.\n",
      "\n",
      "**Rank 5: Yanfang Ye**\n",
      "* **Justification:** Yanfang Ye has a strong project count (13) and a good number of unique research fields (12). However, her collaborator count is relatively lower (11) compared to the top-ranked individuals. Her influence is driven by project involvement and field diversity, but collaborator network is less extensive in comparison.\n",
      "\n",
      "**Rank 6: Sharad Mehrotra**\n",
      "* **Justification:** Sharad Mehrotra has a decent number of unique collaborators (18) and a good number of projects (10) and research fields (11).  He is consistently in the middle range across all metrics, indicating moderate influence compared to the top researchers.\n",
      "\n",
      "**Rank 7: Mahmut T Kandemir**\n",
      "* **Justification:** Mahmut T Kandemir has a good number of projects (9) and unique collaborators (17), along with a respectable number of research fields (11).  Similar to Sharad Mehrotra, he shows a moderate influence level, being consistently in the mid-range for all criteria.\n",
      "\n",
      "**Rank 8: Aditya Akella**\n",
      "* **Justification:** Aditya Akella has a reasonable number of projects (8) and unique collaborators (13). However, his number of unique research fields is lower (8) compared to many others. His influence is less pronounced due to lower field diversity and project count compared to higher-ranked individuals.\n",
      "\n",
      "**Rank 9: Ferdinando Fioretto**\n",
      "* **Justification:** Ferdinando Fioretto has a lower number of projects (7) and significantly fewer unique collaborators (6) compared to most others. While he has a decent number of research fields (11), his limited project involvement and small collaborator network place him lower in terms of influence based on these metrics.\n",
      "\n",
      "**Rank 10: Ravi Netravali**\n",
      "* **Justification:** Ravi Netravali has the lowest numbers across all criteria: projects (5), unique collaborators (2), and unique research fields (8). His limited involvement in projects, small collaborator network, and lower field diversity indicate the least influence among the listed researchers based on the provided data.\n",
      "\n",
      "**Final Ranking (Most to Least Influential):**\n",
      "\n",
      "1.  Prasad Calyam\n",
      "2.  Tiffany M Barnes\n",
      "3.  Dhabaleswar K Panda\n",
      "4.  Jiliang Tang\n",
      "5.  Yanfang Ye\n",
      "6.  Sharad Mehrotra\n",
      "7.  Mahmut T Kandemir\n",
      "8.  Aditya Akella\n",
      "9.  Ferdinando Fioretto\n",
      "10. Ravi Netravali\n"
     ]
    }
   ],
   "source": [
    "# --- Example Usage ---\n",
    "try:\n",
    "    # --- Find Influencers by DEPARTMENT ---\n",
    "    dept_to_search = \"Computer Science\"\n",
    "    dept_ranking = find_influencers_by_criterion(\n",
    "        df, df_grouped, embedder, model,\n",
    "        criterion_type=\"department\",\n",
    "        criterion_value=dept_to_search,\n",
    "        top_k_candidates=10 # Select top 10 PIs from this department (ranked by awards)\n",
    "    )\n",
    "    if dept_ranking:\n",
    "        print(f\"\\n--- Final Influencer Ranking for Department '{dept_to_search}' ---\")\n",
    "        print(dept_ranking)\n",
    "\n",
    "except NameError as e:\n",
    "     print(f\"Error: Required variable not defined (e.g., 'df', 'df_grouped', 'embedder', 'model'). Details: {e}\")\n",
    "except Exception as e:\n",
    "     print(f\"An error occurred during the influencer search process: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[df['pi_id'].isin(pi_ids_to_analyze)][['pi_full_name', 'pi_id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Prerequisite Imports and Setup ---\n",
    "# Make sure you have these imports and objects loaded from your notebook\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import google.generativeai as genai # Assuming 'model' is configured\n",
    "# from sentence_transformers import SentenceTransformer # Assuming 'embedder' is loaded\n",
    "import networkx as nx # For Method 7\n",
    "from typing import List, Dict, Tuple, Optional\n",
    "import collections # For Method 4 helper\n",
    "\n",
    "# Assuming 'df', 'df_grouped', 'embedder', 'model' are loaded and preprocessed\n",
    "# Assuming 'get_collaborators_for_awards', 'format_influencer_data',\n",
    "# 'generate_influencer_prompt', 'identify_influencer_llm',\n",
    "# 'select_candidate_pis', 'find_influencers_by_criterion',\n",
    "# 'get_gemini_response' functions exist as defined previously.\n",
    "\n",
    "# --- Method 4: Inter-Institutional Collaboration ---\n",
    "\n",
    "# Helper function to get collaborator institutions\n",
    "def get_collaborator_institutions(df: pd.DataFrame, pi_id: str, collaborators_names: List[str]) -> collections.Counter:\n",
    "    \"\"\"\n",
    "    Finds the institutions of a given list of collaborators.\n",
    "\n",
    "    Args:\n",
    "        df: The main DataFrame.\n",
    "        pi_id: The ID of the main PI (to exclude their own institution if needed).\n",
    "        collaborators_names: A list of full names of the collaborators.\n",
    "\n",
    "    Returns:\n",
    "        A Counter object mapping institution names to their frequency.\n",
    "    \"\"\"\n",
    "    if not collaborators_names:\n",
    "        return collections.Counter()\n",
    "\n",
    "    # Find entries for the collaborators\n",
    "    collaborator_df = df[df['pi_full_name'].isin(collaborators_names)]\n",
    "\n",
    "    # Get institutions, excluding NaNs and potentially the main PI's primary institution\n",
    "    # For simplicity here, we count all unique institutions associated with collaborators\n",
    "    institutions = collaborator_df['perf_inst_name'].dropna().unique()\n",
    "\n",
    "    # We can return a Counter of unique institutions found for collaborators\n",
    "    # For influence, we mostly care about the *number* of unique institutions\n",
    "    return collections.Counter(institutions)\n",
    "\n",
    "\n",
    "# Modify format_influencer_data to include institutional diversity\n",
    "def format_influencer_data_v2(df: pd.DataFrame, pi_ids: List[str]) -> Tuple[str, Dict[str, str]]:\n",
    "    \"\"\"\n",
    "    V2: Formats data including project/collaborator counts, field diversity,\n",
    "        AND inter-institutional collaboration breadth.\n",
    "    \"\"\"\n",
    "    print(f\"Formatting influencer data (v2) for PI IDs: {pi_ids}...\")\n",
    "    formatted_data = \"\"\n",
    "    pi_names = {}\n",
    "    filtered_df = df[df['pi_id'].isin(pi_ids)].copy()\n",
    "\n",
    "    if filtered_df.empty:\n",
    "         # (Same empty handling as before)\n",
    "         print(\"Warning: No data found for any specified PI IDs.\")\n",
    "         formatted_data = \"No data could be retrieved for the specified potential influencers.\\n\"\n",
    "         for pi_id in pi_ids:\n",
    "             pi_names[pi_id] = f\"PI ID {pi_id}\"\n",
    "         return formatted_data, pi_names\n",
    "\n",
    "    for pi_id in pi_ids:\n",
    "        pi_specific_data = filtered_df[filtered_df['pi_id'] == pi_id]\n",
    "\n",
    "        if not pi_specific_data.empty:\n",
    "            full_name = pi_specific_data['pi_full_name'].iloc[0]\n",
    "            pi_names[pi_id] = full_name\n",
    "            print(f\"  Processing data for {full_name} ({pi_id})...\")\n",
    "            formatted_data += f\"--- Potential Influencer: {full_name} (ID: {pi_id}) ---\\n\"\n",
    "\n",
    "            # --- Project & Connection Analysis ---\n",
    "            unique_award_titles = pi_specific_data['award_title'].unique()\n",
    "            num_projects = len(unique_award_titles)\n",
    "            formatted_data += f\"Total Projects Involved In: {num_projects}\\n\"\n",
    "            collaborators_by_award = get_collaborators_for_awards(df, list(unique_award_titles))\n",
    "            all_collaborators = set(name for names in collaborators_by_award.values() for name in names if name != full_name)\n",
    "            num_unique_collaborators = len(all_collaborators)\n",
    "            formatted_data += f\"Total Unique Collaborators: {num_unique_collaborators}\\n\"\n",
    "\n",
    "            # --- Field Diversity Analysis ---\n",
    "            unique_elements = pi_specific_data['program_element'].dropna().unique()\n",
    "            unique_references = pi_specific_data['program_reference'].dropna().unique()\n",
    "            all_fields = set(unique_elements) | set(unique_references)\n",
    "            num_unique_fields = len(all_fields)\n",
    "            formatted_data += f\"Number of Unique Research Fields: {num_unique_fields}\\n\"\n",
    "\n",
    "            # --- NEW: Inter-Institutional Collaboration ---\n",
    "            collaborator_institutions = get_collaborator_institutions(df, pi_id, list(all_collaborators))\n",
    "            num_unique_collab_institutions = len(collaborator_institutions)\n",
    "            formatted_data += f\"Number of Unique Collaborating Institutions: {num_unique_collab_institutions}\\n\"\n",
    "            # Optionally list some institutions\n",
    "            inst_preview = \", \".join(list(collaborator_institutions.keys())[:3])\n",
    "            formatted_data += f\"  Collaborating Institutions Sample: {inst_preview}{'...' if num_unique_collab_institutions > 3 else ''}\\n\\n\"\n",
    "\n",
    "        else:\n",
    "             # (Same handling for missing PI as before)\n",
    "             formatted_data += f\"--- Potential Influencer ID: {pi_id} ---\\n\"\n",
    "             formatted_data += \"No award data found...\\n\\n\"\n",
    "             pi_names[pi_id] = f\"PI ID {pi_id}\"\n",
    "\n",
    "    print(\"Influencer data formatting (v2) complete.\")\n",
    "    return formatted_data, pi_names\n",
    "\n",
    "# Modify generate_influencer_prompt to include the new criterion\n",
    "def generate_influencer_prompt_v2(formatted_data_string: str, pi_names_dict: Dict[str, str]) -> str:\n",
    "    \"\"\"\n",
    "    V2: Generates prompt asking LLM to consider projects, collaborators,\n",
    "        field diversity, AND institutional diversity.\n",
    "    \"\"\"\n",
    "    print(\"Generating influencer prompt (v2)...\")\n",
    "    candidate_names_list = \", \".join(pi_names_dict.values())\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "Context:\n",
    "You are an AI assistant analyzing research collaboration data to identify 'influencers'. An influencer is defined as a researcher who has significant connections and reach, demonstrated by:\n",
    "1.  High number of distinct projects/awards involved in.\n",
    "2.  High number of unique collaborators worked with.\n",
    "3.  Experience across a diverse range of research fields.\n",
    "4.  Collaboration with individuals from a wide range of different institutions.\n",
    "\n",
    "Below is summarized data for potential influencers ({candidate_names_list}):\n",
    "\n",
    "{formatted_data_string}\n",
    "\n",
    "Task:\n",
    "Based *only* on the summarized information provided above, please analyze each researcher's profile according to the 'influencer' criteria (project count, collaborator count, field count, AND collaborating institution count).\n",
    "\n",
    "Rank these individuals ({candidate_names_list}) from most influential to least influential based on this definition.\n",
    "\n",
    "Provide a clear ranking and a concise justification for your ranking, referencing the specific metrics provided for each researcher.\n",
    "\"\"\"\n",
    "    print(\"Influencer prompt (v2) generated.\")\n",
    "    return prompt\n",
    "\n",
    "# New Orchestrator using V2 functions\n",
    "def identify_influencer_llm_v2(df: pd.DataFrame, model: genai.GenerativeModel, pi_ids: List[str]) -> Optional[str]:\n",
    "    \"\"\" V2: Orchestrator using formatting and prompt that include institutional diversity. \"\"\"\n",
    "    print(f\"\\n--- Starting Influencer Identification Process (V2 - Incl. Institutions) for PI IDs: {pi_ids} ---\")\n",
    "    formatted_text, pi_names = format_influencer_data_v2(df, pi_ids) # Use V2 format\n",
    "    if not pi_names or all(name.startswith(\"PI ID\") for name in pi_names.values()):\n",
    "         # (Same error handling)\n",
    "         return \"Could not generate influencer ranking due to lack of data.\"\n",
    "\n",
    "    prompt_text = generate_influencer_prompt_v2(formatted_text, pi_names) # Use V2 prompt\n",
    "    print(\"--- Sending Request to Gemini for Influencer Ranking (V2) ---\")\n",
    "    ranking_result, duration = get_gemini_response(model, prompt_text)\n",
    "\n",
    "    if ranking_result:\n",
    "        print(f\"--- Influencer Identification (V2) Complete ({duration:.2f}s) ---\")\n",
    "        return ranking_result\n",
    "    else:\n",
    "        print(\"--- Influencer Identification (V2) Failed ---\")\n",
    "        return \"Failed to get influencer ranking (V2) from the model.\"\n",
    "\n",
    "# --- Method 5: Specific Award Types ---\n",
    "\n",
    "# Modify select_candidate_pis to handle 'award_type'\n",
    "def select_candidate_pis_v2(\n",
    "    df: pd.DataFrame,\n",
    "    df_grouped: pd.DataFrame,\n",
    "    embedder,\n",
    "    criterion_type: str, # topic, department, award_type\n",
    "    criterion_value: str,\n",
    "    top_k: int = 10\n",
    ") -> List[str]:\n",
    "    \"\"\" V2: Selects candidates based on topic, department, OR award_type. \"\"\"\n",
    "    print(f\"Selecting top {top_k} candidates based on {criterion_type}: '{criterion_value}'...\")\n",
    "    candidate_ids = []\n",
    "\n",
    "    if criterion_type == \"topic\":\n",
    "        # (Same logic as before)\n",
    "        if 'text_embedding' not in df_grouped.columns or embedder is None: return []\n",
    "        topic_emb = embedder.encode(criterion_value)\n",
    "        all_embeddings = np.stack(df_grouped['text_embedding'].values)\n",
    "        similarities = cosine_similarity([topic_emb], all_embeddings)[0]\n",
    "        top_indices = np.argsort(similarities)[::-1][:top_k]\n",
    "        candidate_ids = df_grouped.iloc[top_indices]['pi_id'].tolist()\n",
    "\n",
    "    elif criterion_type == \"department\":\n",
    "        # (Same logic as before)\n",
    "        dept_match_df = df[df['department'].str.contains(criterion_value, case=False, na=False)]\n",
    "        if dept_match_df.empty: return []\n",
    "        unique_dept_pi_ids = dept_match_df['pi_id'].unique()\n",
    "        if len(unique_dept_pi_ids) > top_k:\n",
    "            candidate_subset = df_grouped[df_grouped['pi_id'].isin(unique_dept_pi_ids)]\n",
    "            if 'award_count' in candidate_subset.columns:\n",
    "                 ranked_candidates = candidate_subset.sort_values(by='award_count', ascending=False)\n",
    "                 candidate_ids = ranked_candidates.head(top_k)['pi_id'].tolist()\n",
    "            else: candidate_ids = list(unique_dept_pi_ids)[:top_k]\n",
    "        else: candidate_ids = list(unique_dept_pi_ids)\n",
    "\n",
    "    # --- NEW: Award Type Logic ---\n",
    "    elif criterion_type == \"award_title\":\n",
    "        # Filter main df by the specific award type (case-insensitive partial match)\n",
    "        award_match_df = df[df['award_title'].str.contains(criterion_value, case=False, na=False)]\n",
    "        if award_match_df.empty:\n",
    "            print(f\"No PIs found associated with award type: '{criterion_value}'\")\n",
    "            return []\n",
    "        unique_award_pi_ids = award_match_df['pi_id'].unique()\n",
    "\n",
    "        # Rank by award count within this group if needed\n",
    "        if len(unique_award_pi_ids) > top_k:\n",
    "            candidate_subset = df_grouped[df_grouped['pi_id'].isin(unique_award_pi_ids)]\n",
    "            if 'award_count' in candidate_subset.columns:\n",
    "                 ranked_candidates = candidate_subset.sort_values(by='award_count', ascending=False)\n",
    "                 candidate_ids = ranked_candidates.head(top_k)['pi_id'].tolist()\n",
    "            else: candidate_ids = list(unique_award_pi_ids)[:top_k]\n",
    "            print(f\"  (Found {len(unique_award_pi_ids)} PIs, selecting top {top_k} based on award count)\")\n",
    "        else:\n",
    "            candidate_ids = list(unique_award_pi_ids)\n",
    "    # --- End New Logic ---\n",
    "\n",
    "    else:\n",
    "        print(f\"Error: Invalid criterion_type '{criterion_type}'. Use 'topic', 'department', or 'award_title'.\")\n",
    "        return []\n",
    "\n",
    "    print(f\"Selected candidate PI IDs: {candidate_ids}\")\n",
    "    return candidate_ids\n",
    "\n",
    "# Modify the main orchestrator to use the updated selector\n",
    "def find_influencers_by_criterion_v2(\n",
    "    df: pd.DataFrame,\n",
    "    df_grouped: pd.DataFrame,\n",
    "    embedder,\n",
    "    model: genai.GenerativeModel,\n",
    "    criterion_type: str, # topic, department, award_type\n",
    "    criterion_value: str,\n",
    "    top_k_candidates: int = 10\n",
    ") -> Optional[str]:\n",
    "    \"\"\" V2: Finds influencers based on topic, department, OR award_type criterion. \"\"\"\n",
    "    print(f\"\\n--- Starting Influencer Search (V2 Selector) by {criterion_type.capitalize()}: '{criterion_value}' ---\")\n",
    "\n",
    "    # 1. Select Candidate PIs using the V2 selector\n",
    "    candidate_pi_ids = select_candidate_pis_v2( # Use V2 selector\n",
    "        df, df_grouped, embedder, criterion_type, criterion_value, top_k=top_k_candidates\n",
    "    )\n",
    "\n",
    "    if not candidate_pi_ids:\n",
    "        # (Same error handling)\n",
    "        return f\"Could not find candidates matching {criterion_type}: '{criterion_value}'.\"\n",
    "\n",
    "    # 2. Proceed with LLM analysis (using V1 or V2 formatting/prompting as desired)\n",
    "    # Using V2 here to include institutional diversity analysis as well\n",
    "    print(f\"\\n--- Analyzing Selected Candidates for Influence (V2 - Incl. Institutions) ---\")\n",
    "    influencer_ranking_result = identify_influencer_llm_v2(df, model, candidate_pi_ids)\n",
    "\n",
    "    return influencer_ranking_result\n",
    "\n",
    "\n",
    "# --- Method 6: Hybrid Approach (Example: Topic + Institutions in Prompt) ---\n",
    "\n",
    "# We can reuse `find_influencers_by_criterion_v2` but need a modified prompt generator\n",
    "# that explicitly tells the LLM to weigh two factors.\n",
    "\n",
    "def generate_influencer_prompt_hybrid(\n",
    "    formatted_data_string: str,\n",
    "    pi_names_dict: Dict[str, str],\n",
    "    primary_criterion: str, # e.g., \"Topic Relevance to 'AI'\"\n",
    "    secondary_criterion: str # e.g., \"Breadth of Institutional Collaboration\"\n",
    "    ) -> str:\n",
    "    \"\"\" Hybrid: Asks LLM to rank based on two weighted criteria. \"\"\"\n",
    "    print(\"Generating influencer prompt (Hybrid)...\")\n",
    "    candidate_names_list = \", \".join(pi_names_dict.values())\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "Context:\n",
    "You are an AI assistant identifying 'influencers' based on multiple factors.\n",
    "Primary Factor: {primary_criterion}\n",
    "Secondary Factor: {secondary_criterion}\n",
    "\n",
    "Below is data for potential influencers ({candidate_names_list}), including metrics for projects, collaborators, fields, and collaborating institutions:\n",
    "\n",
    "{formatted_data_string}\n",
    "\n",
    "Task:\n",
    "Based *only* on the summarized information provided, please rank these individuals ({candidate_names_list}) from most influential to least influential.\n",
    "\n",
    "Your ranking should primarily consider the **Primary Factor ({primary_criterion})**. Then, among those who rank highly on the primary factor, give preference based on the **Secondary Factor ({secondary_criterion})**.\n",
    "\n",
    "Provide a clear ranking and justify your reasoning by referencing the specific metrics and how they relate to both factors.\n",
    "\"\"\"\n",
    "    print(\"Influencer prompt (Hybrid) generated.\")\n",
    "    return prompt\n",
    "\n",
    "# Orchestrator for Hybrid approach\n",
    "def find_influencers_hybrid(\n",
    "    df: pd.DataFrame,\n",
    "    df_grouped: pd.DataFrame,\n",
    "    embedder,\n",
    "    model: genai.GenerativeModel,\n",
    "    primary_criterion_type: str, # e.g., \"topic\"\n",
    "    primary_criterion_value: str, # e.g., \"STATISTICS\"\n",
    "    secondary_criterion_desc: str, # e.g., \"Breadth of Institutional Collaboration\"\n",
    "    top_k_candidates: int = 10\n",
    ") -> Optional[str]:\n",
    "    \"\"\" Hybrid: Selects on primary, then asks LLM to rank using primary+secondary factors. \"\"\"\n",
    "\n",
    "    primary_criterion_desc = f\"{primary_criterion_type.capitalize()} related to '{primary_criterion_value}'\"\n",
    "    print(f\"\\n--- Starting Hybrid Influencer Search ({primary_criterion_desc} + {secondary_criterion_desc}) ---\")\n",
    "\n",
    "    # 1. Select candidates based on the PRIMARY criterion\n",
    "    candidate_pi_ids = select_candidate_pis_v2(\n",
    "        df, df_grouped, embedder, primary_criterion_type, primary_criterion_value, top_k=top_k_candidates\n",
    "    )\n",
    "    if not candidate_pi_ids:\n",
    "        return f\"Could not find candidates matching primary criterion: {primary_criterion_desc}.\"\n",
    "\n",
    "    # 2. Format data (use V2 to ensure institutional data is included)\n",
    "    formatted_text, pi_names = format_influencer_data_v2(df, candidate_pi_ids)\n",
    "    if not pi_names or all(name.startswith(\"PI ID\") for name in pi_names.values()):\n",
    "         return \"Could not generate ranking due to lack of data for selected candidates.\"\n",
    "\n",
    "    # 3. Generate the HYBRID prompt\n",
    "    prompt_text = generate_influencer_prompt_hybrid(\n",
    "        formatted_text, pi_names, primary_criterion_desc, secondary_criterion_desc\n",
    "    )\n",
    "\n",
    "    # 4. Get LLM Response\n",
    "    print(\"--- Sending Request to Gemini for Influencer Ranking (Hybrid) ---\")\n",
    "    ranking_result, duration = get_gemini_response(model, prompt_text)\n",
    "\n",
    "    if ranking_result:\n",
    "        print(f\"--- Influencer Identification (Hybrid) Complete ({duration:.2f}s) ---\")\n",
    "        return ranking_result\n",
    "    else:\n",
    "        print(\"--- Influencer Identification (Hybrid) Failed ---\")\n",
    "        return \"Failed to get influencer ranking (Hybrid) from the model.\"\n",
    "\n",
    "\n",
    "# --- Method 7: Network Centrality (Requires NetworkX) ---\n",
    "\n",
    "def calculate_network_centrality(df: pd.DataFrame, top_n: int = 20) -> Optional[pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Calculates Degree and Betweenness Centrality for PIs based on co-awards.\n",
    "\n",
    "    Args:\n",
    "        df: The main DataFrame with 'award_title' and 'pi_id'.\n",
    "        top_n: Number of top influencers to return based on centrality.\n",
    "\n",
    "    Returns:\n",
    "        A DataFrame with PI IDs, names, degree, and betweenness centrality,\n",
    "        ranked by betweenness, then degree. Returns None if networkx is not installed.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        import networkx as nx\n",
    "    except ImportError:\n",
    "        print(\"Error: networkx library is required for network centrality analysis. Install using 'pip install networkx'\")\n",
    "        return None\n",
    "\n",
    "    print(\"\\n--- Calculating Network Centrality ---\")\n",
    "    # Create graph\n",
    "    G = nx.Graph()\n",
    "\n",
    "    # Group by award to find collaborators\n",
    "    awards = df.groupby('award_title')['pi_id'].apply(list)\n",
    "\n",
    "    # Add edges between collaborators on the same award\n",
    "    for award_id, collaborators in awards.items():\n",
    "        # Remove duplicates just in case\n",
    "        unique_collaborators = list(set(collaborators))\n",
    "        if len(unique_collaborators) > 1:\n",
    "            # Add edges between all pairs in this award group\n",
    "            import itertools\n",
    "            for pi1, pi2 in itertools.combinations(unique_collaborators, 2):\n",
    "                if G.has_edge(pi1, pi2):\n",
    "                    G[pi1][pi2]['weight'] = G[pi1][pi2].get('weight', 0) + 1\n",
    "                else:\n",
    "                    G.add_edge(pi1, pi2, weight=1)\n",
    "\n",
    "    if not G.nodes():\n",
    "        print(\"Graph contains no nodes. Cannot calculate centrality.\")\n",
    "        return pd.DataFrame(columns=['pi_id', 'pi_full_name', 'degree_centrality', 'betweenness_centrality'])\n",
    "\n",
    "\n",
    "    # Calculate centrality measures\n",
    "    print(\"Calculating Degree Centrality...\")\n",
    "    degree_centrality = nx.degree_centrality(G)\n",
    "    print(\"Calculating Betweenness Centrality (may take time)...\")\n",
    "    betweenness_centrality = nx.betweenness_centrality(G, normalized=True, weight='weight') # Consider edge weights\n",
    "\n",
    "    # Combine results into a DataFrame\n",
    "    pi_ids = list(G.nodes())\n",
    "    centrality_df = pd.DataFrame({\n",
    "        'pi_id': pi_ids,\n",
    "        'degree_centrality': [degree_centrality.get(pi, 0) for pi in pi_ids],\n",
    "        'betweenness_centrality': [betweenness_centrality.get(pi, 0) for pi in pi_ids]\n",
    "    })\n",
    "\n",
    "    # Merge with PI names (get the first name found for each PI ID)\n",
    "    pi_names_map = df[['pi_id', 'pi_full_name']].drop_duplicates(subset='pi_id').set_index('pi_id')\n",
    "    centrality_df = centrality_df.join(pi_names_map, on='pi_id')\n",
    "\n",
    "    # Rank: Prioritize betweenness, then degree\n",
    "    ranked_df = centrality_df.sort_values(\n",
    "        by=['betweenness_centrality', 'degree_centrality'],\n",
    "        ascending=[False, False]\n",
    "    ).reset_index(drop=True)\n",
    "\n",
    "    print(\"--- Network Centrality Calculation Complete ---\")\n",
    "    return ranked_df[['pi_id', 'pi_full_name', 'degree_centrality', 'betweenness_centrality']].head(top_n)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Influencers BASED ON range of institutional connections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 1: Find influencers based on institutional breadth (using V2)\n",
    "print(\"\\n=== EXAMPLE: Influencers by Institutional Breadth ===\")\n",
    "candidate_ids_for_inst = ['000025762', '269811881', '269807623', '270021884'] # Example list\n",
    "inst_ranking = identify_influencer_llm_v2(df, model, candidate_ids_for_inst)\n",
    "if inst_ranking: print(inst_ranking)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Influencers BASED ON Department"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 2: Find influencers from 'Computer Science' dept (using V2 selector & V2 analysis)\n",
    "print(\"\\n=== EXAMPLE: Influencers by Department (Computer Science) ===\")\n",
    "cs_ranking = find_influencers_by_criterion_v2(\n",
    "    df, df_grouped, embedder, model,\n",
    "    criterion_type=\"department\",\n",
    "    criterion_value=\"Computer Science\",\n",
    "    top_k_candidates=10\n",
    ")\n",
    "if cs_ranking: print(cs_ranking)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Influencers BASED ON award title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 3: Find influencers associated with 'MRI' award type (using V2 selector & V2 analysis)\n",
    "print(\"\\n=== EXAMPLE: Influencers by Award Type (MRI) ===\")\n",
    "mri_ranking = find_influencers_by_criterion_v2(\n",
    "    df, df_grouped, embedder, model,\n",
    "    criterion_type=\"award_title\",\n",
    "    criterion_value=\"NSF\", # Major Research Instrumentation\n",
    "    top_k_candidates=5\n",
    ")\n",
    "if mri_ranking: print(mri_ranking)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topic & Institutional Breadth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 4: Hybrid search - Topic: \"Robotics\" + Secondary: Institutional Breadth\n",
    "print(\"\\n=== EXAMPLE: Hybrid Search (Topic: Robotics + Institutions) ===\")\n",
    "hybrid_ranking = find_influencers_hybrid(\n",
    "    df, df_grouped, embedder, model,\n",
    "    primary_criterion_type=\"topic\",\n",
    "    primary_criterion_value=\"Robotics\",\n",
    "    secondary_criterion_desc=\"Breadth of Institutional Collaboration\",\n",
    "    top_k_candidates=10\n",
    ")\n",
    "if hybrid_ranking: print(hybrid_ranking)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network Centrality Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 5: Network Centrality Analysis\n",
    "print(\"\\n=== EXAMPLE: Network Centrality Analysis ===\")\n",
    "centrality_results = calculate_network_centrality(df, top_n=15)\n",
    "if centrality_results is not None:\n",
    "    print(centrality_results.to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PI classification rule based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from datetime import datetime\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Combine relevant text columns into one (you may adjust columns as needed)\n",
    "text_columns = [\n",
    "    \"award_type\", \"award_title\", \"abstract\", \n",
    "    \"org_name\", \"org_name2\", \"perf_inst_name\", \n",
    "    \"program_element\", \"program_reference\"\n",
    "]\n",
    "df[\"combined_text\"] = df[text_columns].astype(str).agg(\" \".join, axis=1)\n",
    "\n",
    "# a. Leadership indicator: 1 if role suggests prior leadership (e.g., contains \"Principal Investigator\")\n",
    "df[\"leadership\"] = df[\"role\"].apply(lambda x: 1 if \"Principal Investigator\" in str(x) else 0)\n",
    "\n",
    "# b. Experience in years: use start_date and a reference date (here we use today)\n",
    "df[\"start_date\"] = pd.to_datetime(df[\"start_date\"], errors='coerce')\n",
    "reference_date = datetime.now()  # or use a fixed project date\n",
    "df[\"experience_years\"] = (reference_date - df[\"start_date\"]).dt.days / 365.25\n",
    "\n",
    "# Load a pre-trained sentence transformer\n",
    "embedder = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "# Compute embedding for each award's combined text\n",
    "df[\"text_embedding\"] = df[\"combined_text\"].apply(lambda x: embedder.encode(x))\n",
    "\n",
    "# We assume each row has a researcher ID (\"pi_id\"). If a researcher has multiple rows, we aggregate.\n",
    "# For aggregated text, we average the embeddings; for numeric features, we use appropriate aggregation.\n",
    "award_counts = df.groupby(\"pi_id\").size().reset_index(name=\"award_count\")\n",
    "df_grouped = df.groupby(\"pi_id\").agg({\n",
    "    \"experience_years\": \"mean\",       # average experience across awards\n",
    "    \"leadership\": \"max\",              # if they have ever been a PI, mark as leadership\n",
    "    \"text_embedding\": lambda embs: np.mean(np.stack(embs), axis=0)\n",
    "}).reset_index()\n",
    "df_grouped = df_grouped.merge(award_counts, on=\"pi_id\", how=\"left\")\n",
    "\n",
    "# For later scoring, normalize the numeric features (experience and award_count)\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "df_grouped[[\"exp_norm\", \"award_norm\"]] = scaler.fit_transform(df_grouped[[\"experience_years\", \"award_count\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rank_candidates(research_topic, candidate_ids, base_weight=0.5, topic_weight=0.5):\n",
    "    # Compute embedding for the research topic\n",
    "    topic_emb = embedder.encode(research_topic)\n",
    "    \n",
    "    candidate_scores = []\n",
    "    for cid in candidate_ids:\n",
    "        candidate = df_grouped[df_grouped[\"pi_id\"] == cid].iloc[0]\n",
    "        \n",
    "        # Topic relevance score: cosine similarity between candidate's aggregated embedding and the topic\n",
    "        candidate_emb = candidate[\"text_embedding\"]\n",
    "        relevance_score = cosine_similarity([candidate_emb], [topic_emb])[0][0]\n",
    "        \n",
    "        # Base score: a simple weighted sum of normalized features plus a bonus for leadership\n",
    "        # Adjust weights as needed. Here, leadership gets a bonus of 1 if present.\n",
    "        base_score = candidate[\"exp_norm\"] + candidate[\"award_norm\"] + (1 if candidate[\"leadership\"] == 1 else 0)\n",
    "        \n",
    "        # Combined score: weighted combination of base score and topic relevance\n",
    "        combined_score = base_weight * base_score + topic_weight * relevance_score\n",
    "        candidate_scores.append(combined_score)\n",
    "    \n",
    "    candidate_scores = np.array(candidate_scores)\n",
    "    best_index = np.argmax(candidate_scores)\n",
    "    pi_candidate = candidate_ids[best_index]\n",
    "    co_pi_candidates = [cid for i, cid in enumerate(candidate_ids) if i != best_index]\n",
    "    \n",
    "    return pi_candidate, co_pi_candidates, candidate_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with various topics dynamically.\n",
    "for test_topic in [\"knowledge graph\", \"AI\", \"Neuroscience\", \"STATISTICS\"]:\n",
    "    print(\"Testing with topic:\", test_topic)\n",
    "    pi_candidate, co_pi_candidates, scores = rank_candidates(test_topic, pi_ids_to_analyze)\n",
    "    print(\"Predicted PI:\", pi_candidate)\n",
    "    print(\"Predicted Co-PIs:\", co_pi_candidates)\n",
    "    print(\"Candidate Combined Scores:\", scores)\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[df.pi_id.isin(pi_ids_to_analyze)][['pi_id', 'pi_full_name', 'role', 'department', 'leadership', 'experience_years', 'program_element']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define the list of keywords for departments of interest,\n",
    "# # including alternative spellings (e.g., math and mathmatics, stat and statistics)\n",
    "# allowed_keywords = ['computer', 'electrical', 'biomedical', 'bioinformatics', 'math', 'mathmatics', 'stat', 'statistics']\n",
    "\n",
    "# # Filter the DataFrame to only include rows where the 'department' field contains one of the keywords (case insensitive)\n",
    "# qualified_df = df[df['department'].fillna('').str.lower().str.contains('|'.join(allowed_keywords))]\n",
    "\n",
    "# # Get unique PI IDs from the filtered DataFrame\n",
    "# unique_pi_ids = qualified_df['pi_id'].unique()\n",
    "\n",
    "# # Generate 15 sets, each containing 3 distinct PI IDs sampled without replacement\n",
    "# pi_id_sets = [list(np.random.choice(unique_pi_ids, 3, replace=False)) for _ in range(15)]\n",
    "\n",
    "# # Output the sets with department and program_element information\n",
    "# for idx, pi_set in enumerate(pi_id_sets, start=1):\n",
    "#     print(f\"Set {idx}:\")\n",
    "#     for pi in pi_set:\n",
    "#         info = qualified_df[qualified_df['pi_id'] == pi].iloc[0]\n",
    "#         print(f\"  PI: {pi} | Department: {info['department']} | Program Element: {info['program_element']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "candidate_sets = [\n",
    "    (['269948909', '000173003', '269886945'], 'STATISTICS'),\n",
    "    (['269807623', '269794080', '269879497'], 'AI Circuits design'),\n",
    "    (['269807623', '269794080', '269879497'], 'hardware software co-design'),\n",
    "    (['269677663', '269988546', '270021884'], 'Trustworthy AI'),\n",
    "    (['269677663', '269988546', '269814599'], 'Networking safety'),\n",
    "    (['269811881', '269958535', '270083608'], 'Bioinformatics'),\n",
    "    (['270082637', '269726900', '269963435'], 'Robotics'),\n",
    "    (['270082637', '269726900', '270021884'], 'AI in Robotics'),\n",
    "    (['269934201', '269769382', '269911544'], 'Algorithm'),\n",
    "    (['269721983', '269928133', '000171581'], 'Data Science')\n",
    "]\n",
    "\n",
    "for pi_ids, topic in candidate_sets:\n",
    "    print(f\"Topic: {topic}\")\n",
    "    pi_candidate, co_pi_candidates, scores = rank_candidates(topic, pi_ids)\n",
    "    print(\"Predicted PI:\", pi_candidate)\n",
    "    print(\"Predicted Co-PIs:\", co_pi_candidates)\n",
    "    print(\"Candidate Combined Scores:\", scores)\n",
    "    # display(df[df.pi_id.isin(pi_ids)][['pi_id', 'pi_full_name', 'role', 'department', 'leadership', 'experience_years', 'program_element']])\n",
    "    # display(df_grouped[df_grouped.pi_id.isin(pi_ids)][['pi_id', 'award_count', 'experience_years', 'leadership']])\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import random\n",
    "\n",
    "# for i in range(20):\n",
    "#     pi_ids = candidate_sets[random.randint(1, 10) - 1][0]\n",
    "#     topic = candidate_sets[random.randint(1, 10) - 1][1]\n",
    "#     print(f\"Topic: {topic}\")\n",
    "#     pi_candidate, co_pi_candidates, scores = rank_candidates(topic, pi_ids)\n",
    "#     print(\"Predicted PI:\", pi_candidate)\n",
    "#     print(\"Predicted Co-PIs:\", co_pi_candidates)\n",
    "#     print(\"Candidate Combined Scores:\", scores)\n",
    "#     print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# pi = [269948909, 000173003, 269886945], topic = 'STATISTICS'\n",
    "# pi = [269807623, 269794080, 269879497], topic = 'AI Circuits design'\n",
    "# pi = [269807623, 269794080, 269879497], topic = 'hardware software co-design'\n",
    "# pi = [269677663, 269988546, 270021884], topic = 'Trustworthy AI'\n",
    "# pi = [269677663, 269988546, 269814599], topic = 'Networking safety'\n",
    "# pi = [269811881, 269958535, 270083608], topic = 'Bioinformatics'\n",
    "# pi = [270082637, 269726900, 269963435], topic = 'Robotics'\n",
    "# pi = [270082637, 269726900, 270021884], topic = 'AI in Robotics'\n",
    "# pi = [269934201, 269769382, 269911544], topic = 'Algorithm'\n",
    "# pi = [269721983, 269928133, 000171581], topic = 'Data Science'\n",
    "# rank_candidates(research_topic, candidate_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[df['pi_id'] == '000173003'][['pi_full_name', 'pi_id', 'role', 'department', 'leadership', 'experience_years', 'program_element']]\n",
    "df[df.pi_id == '269769382']['pi_full_name'].to_list()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.pi_full_name == 'Xin Zhang']['pi_id'].to_list()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pi_ids_to_analyze = ['270082637', '269726900', '270021884']\n",
    "df[df.pi_id.isin(pi_ids_to_analyze)][['pi_id', 'pi_full_name', 'role', 'department', 'leadership', 'experience_years', 'program_element']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_r = [1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = [1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1]  # predicted\n",
    "y_true = [1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1]  # actual/ground truth\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "\n",
    "precision = precision_score(y_true, y_pred)\n",
    "recall = recall_score(y_true, y_pred)\n",
    "f1 = f1_score(y_true, y_pred)\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1 Score: {f1}\")\n",
    "print(f\"Accuracy: {accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample raw results (each as a string).\n",
    "raw_results = [\n",
    "    \"['269948909', '000173003', '269886945'] - STATISTICS - Xin Zhang - 269948909 - correct\",\n",
    "    \"['269807623', '269794080', '269879497'] - AI Circuits design - Azadeh Davoodi - 269794080 - correct\",\n",
    "    \"['269807623', '269794080', '269879497'] - hardware software co-design - Azadeh Davoodi - 269794080 - correct\",\n",
    "    \"['269677663', '269988546', '270021884'] - Trustworthy AI - Benjamin Fuller - 269988546 - wrong\",\n",
    "    \"['269677663', '269988546', '269814599'] - Networking safety - Benjamin Fuller - 269988546 - correct\",\n",
    "    \"['269811881', '269958535', '270083608'] - Bioinformatics - Jianlin Cheng - 269811881 - correct\",\n",
    "    \"['270082637', '269726900', '269963435'] - Robotics - Rodrigo O Spinola - 270082637 - correct\",\n",
    "    \"['270082637', '269726900', '270021884'] - AI in Robotics - Guido F Montufar Cuartas - 270021884 - wrong\",\n",
    "    \"['269934201', '269769382', '269911544'] - Algorithm - Michael Dinitz - 269934201 - correct\",\n",
    "    \"['269721983', '269928133', '000171581'] - Data Science - Sofya Raskhodnikova - 269721983 - correct\",\n",
    "    \"\",\n",
    "    \"['000025017', '000025762', '000030655'] - knowledge graph - Steven N MacEachern - 000025762 - correct\",\n",
    "    \"['000025017', '000025762', '000030655'] - AI - Steven N MacEachern - 000025762 - correct\",\n",
    "    \"['000025017', '000025762', '000030655'] - Neuroscience - Steven N MacEachern - 000025762 - correct\",\n",
    "    \"['000025017', '000025762', '000030655'] - STATISTICS - Steven N MacEachern - 000025762 - correct\"\n",
    "]\n",
    "\n",
    "# Initialize counters.\n",
    "tp = 0  # true positives\n",
    "fp = 0  # false positives\n",
    "fn = 0  # false negatives\n",
    "total = 0  # total evaluated samples\n",
    "\n",
    "# Loop through each line in the results.\n",
    "for line in raw_results:\n",
    "    # Skip empty lines (if any)\n",
    "    if not line.strip():\n",
    "        continue\n",
    "\n",
    "    total += 1\n",
    "    \n",
    "    # The label is the last token when splitting by ' - '\n",
    "    # We assume that the parts are separated by \" - \" and the last part is the status.\n",
    "    parts = line.split(\" - \")\n",
    "    status = parts[-1].strip().lower()  # e.g., 'correct', 'wrong', 'waiting'\n",
    "    \n",
    "    if status == \"correct\":\n",
    "        tp += 1\n",
    "    elif status == \"wrong\":\n",
    "        # A wrong prediction means the algorithm made a prediction but it did not match\n",
    "        # the true answer. This counts as a false positive and a missed correct answer (FN).\n",
    "        fp += 1\n",
    "        fn += 1\n",
    "    else:\n",
    "        print(f\"Unrecognized status: {status}\")\n",
    "\n",
    "# Calculate precision, recall, F1 and accuracy rate.\n",
    "if (tp + fp) > 0:\n",
    "    precision = tp / (tp + fp)\n",
    "else:\n",
    "    precision = 0\n",
    "\n",
    "if (tp + fn) > 0:\n",
    "    recall = tp / (tp + fn)\n",
    "else:\n",
    "    recall = 0\n",
    "\n",
    "if (precision + recall) > 0:\n",
    "    f1 = 2 * (precision * recall) / (precision + recall)\n",
    "else:\n",
    "    f1 = 0\n",
    "\n",
    "accuracy = tp / total if total > 0 else 0\n",
    "\n",
    "# Display the results.\n",
    "print(\"Evaluation metrics:\")\n",
    "print(\"-------------------\")\n",
    "print(f\"Total samples: {total}\")\n",
    "print(f\"Correct (TP): {tp}\")\n",
    "print(f\"Wrong (FP): {fp}\")\n",
    "print(f\"Waiting (FN): {fn}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall:    {recall:.4f}\")\n",
    "print(f\"F1 score:  {f1:.4f}\")\n",
    "print(f\"Accuracy:  {accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Updated raw results list.\n",
    "raw_results = [\n",
    "    \"['269948909', '000173003', '269886945'] - STATISTICS - 000173003 - Peter D Hislop - 2nd most optimal option\",\n",
    "    \"['269807623', '269794080', '269879497'] - AI Circuits design - 269794080 - Azadeh Davoodi - correct\",\n",
    "    \"['269807623', '269794080', '269879497'] - hardware software co-design - 269794080 - Azadeh Davoodi - correct\",\n",
    "    \"['269677663', '269988546', '270021884'] - Trustworthy AI - 270021884 - Guido F Montufar Cuartas - correct\",\n",
    "    \"['269677663', '269988546', '269814599'] - Networking safety - 269814599 - Srinivas Shakkottai - wrong\",\n",
    "    \"['269811881', '269958535', '270083608'] - Bioinformatics - 269958535 - HaiYing   Wang - wrong\",\n",
    "    \"['270082637', '269726900', '269963435'] - Robotics - 270082637 - Rodrigo O Spinola - correct\",\n",
    "    \"['270082637', '269726900', '270021884'] - AI in Robotics - 270021884 - Guido F Montufar Cuartas - wrong\",\n",
    "    \"['269934201', '269769382', '269911544'] - Algorithm - 269769382 - Susan D Nickerson - wrong\",\n",
    "    \"['269721983', '269928133', '000171581'] - Data Science - 269721983 - Sofya Raskhodnikova - correct\",\n",
    "    \"['000025017', '000025762', '000030655'] - knowledge graph - 000025762 - Steven N MacEachern - correct\",\n",
    "    \"['000025017', '000025762', '000030655'] - AI - 000025762 - Steven N MacEachern - correct\",\n",
    "    \"['000025017', '000025762', '000030655'] - Neuroscience - 000025762 - Steven N MacEachern - correct\",\n",
    "    \"['000025017', '000025762', '000030655'] - STATISTICS - 000025762 - Steven N MacEachern - correct\"\n",
    "]\n",
    "\n",
    "# Initialize counters.\n",
    "tp = 0  # true positives\n",
    "fp = 0  # false positives\n",
    "fn = 0  # false negatives\n",
    "total = 0  # total valid samples\n",
    "\n",
    "# Process each line in the results.\n",
    "for line in raw_results:\n",
    "    if not line.strip():\n",
    "        continue  # Skip empty lines.\n",
    "    \n",
    "    total += 1\n",
    "    parts = line.split(\" - \")\n",
    "    # The final token is the prediction label.\n",
    "    outcome = parts[-1].strip().lower()\n",
    "    \n",
    "    # Count outcomes; only exactly 'correct' is TP.\n",
    "    if outcome == \"correct\":\n",
    "        tp += 1\n",
    "    elif outcome in [\"wrong\", \"2nd most optimal option\"]:\n",
    "        fp += 1\n",
    "        fn += 1\n",
    "    else:\n",
    "        print(f\"Unrecognized status: {outcome}\")\n",
    "\n",
    "# Compute metrics.\n",
    "precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "recall    = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "f1        = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "accuracy  = tp / total if total > 0 else 0\n",
    "\n",
    "# Output the results.\n",
    "print(\"Evaluation metrics:\")\n",
    "print(\"-------------------\")\n",
    "print(f\"Total samples: {total}\")\n",
    "print(f\"Correct (TP): {tp}\")\n",
    "print(f\"Wrong (FP): {fp}\")\n",
    "print(f\"False Negatives (FN): {fn}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall:    {recall:.4f}\")\n",
    "print(f\"F1 score:  {f1:.4f}\")\n",
    "print(f\"Accuracy:  {accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agent",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
