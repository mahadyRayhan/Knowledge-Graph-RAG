{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/agent/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv() ## load all the environment variables from .env\n",
    "import glob\n",
    "# import streamlit as st\n",
    "import os\n",
    "from PIL import Image\n",
    "import google.generativeai as genai\n",
    "from IPython.display import display\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import textwrap\n",
    "from typing import List, Dict, Tuple, Optional # For type hinting\n",
    "import time\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "genai.configure(api_key=os.getenv(\"GOOGLE_API_KEY\"))\n",
    "\n",
    "## Load Gemini model\n",
    "model=genai.GenerativeModel('gemini-2.0-flash-thinking-exp-01-21')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gemini_response(input,image,user_prompt):\n",
    "    response=model.generate_content([input,image[0],user_prompt])\n",
    "    return response.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DATA Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading files in 2022...\n",
      "Reading files in 2024...\n",
      "Reading files in 2023...\n",
      "Reading files in 2021...\n",
      "Reading files in 2020...\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "data_directory = 'data/ranking_data/'\n",
    "records = []\n",
    "\n",
    "def safe_get(data, keys, default=None):\n",
    "    \"\"\"\n",
    "    Safely get a nested key from a dictionary using a list of keys.\n",
    "    Returns default if any key is missing.\n",
    "    \"\"\"\n",
    "    for key in keys:\n",
    "        if isinstance(data, dict) and key in data:\n",
    "            data = data[key]\n",
    "        else:\n",
    "            return default\n",
    "    return data\n",
    "\n",
    "for sub_dir in os.listdir(data_directory):\n",
    "    print(f\"Reading files in {sub_dir}...\")\n",
    "    sub_directory = os.path.join(data_directory, sub_dir)\n",
    "    for filename in os.listdir(sub_directory):\n",
    "        if filename.endswith('.json'):\n",
    "            filepath = os.path.join(sub_directory, filename)\n",
    "            try:\n",
    "                with open(filepath, 'r') as file:\n",
    "                    data = json.load(file)\n",
    "            except Exception as e:\n",
    "                print(f\"Error reading {filepath}: {e}\")\n",
    "                continue\n",
    "\n",
    "            # Extract award-level context information safely\n",
    "            award_type = data.get(\"awd_istr_txt\")\n",
    "            award_title = data.get(\"awd_titl_txt\")\n",
    "            abstract = data.get(\"abst_narr_txt\")\n",
    "            org_name = data.get(\"org_long_name\")\n",
    "            org_name2 = data.get(\"org_long_name2\")\n",
    "            perf_inst_name = safe_get(data, [\"perf_inst\", \"perf_inst_name\"])\n",
    "            \n",
    "            # Extract program element and reference safely (checking if list exists)\n",
    "            pgm_ele_list = data.get(\"pgm_ele\")\n",
    "            if isinstance(pgm_ele_list, list) and len(pgm_ele_list) > 0:\n",
    "                program_element = pgm_ele_list[0].get(\"pgm_ele_long_name\")\n",
    "            else:\n",
    "                program_element = None\n",
    "\n",
    "            pgm_ref_list = data.get(\"pgm_ref\")\n",
    "            if isinstance(pgm_ref_list, list) and len(pgm_ref_list) > 0:\n",
    "                program_reference = pgm_ref_list[0].get(\"pgm_ref_long_name\")\n",
    "            else:\n",
    "                program_reference = None\n",
    "\n",
    "            # Get investigator information, ensuring it's a list\n",
    "            pi_list = data.get(\"pi\")\n",
    "            if not isinstance(pi_list, list):\n",
    "                continue\n",
    "\n",
    "            # Loop through each investigator in the file\n",
    "            for pi in pi_list:\n",
    "                record = {\n",
    "                    \"award_type\": award_type,\n",
    "                    \"award_title\": award_title,\n",
    "                    \"abstract\": abstract,\n",
    "                    \"org_name\": org_name,\n",
    "                    \"org_name2\": org_name2,\n",
    "                    \"perf_inst_name\": perf_inst_name,\n",
    "                    \"program_element\": program_element,\n",
    "                    \"program_reference\": program_reference,\n",
    "                    \"pi_id\": pi.get(\"pi_id\"),\n",
    "                    \"pi_full_name\": pi.get(\"pi_full_name\", \"\").strip() if pi.get(\"pi_full_name\") else None,\n",
    "                    \"role\": pi.get(\"proj_role_code2\", \"\").strip() if pi.get(\"proj_role_code2\") else None,\n",
    "                    \"department\": pi.get(\"pi_dept_name\"),\n",
    "                    \"email\": pi.get(\"pi_email_addr\"),\n",
    "                    \"start_date\": pi.get(\"start_date\")\n",
    "                }\n",
    "                records.append(record)\n",
    "\n",
    "# Create a DataFrame from the records\n",
    "df = pd.DataFrame(records)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>award_type</th>\n",
       "      <th>award_title</th>\n",
       "      <th>abstract</th>\n",
       "      <th>org_name</th>\n",
       "      <th>org_name2</th>\n",
       "      <th>perf_inst_name</th>\n",
       "      <th>program_element</th>\n",
       "      <th>program_reference</th>\n",
       "      <th>pi_id</th>\n",
       "      <th>pi_full_name</th>\n",
       "      <th>role</th>\n",
       "      <th>department</th>\n",
       "      <th>email</th>\n",
       "      <th>start_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Standard Grant</td>\n",
       "      <td>MRI: Acquisition of a High-Performance Computa...</td>\n",
       "      <td>This project will acquire and deploy a high-pe...</td>\n",
       "      <td>Directorate for Computer and Information Scien...</td>\n",
       "      <td>Office of Advanced Cyberinfrastructure (OAC)</td>\n",
       "      <td>Oklahoma State University</td>\n",
       "      <td>Major Research Instrumentation</td>\n",
       "      <td>WOMEN, MINORITY, DISABLED, NEC</td>\n",
       "      <td>269967889</td>\n",
       "      <td>Terrance   Figy</td>\n",
       "      <td>Co-Principal Investigator</td>\n",
       "      <td>Mathematics, Statistics, and Physics</td>\n",
       "      <td>Terrance.Figy@wichita.edu</td>\n",
       "      <td>2024-08-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Standard Grant</td>\n",
       "      <td>MRI: Acquisition of a High-Performance Computa...</td>\n",
       "      <td>This project will acquire and deploy a high-pe...</td>\n",
       "      <td>Directorate for Computer and Information Scien...</td>\n",
       "      <td>Office of Advanced Cyberinfrastructure (OAC)</td>\n",
       "      <td>Oklahoma State University</td>\n",
       "      <td>Major Research Instrumentation</td>\n",
       "      <td>WOMEN, MINORITY, DISABLED, NEC</td>\n",
       "      <td>269758255</td>\n",
       "      <td>Pratul K Agarwal</td>\n",
       "      <td>Principal Investigator</td>\n",
       "      <td></td>\n",
       "      <td>pratul.agarwal@okstate.edu</td>\n",
       "      <td>2022-08-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Standard Grant</td>\n",
       "      <td>MRI: Acquisition of a High-Performance Computa...</td>\n",
       "      <td>This project will acquire and deploy a high-pe...</td>\n",
       "      <td>Directorate for Computer and Information Scien...</td>\n",
       "      <td>Office of Advanced Cyberinfrastructure (OAC)</td>\n",
       "      <td>Oklahoma State University</td>\n",
       "      <td>Major Research Instrumentation</td>\n",
       "      <td>WOMEN, MINORITY, DISABLED, NEC</td>\n",
       "      <td>000224099</td>\n",
       "      <td>Mickey   Slimp</td>\n",
       "      <td>Co-Principal Investigator</td>\n",
       "      <td>Department of Chemistry</td>\n",
       "      <td></td>\n",
       "      <td>2024-08-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Standard Grant</td>\n",
       "      <td>MRI: Acquisition of a High-Performance Computa...</td>\n",
       "      <td>This project will acquire and deploy a high-pe...</td>\n",
       "      <td>Directorate for Computer and Information Scien...</td>\n",
       "      <td>Office of Advanced Cyberinfrastructure (OAC)</td>\n",
       "      <td>Oklahoma State University</td>\n",
       "      <td>Major Research Instrumentation</td>\n",
       "      <td>WOMEN, MINORITY, DISABLED, NEC</td>\n",
       "      <td>269666332</td>\n",
       "      <td>William H Hsu</td>\n",
       "      <td>Co-Principal Investigator</td>\n",
       "      <td>Computer Science</td>\n",
       "      <td>bhsu@ksu.edu</td>\n",
       "      <td>2022-08-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Standard Grant</td>\n",
       "      <td>MRI: Acquisition of a High-Performance Computa...</td>\n",
       "      <td>This project will acquire and deploy a high-pe...</td>\n",
       "      <td>Directorate for Computer and Information Scien...</td>\n",
       "      <td>Office of Advanced Cyberinfrastructure (OAC)</td>\n",
       "      <td>Oklahoma State University</td>\n",
       "      <td>Major Research Instrumentation</td>\n",
       "      <td>WOMEN, MINORITY, DISABLED, NEC</td>\n",
       "      <td>270046494</td>\n",
       "      <td>Robert   Fleming</td>\n",
       "      <td>Co-Principal Investigator</td>\n",
       "      <td>Engineering</td>\n",
       "      <td>rofleming@AState.edu</td>\n",
       "      <td>2024-08-29</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       award_type                                        award_title  \\\n",
       "0  Standard Grant  MRI: Acquisition of a High-Performance Computa...   \n",
       "1  Standard Grant  MRI: Acquisition of a High-Performance Computa...   \n",
       "2  Standard Grant  MRI: Acquisition of a High-Performance Computa...   \n",
       "4  Standard Grant  MRI: Acquisition of a High-Performance Computa...   \n",
       "7  Standard Grant  MRI: Acquisition of a High-Performance Computa...   \n",
       "\n",
       "                                            abstract  \\\n",
       "0  This project will acquire and deploy a high-pe...   \n",
       "1  This project will acquire and deploy a high-pe...   \n",
       "2  This project will acquire and deploy a high-pe...   \n",
       "4  This project will acquire and deploy a high-pe...   \n",
       "7  This project will acquire and deploy a high-pe...   \n",
       "\n",
       "                                            org_name  \\\n",
       "0  Directorate for Computer and Information Scien...   \n",
       "1  Directorate for Computer and Information Scien...   \n",
       "2  Directorate for Computer and Information Scien...   \n",
       "4  Directorate for Computer and Information Scien...   \n",
       "7  Directorate for Computer and Information Scien...   \n",
       "\n",
       "                                      org_name2             perf_inst_name  \\\n",
       "0  Office of Advanced Cyberinfrastructure (OAC)  Oklahoma State University   \n",
       "1  Office of Advanced Cyberinfrastructure (OAC)  Oklahoma State University   \n",
       "2  Office of Advanced Cyberinfrastructure (OAC)  Oklahoma State University   \n",
       "4  Office of Advanced Cyberinfrastructure (OAC)  Oklahoma State University   \n",
       "7  Office of Advanced Cyberinfrastructure (OAC)  Oklahoma State University   \n",
       "\n",
       "                  program_element               program_reference      pi_id  \\\n",
       "0  Major Research Instrumentation  WOMEN, MINORITY, DISABLED, NEC  269967889   \n",
       "1  Major Research Instrumentation  WOMEN, MINORITY, DISABLED, NEC  269758255   \n",
       "2  Major Research Instrumentation  WOMEN, MINORITY, DISABLED, NEC  000224099   \n",
       "4  Major Research Instrumentation  WOMEN, MINORITY, DISABLED, NEC  269666332   \n",
       "7  Major Research Instrumentation  WOMEN, MINORITY, DISABLED, NEC  270046494   \n",
       "\n",
       "       pi_full_name                       role  \\\n",
       "0   Terrance   Figy  Co-Principal Investigator   \n",
       "1  Pratul K Agarwal     Principal Investigator   \n",
       "2    Mickey   Slimp  Co-Principal Investigator   \n",
       "4     William H Hsu  Co-Principal Investigator   \n",
       "7  Robert   Fleming  Co-Principal Investigator   \n",
       "\n",
       "                             department                       email  \\\n",
       "0  Mathematics, Statistics, and Physics   Terrance.Figy@wichita.edu   \n",
       "1                                        pratul.agarwal@okstate.edu   \n",
       "2               Department of Chemistry                               \n",
       "4                      Computer Science                bhsu@ksu.edu   \n",
       "7                           Engineering        rofleming@AState.edu   \n",
       "\n",
       "   start_date  \n",
       "0  2024-08-29  \n",
       "1  2022-08-03  \n",
       "2  2024-08-29  \n",
       "4  2022-08-03  \n",
       "7  2024-08-29  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[df['role'].isin(['Co-Principal Investigator', 'Principal Investigator'])]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(83112, 14)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_csv('combined_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scholer Identifier LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_data_by_pi(df: pd.DataFrame, pi_ids: List[str]) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Filters the DataFrame to include only rows matching the provided PI IDs.\n",
    "\n",
    "    Args:\n",
    "        df: The input DataFrame.\n",
    "        pi_ids: A list of PI IDs (strings) to filter by.\n",
    "\n",
    "    Returns:\n",
    "        A DataFrame containing only the rows for the specified PI IDs.\n",
    "    \"\"\"\n",
    "    print(f\"Filtering DataFrame for PI IDs: {pi_ids}...\")\n",
    "    filtered = df[df['pi_id'].isin(pi_ids)].copy()\n",
    "    # print(f\"Found {len(filtered)} relevant entries.\")\n",
    "    return filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_pi_data_for_prompt(filtered_df: pd.DataFrame, pi_ids_to_format: List[str]) -> Tuple[str, Dict[str, str]]:\n",
    "    \"\"\"\n",
    "    Formats the filtered PI data into a string suitable for the prompt context.\n",
    "\n",
    "    Args:\n",
    "        filtered_df: The DataFrame already filtered for relevant PIs.\n",
    "        pi_ids_to_format: The original list of PI IDs requested, to ensure all are mentioned.\n",
    "\n",
    "\n",
    "    Returns:\n",
    "        A tuple containing:\n",
    "            - formatted_data_string: A string with formatted details for each PI.\n",
    "            - pi_names_dict: A dictionary mapping PI ID to PI full name.\n",
    "    \"\"\"\n",
    "    # print(\"Formatting data for prompt...\")\n",
    "    formatted_data = \"\"\n",
    "    pi_names = {} # Dictionary to store PI names\n",
    "\n",
    "    if filtered_df.empty:\n",
    "        print(\"Warning: Filtered DataFrame is empty. Formatting 'no data' message.\")\n",
    "        formatted_data = \"No data could be retrieved for the specified potential collaborators.\\n\"\n",
    "        for pi_id in pi_ids_to_format:\n",
    "             pi_names[pi_id] = f\"PI ID {pi_id}\" # Use ID as placeholder name\n",
    "        return formatted_data, pi_names\n",
    "\n",
    "    # Iterate through the original list to ensure all requested PIs are accounted for\n",
    "    for pi_id in pi_ids_to_format:\n",
    "        pi_specific_data = filtered_df[filtered_df['pi_id'] == pi_id]\n",
    "\n",
    "        if not pi_specific_data.empty:\n",
    "            # Get consistent name and department from the first entry\n",
    "            full_name = pi_specific_data['pi_full_name'].iloc[0]\n",
    "            department = pi_specific_data['department'].iloc[0]\n",
    "            pi_names[pi_id] = full_name\n",
    "\n",
    "            formatted_data += f\"--- Researcher: {full_name} (ID: {pi_id}) ---\\n\"\n",
    "            formatted_data += f\"Department: {department}\\n\"\n",
    "            formatted_data += \"Relevant Roles & Awards Found:\\n\"\n",
    "\n",
    "            for index, row in pi_specific_data.iterrows():\n",
    "                formatted_data += f\"- Role: {row.get('role', 'N/A')}\\n\"\n",
    "                formatted_data += f\"  Award Title: {row.get('award_title', 'N/A')}\\n\"\n",
    "                formatted_data += f\"  Start Date: {row.get('start_date', 'N/A')}\\n\"\n",
    "                abstract_preview = textwrap.shorten(row.get('abstract', 'N/A'), width=200, placeholder=\"...\")\n",
    "                formatted_data += f\"  Abstract Snippet: {abstract_preview}\\n\"\n",
    "                formatted_data += f\"  Program Element/Reference: {row.get('program_element', 'N/A')} / {row.get('program_reference', 'N/A')}\\n\\n\"\n",
    "        else:\n",
    "            # Handle case where a specific PI ID from the list had no data in the filtered df\n",
    "            formatted_data += f\"--- Researcher ID: {pi_id} ---\\n\"\n",
    "            formatted_data += \"No award data found in the provided dataset for this PI.\\n\\n\"\n",
    "            pi_names[pi_id] = f\"PI ID {pi_id}\" # Use ID as placeholder name\n",
    "\n",
    "    # print(\"Data formatting complete.\")\n",
    "    return formatted_data, pi_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_recommendation_prompt(formatted_data_string: str, pi_names_dict: Dict[str, str], research_topic: str) -> str:\n",
    "    \"\"\"\n",
    "    Generates the full prompt string for the Gemini model.\n",
    "\n",
    "    Args:\n",
    "        formatted_data_string: The formatted string containing PI details.\n",
    "        pi_names_dict: A dictionary mapping PI ID to PI name.\n",
    "        research_topic: The research topic for collaboration.\n",
    "\n",
    "    Returns:\n",
    "        The complete prompt string.\n",
    "    \"\"\"\n",
    "    # print(\"Generating prompt...\")\n",
    "    collaborator_names_list = \", \".join(pi_names_dict.values())\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "        Context:\n",
    "        The following researchers ({collaborator_names_list}) are considering collaborating on a new research project focused on the topic '{research_topic}'. Below is information extracted from a database about their previous grants and roles:\n",
    "\n",
    "        {formatted_data_string}\n",
    "\n",
    "        Task:\n",
    "        Based *only* on the information provided above, please analyze the qualifications, experience, and relevance of past work for each researcher ({collaborator_names_list}). Recommend which of these individuals would be the most suitable Principal Investigator (PI) to lead this new collaborative project on '{research_topic}'.\n",
    "\n",
    "        Provide a detailed explanation for your recommendation. Consider factors apparent from the data, such as:\n",
    "        - Direct relevance of their past research (award titles, abstracts, program elements) to the topic '{research_topic}'.\n",
    "        - Demonstrated experience (e.g., number of awards listed, roles held like 'Principal Investigator').\n",
    "        - Any indicators of leadership or seniority (e.g., award types like 'Career Award' if present, consistent PI roles).\n",
    "\n",
    "        Please identify the suggested PI clearly by name.\n",
    "        \"\"\"\n",
    "    # print(\"Prompt generated.\")\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Please identify the suggested PI clearly by name and justify your choice thoroughly using specific evidence from the provided context. If the data is insufficient to make a strong recommendation for any particular candidate, please state that clearly as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gemini_response(model: genai.GenerativeModel, prompt: str) -> Tuple[Optional[str], float]:\n",
    "    \"\"\"\n",
    "    Sends the prompt to the Gemini model, streams the response, and measures time.\n",
    "\n",
    "    Args:\n",
    "        model: The configured Gemini model object.\n",
    "        prompt: The prompt string to send to the model.\n",
    "\n",
    "    Returns:\n",
    "        A tuple containing:\n",
    "            - The full response text as a string (or None if an error occurs).\n",
    "            - The time taken for the API call in seconds.\n",
    "    \"\"\"\n",
    "    # print(\"--- Sending Request to Gemini ---\")\n",
    "    start_time = time.time()\n",
    "    full_response_text = \"\"\n",
    "    contents = [prompt] # Prepare contents for the API\n",
    "\n",
    "    try:\n",
    "        responses = model.generate_content(contents, stream=True)\n",
    "        # responses = model.generate_content(contents)\n",
    "\n",
    "        # print(\"\\n-------Response--------\")\n",
    "        for response in responses:\n",
    "            # print(response.text, end=\"\")\n",
    "            full_response_text += response.text\n",
    "        # print(\"\\n-----------------------\")\n",
    "        PI_NAME = full_response_text.split('\\n')[-1].strip()\n",
    "        print(f\"\\nPI: {PI_NAME}\")\n",
    "\n",
    "        response_time = time.time() - start_time\n",
    "        print(f\"\\nResponse generated in {response_time:.2f} seconds.\")\n",
    "        return full_response_text, response_time\n",
    "\n",
    "    except AttributeError:\n",
    "        response_time = time.time() - start_time\n",
    "        print(\"\\nError: 'model' object not found or not configured correctly.\")\n",
    "        print(\"Please ensure the 'model' variable holds your loaded Gemini model.\")\n",
    "        return None, response_time\n",
    "    except Exception as e:\n",
    "        response_time = time.time() - start_time\n",
    "        print(f\"\\nAn error occurred during the API call: {e}\")\n",
    "        print(f\"Attempt failed after {response_time:.2f} seconds.\")\n",
    "        return None, response_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_pi(df: pd.DataFrame, model: genai.GenerativeModel, pi_ids: List[str], research_topic: str) -> Optional[str]:\n",
    "    \"\"\"\n",
    "    Orchestrates the process of filtering data, formatting, generating prompt,\n",
    "    and getting a PI recommendation from the Gemini model.\n",
    "\n",
    "    Args:\n",
    "        df: The main DataFrame.\n",
    "        model: The configured Gemini model object.\n",
    "        pi_ids: A list of PI IDs to consider.\n",
    "        research_topic: The topic for collaboration.\n",
    "\n",
    "    Returns:\n",
    "        The recommendation text from the model, or None if an error occurred\n",
    "        or essential steps failed.\n",
    "    \"\"\"\n",
    "    print(f\"\\n--- Starting PI Recommendation Process for Topic: '{research_topic}' ---\")\n",
    "\n",
    "    # 1. Filter Data\n",
    "    filtered_data = filter_data_by_pi(df, pi_ids)\n",
    "    # Optional: Add a check here if you want to stop if no data is found at all\n",
    "    # if filtered_data.empty:\n",
    "    #     print(\"Stopping process as no data was found for any specified PI.\")\n",
    "    #     return None\n",
    "\n",
    "    # 2. Format Data\n",
    "    # Pass the original pi_ids list to ensure all are mentioned in formatting\n",
    "    formatted_text, pi_names = format_pi_data_for_prompt(filtered_data, pi_ids)\n",
    "\n",
    "    # 3. Generate Prompt\n",
    "    prompt_text = generate_recommendation_prompt(formatted_text, pi_names, research_topic)\n",
    "\n",
    "    # 4. Get Response\n",
    "    recommendation, duration = get_gemini_response(model, prompt_text)\n",
    "\n",
    "    # print(f\"--- PI Recommendation Process Complete ({duration:.2f}s) ---\")\n",
    "    return recommendation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Starting PI Recommendation Process for Topic: 'STATISTICS' ---\n",
      "Filtering DataFrame for PI IDs: ['000025017', '000025762', '000030655']...\n",
      "\n",
      "PI: **Suggested Principal Investigator: Steven N MacEachern**\n",
      "\n",
      "Response generated in 11.70 seconds.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    pi_ids_to_analyze = ['000025017', '000025762', '000030655']\n",
    "    research_topic = 'STATISTICS'\n",
    "\n",
    "    # --- Run the Recommendation Process ---\n",
    "    recommendation_result = recommend_pi(df, model, pi_ids_to_analyze, research_topic)\n",
    "\n",
    "    # Optional: Do something with the result\n",
    "    if recommendation_result:\n",
    "        # print(\"\\n--- Final Recommendation Text ---\")\n",
    "        # print(recommendation_result) # Already printed during streaming\n",
    "        pass # Result is already printed by get_gemini_response\n",
    "    else:\n",
    "        print(\"\\nRecommendation could not be generated.\")\n",
    "\n",
    "except ImportError:\n",
    "    print(\"Please install required libraries: pip install pandas google-generativeai\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred during setup or execution: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing with topic: knowledge graph\n",
      "\n",
      "--- Starting PI Recommendation Process for Topic: 'knowledge graph' ---\n",
      "Filtering DataFrame for PI IDs: ['000025017', '000025762', '000030655']...\n",
      "\n",
      "PI: **Caveat:** It is important to reiterate that *none* of the researchers' listed past projects are directly related to 'knowledge graph'.  The recommendation of Steven N MacEachern is based on the *closest conceptual link* found in his research description (focus on data-driven knowledge and causal relationships) and his demonstrated experience as a PI.  Ideally, a PI for a 'knowledge graph' project would have a background in computer science, information science, or a related field with direct experience in semantic web technologies, graph databases, or knowledge representation. However, *among these three researchers*, Steven N MacEachern appears to be the most suitable choice based on the limited information provided.\n",
      "\n",
      "Response generated in 13.26 seconds.\n",
      "--------------------------------------------------\n",
      "Testing with topic: AI\n",
      "\n",
      "--- Starting PI Recommendation Process for Topic: 'AI' ---\n",
      "Filtering DataFrame for PI IDs: ['000025017', '000025762', '000030655']...\n",
      "\n",
      "PI: In summary, although Howard B Bluestein has a strong track record in Meteorology research and leadership, Steven N MacEachern's expertise in Statistics and Bayesian methods makes him the most qualified and relevant choice to lead a new collaborative project focused on 'AI'. His background directly addresses the theoretical and methodological underpinnings of AI, making him the most strategically suitable PI for this initiative.\n",
      "\n",
      "Response generated in 11.61 seconds.\n",
      "--------------------------------------------------\n",
      "Testing with topic: Neuroscience\n",
      "\n",
      "--- Starting PI Recommendation Process for Topic: 'Neuroscience' ---\n",
      "Filtering DataFrame for PI IDs: ['000025017', '000025762', '000030655']...\n",
      "\n",
      "PI: **In conclusion, while none of the researchers are ideal candidates based on direct Neuroscience experience, Steven N MacEachern's statistical expertise provides the most tenuous, yet still relatively more plausible, link to the analytical and data-driven aspects often present in Neuroscience research, making him the most suitable choice for PI *among these three*, based solely on the provided data.** It is critical to reiterate that this recommendation is based on selecting the *least unsuitable* candidate from a group where none have demonstrated direct relevance to Neuroscience in their prior work as presented.\n",
      "\n",
      "Response generated in 16.36 seconds.\n",
      "--------------------------------------------------\n",
      "Testing with topic: STATISTICS\n",
      "\n",
      "--- Starting PI Recommendation Process for Topic: 'STATISTICS' ---\n",
      "Filtering DataFrame for PI IDs: ['000025017', '000025762', '000030655']...\n",
      "\n",
      "PI: Therefore, based *solely* on the provided information, **Steven N MacEachern** is the recommended Principal Investigator for the new collaborative project on 'STATISTICS'.\n",
      "\n",
      "Response generated in 11.53 seconds.\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Test with various topics dynamically.\n",
    "for test_topic in [\"knowledge graph\", \"AI\", \"Neuroscience\", \"STATISTICS\"]:\n",
    "    print(\"Testing with topic:\", test_topic)\n",
    "    recommendation_result = recommend_pi(df, model, pi_ids_to_analyze, test_topic)\n",
    "    # print(\"Predicted PI:\", pi_candidate)\n",
    "    # print(\"Predicted Co-PIs:\", co_pi_candidates)\n",
    "    # print(\"Candidate Combined Scores:\", scores)\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Starting PI Recommendation Process for Topic: 'STATISTICS' ---\n",
      "Filtering DataFrame for PI IDs: ['269948909', '000173003', '269886945']...\n",
      "\n",
      "PI: **In conclusion, Xin Zhang's departmental affiliation, the titles and abstracts of his funded projects, and the explicit mention of 'STATISTICS' and 'Machine Learning Theory' in his program elements clearly establish him as the most qualified and relevant individual to serve as the Principal Investigator for a new collaborative project on 'STATISTICS'.**\n",
      "\n",
      "Response generated in 13.91 seconds.\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Starting PI Recommendation Process for Topic: 'AI Circuits design' ---\n",
      "Filtering DataFrame for PI IDs: ['269807623', '269794080', '269879497']...\n",
      "\n",
      "PI: **Suggested Principal Investigator: Azadeh Davoodi**\n",
      "\n",
      "Response generated in 13.75 seconds.\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Starting PI Recommendation Process for Topic: 'hardware software co-design' ---\n",
      "Filtering DataFrame for PI IDs: ['269807623', '269794080', '269879497']...\n",
      "\n",
      "PI: **Suggested Principal Investigator: Azadeh Davoodi**\n",
      "\n",
      "Response generated in 13.48 seconds.\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Starting PI Recommendation Process for Topic: 'Trustworthy AI' ---\n",
      "Filtering DataFrame for PI IDs: ['269677663', '269988546', '270021884']...\n",
      "\n",
      "PI: While Guido F Montufar Cuartas has significant expertise in AI and Machine Learning, which are essential for any 'Trustworthy AI' project, Benjamin Fuller's background more directly addresses the 'trustworthiness' aspect itself, making him the most suitable PI to lead a project specifically focused on 'Trustworthy AI' based on the provided data. His work inherently deals with building secure and trustworthy systems, which is at the core of the proposed research topic.\n",
      "\n",
      "Response generated in 12.20 seconds.\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Starting PI Recommendation Process for Topic: 'Networking safety' ---\n",
      "Filtering DataFrame for PI IDs: ['269677663', '269988546', '269814599']...\n",
      "\n",
      "PI: In conclusion, Benjamin Fullerâ€™s research history, particularly his focus on cryptographic authentication, secure data querying, and participation in programs like 'Secure &Trustworthy Cyberspace', makes him the most qualified and appropriate choice to serve as the Principal Investigator for a new project on 'Networking safety' among these three researchers.\n",
      "\n",
      "Response generated in 19.02 seconds.\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Starting PI Recommendation Process for Topic: 'Bioinformatics' ---\n",
      "Filtering DataFrame for PI IDs: ['269811881', '269958535', '270083608']...\n",
      "\n",
      "PI: In summary, while all three researchers have relevant backgrounds, Jianlin Cheng's prior experience as a **Principal Investigator** on a clearly defined 'Bioinformatics' project, combined with the direct relevance of his research to the topic, makes him the most qualified and suitable choice to lead this new collaborative project as the PI.\n",
      "\n",
      "Response generated in 10.80 seconds.\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Starting PI Recommendation Process for Topic: 'Robotics' ---\n",
      "Filtering DataFrame for PI IDs: ['270082637', '269726900', '269963435']...\n",
      "\n",
      "PI: **In conclusion, Rodrigo O Spinola's direct experience as a Principal Investigator on a project explicitly focused on 'Collaborative robots' within the 'National Robotics Initiative' makes him the most qualified and suitable choice to lead the new collaborative project on 'Robotics' based solely on the provided information.** While the other researchers bring valuable and related expertise, Rodrigo's background is the most directly aligned with the project's topic and leadership needs.\n",
      "\n",
      "Response generated in 11.07 seconds.\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Starting PI Recommendation Process for Topic: 'AI in Robotics' ---\n",
      "Filtering DataFrame for PI IDs: ['270082637', '269726900', '270021884']...\n",
      "\n",
      "PI: **In conclusion, Guido F Montufar Cuartas's proven expertise in Artificial Intelligence, coupled with his experience as a Principal Investigator and the recognition of a CAREER award, makes him the most qualified and suitable individual to lead the collaborative project on 'AI in Robotics'.  Rodrigo O Spinola's robotics expertise is also highly relevant and would be a valuable asset to the project team, potentially in a Co-PI or senior researcher role. Shrideep B Pallickara's expertise is less directly aligned with the project's core focus based on the provided data.**\n",
      "\n",
      "Response generated in 11.13 seconds.\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Starting PI Recommendation Process for Topic: 'Algorithm' ---\n",
      "Filtering DataFrame for PI IDs: ['269934201', '269769382', '269911544']...\n",
      "\n",
      "PI: In summary, Michael Dinitz stands out due to the explicit and direct relevance of his past research, his departmental alignment, and his experience as a Principal Investigator in a field directly focused on algorithms. While Xiaohong Wang is also a strong candidate with PI experience and related research, Michael Dinitz's background is the most precisely aligned with a project focused on the topic 'Algorithm' based solely on the provided information. Susan D Nickerson's expertise lies in a different domain (education) and is less relevant to the proposed project.\n",
      "\n",
      "Response generated in 12.43 seconds.\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Starting PI Recommendation Process for Topic: 'Data Science' ---\n",
      "Filtering DataFrame for PI IDs: ['269721983', '269928133', '000171581']...\n",
      "\n",
      "PI: **In summary, while Wencong Su demonstrates broader research leadership experience and Yanyan Li has PI experience in a fundamental field, Sofya Raskhodnikova's background is the most directly and centrally relevant to 'Data Science' as evidenced by her past award. This direct relevance makes her the most suitable candidate to lead a new collaborative project specifically focused on 'Data Science'.**\n",
      "\n",
      "Response generated in 14.09 seconds.\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "candidate_sets = [\n",
    "    (['269948909', '000173003', '269886945'], 'STATISTICS'),\n",
    "    (['269807623', '269794080', '269879497'], 'AI Circuits design'),\n",
    "    (['269807623', '269794080', '269879497'], 'hardware software co-design'),\n",
    "    (['269677663', '269988546', '270021884'], 'Trustworthy AI'),\n",
    "    (['269677663', '269988546', '269814599'], 'Networking safety'),\n",
    "    (['269811881', '269958535', '270083608'], 'Bioinformatics'),\n",
    "    (['270082637', '269726900', '269963435'], 'Robotics'),\n",
    "    (['270082637', '269726900', '270021884'], 'AI in Robotics'),\n",
    "    (['269934201', '269769382', '269911544'], 'Algorithm'),\n",
    "    (['269721983', '269928133', '000171581'], 'Data Science')\n",
    "]\n",
    "\n",
    "for pi_ids, topic in candidate_sets:\n",
    "    recommendation_result = recommend_pi(df, model, pi_ids, topic) #recommend_pi(df, model, pi_ids_to_analyze, research_topic)\n",
    "    # print(\"Predicted PI:\", pi_candidate)\n",
    "    # print(\"Predicted Co-PIs:\", co_pi_candidates)\n",
    "    # print(\"Candidate Combined Scores:\", scores)\n",
    "    print(\"-\" * 50)\n",
    "    # break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Influencer - from a list of PI's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import textwrap\n",
    "from typing import List, Dict, Tuple, Optional # For type hinting\n",
    "import google.generativeai as genai # Assuming genai is already configured\n",
    "\n",
    "# --- Helper Function to get Collaborators for specific awards ---\n",
    "# (This is needed for format_influencer_data)\n",
    "def get_collaborators_for_awards(df: pd.DataFrame, award_titles: List[str]) -> Dict[str, List[str]]:\n",
    "    \"\"\"\n",
    "    Finds all PIs/Co-PIs associated with a list of award titles.\n",
    "\n",
    "    Args:\n",
    "        df: The main DataFrame.\n",
    "        award_titles: A list of award titles.\n",
    "\n",
    "    Returns:\n",
    "        A dictionary where keys are award titles and values are lists of\n",
    "        PI/Co-PI full names on that award.\n",
    "    \"\"\"\n",
    "    collaborators = {}\n",
    "    relevant_awards_df = df[df['award_title'].isin(award_titles)]\n",
    "    for title in award_titles:\n",
    "        # Filter for the specific award title and valid roles\n",
    "        award_pis = relevant_awards_df[\n",
    "            (relevant_awards_df['award_title'] == title) &\n",
    "            (relevant_awards_df['role'].isin(['Principal Investigator', 'Co-Principal Investigator']))\n",
    "        ]\n",
    "        # Get unique names, handling potential missing names\n",
    "        names = [name for name in award_pis['pi_full_name'].unique() if pd.notna(name)]\n",
    "        collaborators[title] = names\n",
    "    return collaborators\n",
    "\n",
    "# --- New Function 1: Format Data for Influencer Prompt ---\n",
    "def format_influencer_data(df: pd.DataFrame, pi_ids: List[str]) -> Tuple[str, Dict[str, str]]:\n",
    "    \"\"\"\n",
    "    Formats data for selected PIs to highlight connections and field diversity\n",
    "    suitable for an 'influencer' analysis prompt.\n",
    "\n",
    "    Args:\n",
    "        df: The main DataFrame containing award and PI information.\n",
    "        pi_ids: A list of PI IDs to format data for.\n",
    "\n",
    "    Returns:\n",
    "        A tuple containing:\n",
    "            - formatted_data_string: A string with formatted details for each PI,\n",
    "              focusing on connections and fields.\n",
    "            - pi_names_dict: A dictionary mapping PI ID to PI full name.\n",
    "    \"\"\"\n",
    "    print(f\"Formatting influencer data for PI IDs: {pi_ids}...\")\n",
    "    formatted_data = \"\"\n",
    "    pi_names = {} # Dictionary to store PI names\n",
    "\n",
    "    # Filter main df once for all relevant PIs to improve efficiency\n",
    "    filtered_df = df[df['pi_id'].isin(pi_ids)].copy()\n",
    "\n",
    "    if filtered_df.empty:\n",
    "        print(\"Warning: No data found for any specified PI IDs.\")\n",
    "        formatted_data = \"No data could be retrieved for the specified potential influencers.\\n\"\n",
    "        for pi_id in pi_ids:\n",
    "             pi_names[pi_id] = f\"PI ID {pi_id}\" # Use ID as placeholder name\n",
    "        return formatted_data, pi_names\n",
    "\n",
    "    # Iterate through the requested PI IDs\n",
    "    for pi_id in pi_ids:\n",
    "        pi_specific_data = filtered_df[filtered_df['pi_id'] == pi_id]\n",
    "\n",
    "        if not pi_specific_data.empty:\n",
    "            # Get consistent name from the first entry\n",
    "            full_name = pi_specific_data['pi_full_name'].iloc[0]\n",
    "            pi_names[pi_id] = full_name\n",
    "            print(f\"  Processing data for {full_name} ({pi_id})...\")\n",
    "\n",
    "            formatted_data += f\"--- Potential Influencer: {full_name} (ID: {pi_id}) ---\\n\"\n",
    "\n",
    "            # --- Project & Connection Analysis ---\n",
    "            unique_award_titles = pi_specific_data['award_title'].unique()\n",
    "            num_projects = len(unique_award_titles)\n",
    "            formatted_data += f\"Total Projects Involved In (as PI/Co-PI): {num_projects}\\n\"\n",
    "\n",
    "            # Get all collaborators across these projects\n",
    "            collaborators_by_award = get_collaborators_for_awards(df, list(unique_award_titles))\n",
    "            all_collaborators = set()\n",
    "            for title, names in collaborators_by_award.items():\n",
    "                # Add collaborators, excluding the PI themselves\n",
    "                all_collaborators.update(name for name in names if name != full_name)\n",
    "\n",
    "            num_unique_collaborators = len(all_collaborators)\n",
    "            formatted_data += f\"Total Unique Collaborators (excluding self): {num_unique_collaborators}\\n\"\n",
    "            # Optionally list some collaborators:\n",
    "            collaborators_preview = \", \".join(list(all_collaborators)[:5]) # Preview first 5\n",
    "            formatted_data += f\"  Collaborators Sample: {collaborators_preview}{'...' if num_unique_collaborators > 5 else ''}\\n\"\n",
    "\n",
    "            # --- Field Diversity Analysis ---\n",
    "            unique_elements = pi_specific_data['program_element'].dropna().unique()\n",
    "            unique_references = pi_specific_data['program_reference'].dropna().unique()\n",
    "            all_fields = set(unique_elements) | set(unique_references)\n",
    "            num_unique_fields = len(all_fields)\n",
    "            formatted_data += f\"Number of Unique Research Fields (Program Elements/References): {num_unique_fields}\\n\"\n",
    "            # Optionally list some fields:\n",
    "            fields_preview = \", \".join(list(all_fields)[:5]) # Preview first 5\n",
    "            formatted_data += f\"  Fields Sample: {fields_preview}{'...' if num_unique_fields > 5 else ''}\\n\\n\"\n",
    "\n",
    "            # --- Detailed Project List (Optional - can make prompt very long) ---\n",
    "            # formatted_data += \"  Projects Overview:\\n\"\n",
    "            # for title in unique_award_titles:\n",
    "            #    roles_on_project = pi_specific_data[pi_specific_data['award_title'] == title]['role'].unique()\n",
    "            #    formatted_data += f\"  - {title} (Roles: {', '.join(roles_on_project)})\\n\"\n",
    "            #    formatted_data += f\"    Collaborators on this project: {', '.join(c for c in collaborators_by_award.get(title, []) if c != full_name)}\\n\"\n",
    "            # formatted_data += \"\\n\"\n",
    "\n",
    "        else:\n",
    "            # Handle case where a specific PI ID from the list had no data\n",
    "            formatted_data += f\"--- Potential Influencer ID: {pi_id} ---\\n\"\n",
    "            formatted_data += \"No award data found in the provided dataset for this PI.\\n\\n\"\n",
    "            pi_names[pi_id] = f\"PI ID {pi_id}\" # Use ID as placeholder name\n",
    "\n",
    "    print(\"Influencer data formatting complete.\")\n",
    "    return formatted_data, pi_names\n",
    "\n",
    "\n",
    "# --- New Function 2: Generate Influencer Prompt ---\n",
    "def generate_influencer_prompt(formatted_data_string: str, pi_names_dict: Dict[str, str]) -> str:\n",
    "    \"\"\"\n",
    "    Generates the full prompt string for the Gemini model to identify influencers.\n",
    "\n",
    "    Args:\n",
    "        formatted_data_string: The formatted string containing PI details focused\n",
    "                               on connections and fields.\n",
    "        pi_names_dict: A dictionary mapping PI ID to PI name.\n",
    "\n",
    "    Returns:\n",
    "        The complete prompt string for influencer identification.\n",
    "    \"\"\"\n",
    "    print(\"Generating influencer prompt...\")\n",
    "    candidate_names_list = \", \".join(pi_names_dict.values())\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "        Context:\n",
    "        You are an AI assistant analyzing research collaboration data to identify 'influencers'. An influencer is defined as a researcher who has significant connections within the network, demonstrated by:\n",
    "        1.  Being involved (as PI or Co-PI) in a relatively high number of distinct projects/awards.\n",
    "        2.  Having collaborated with a relatively high number of unique individuals.\n",
    "        3.  Having experience across a diverse range of research fields (indicated by different Program Elements or Program References).\n",
    "\n",
    "        Below is summarized data for potential influencers ({candidate_names_list}):\n",
    "\n",
    "        {formatted_data_string}\n",
    "\n",
    "        Task:\n",
    "        Based *only* on the summarized information provided above, please analyze each researcher's profile according to the 'influencer' criteria (number of projects, number of unique collaborators, and field diversity).\n",
    "\n",
    "        Rank these individuals ({candidate_names_list}) from most influential to least influential based on the definition provided.\n",
    "\n",
    "        Provide a clear ranking and a concise justification for your ranking, referencing the specific metrics (project count, collaborator count, field count) for each researcher from the context provided.\n",
    "    \"\"\"\n",
    "    print(\"Influencer prompt generated.\")\n",
    "    return prompt\n",
    "\n",
    "# --- New Function 3: Identify Influencer using LLM ---\n",
    "def identify_influencer_llm(df: pd.DataFrame, model: genai.GenerativeModel, pi_ids: List[str]) -> Optional[str]:\n",
    "    \"\"\"\n",
    "    Orchestrates the process of formatting data, generating an influencer prompt,\n",
    "    and getting a ranking from the Gemini model.\n",
    "\n",
    "    Args:\n",
    "        df: The main DataFrame.\n",
    "        model: The configured Gemini model object.\n",
    "        pi_ids: A list of PI IDs to consider as potential influencers.\n",
    "\n",
    "    Returns:\n",
    "        The influencer ranking text from the model, or None if an error occurred.\n",
    "    \"\"\"\n",
    "    print(f\"\\n--- Starting Influencer Identification Process for PI IDs: {pi_ids} ---\")\n",
    "\n",
    "    # 1. Format Data for Influencer Analysis\n",
    "    # Note: This function now focuses on connections and diversity metrics\n",
    "    formatted_text, pi_names = format_influencer_data(df, pi_ids)\n",
    "\n",
    "    # Check if formatting yielded any usable data\n",
    "    if not pi_names or all(name.startswith(\"PI ID\") for name in pi_names.values()):\n",
    "         print(\"Stopping process as no valid data could be formatted.\")\n",
    "         return \"Could not generate influencer ranking due to lack of data for the specified PIs.\"\n",
    "\n",
    "    # 2. Generate Influencer Prompt\n",
    "    prompt_text = generate_influencer_prompt(formatted_text, pi_names)\n",
    "\n",
    "    # 3. Get Response (using the existing get_gemini_response function)\n",
    "    print(\"--- Sending Request to Gemini for Influencer Ranking ---\")\n",
    "    # Assuming get_gemini_response takes model and prompt, and returns (response_text, duration)\n",
    "    # You might need to adapt this call slightly if your get_gemini_response has different args/return values\n",
    "    ranking_result, duration = get_gemini_response(model, prompt_text) # Use your existing function\n",
    "\n",
    "    if ranking_result:\n",
    "        print(f\"--- Influencer Identification Complete ({duration:.2f}s) ---\")\n",
    "        # The result is already printed by get_gemini_response during streaming usually\n",
    "        return ranking_result\n",
    "    else:\n",
    "        print(\"--- Influencer Identification Failed ---\")\n",
    "        return \"Failed to get influencer ranking from the model.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Starting Influencer Identification Process for PI IDs: ['000025762', '269811881', '269807623', '270021884'] ---\n",
      "Formatting influencer data for PI IDs: ['000025762', '269811881', '269807623', '270021884']...\n",
      "  Processing data for Steven N MacEachern (000025762)...\n",
      "  Processing data for Jianlin   Cheng (269811881)...\n",
      "  Processing data for Dirk J Colbry (269807623)...\n",
      "  Processing data for Guido F Montufar Cuartas (270021884)...\n",
      "Influencer data formatting complete.\n",
      "Generating influencer prompt...\n",
      "Influencer prompt generated.\n",
      "--- Sending Request to Gemini for Influencer Ranking ---\n",
      "\n",
      "PI: This ranking is based solely on the provided summary data and the defined criteria for an 'influencer'. A more comprehensive analysis might require deeper investigation into the nature and impact of their projects and collaborations.\n",
      "\n",
      "Response generated in 14.00 seconds.\n",
      "--- Influencer Identification Complete (14.00s) ---\n",
      "\n",
      "--- Final Influencer Ranking Text ---\n",
      "## Ranking of Potential Influencers:\n",
      "\n",
      "Based on the provided data and the definition of an 'influencer', here is the ranking from most to least influential:\n",
      "\n",
      "**1. Dirk J Colbry (ID: 269807623)**\n",
      "\n",
      "**Justification:** Dirk J Colbry demonstrates the strongest profile according to the influencer criteria.\n",
      "*   **Highest Project Count:** Involved in 3 projects, more than any other researcher in the list.\n",
      "*   **Highest Collaborator Count:**  Significantly higher number of unique collaborators (11) compared to all others.\n",
      "*   **Highest Field Diversity:**  Experience across the most diverse range of research fields (5).\n",
      "\n",
      "**2. Guido F Montufar Cuartas (ID: 270021884)**\n",
      "\n",
      "**Justification:** Guido F Montufar Cuartas shows a strong profile, particularly in field diversity.\n",
      "*   **Moderate Project Count:** Involved in 2 projects, similar to Steven N MacEachern and Jianlin Cheng.\n",
      "*   **Moderate Collaborator Count:** Has 2 unique collaborators, more than Jianlin Cheng but less than Steven N MacEachern.\n",
      "*   **High Field Diversity:**  Experienced in 4 unique research fields, equal to Jianlin Cheng and second only to Dirk J Colbry. His field diversity is notably higher than Steven N MacEachern.\n",
      "\n",
      "**3. Steven N MacEachern (ID: 000025762)**\n",
      "\n",
      "**Justification:** Steven N MacEachern shows a moderate profile, with a notable number of collaborators but limited field diversity.\n",
      "*   **Moderate Project Count:** Involved in 2 projects.\n",
      "*   **Moderate Collaborator Count:** Has 4 unique collaborators, more than Guido F Montufar Cuartas and Jianlin Cheng, but significantly less than Dirk J Colbry.\n",
      "*   **Lowest Field Diversity:**  Limited experience in only 1 unique research field. His lack of field diversity is a significant factor placing him lower in the ranking compared to Guido F Montufar Cuartas who has a similar project count but much higher field diversity.\n",
      "\n",
      "**4. Jianlin Cheng (ID: 269811881)**\n",
      "\n",
      "**Justification:** Jianlin Cheng presents the weakest profile among the listed researchers based on the influencer criteria.\n",
      "*   **Moderate Project Count:** Involved in 2 projects.\n",
      "*   **Lowest Collaborator Count:**  Has only 1 unique collaborator, indicating a limited network in terms of unique individuals.\n",
      "*   **High Field Diversity:**  Experienced in 4 unique research fields, equal to Guido F Montufar Cuartas, but this strength is overshadowed by the low collaborator count.\n",
      "\n",
      "**Summary Ranking:**\n",
      "\n",
      "1.  **Dirk J Colbry**\n",
      "2.  **Guido F Montufar Cuartas**\n",
      "3.  **Steven N MacEachern**\n",
      "4.  **Jianlin Cheng**\n",
      "\n",
      "This ranking is based solely on the provided summary data and the defined criteria for an 'influencer'. A more comprehensive analysis might require deeper investigation into the nature and impact of their projects and collaborations.\n"
     ]
    }
   ],
   "source": [
    "# --- Example Usage ---\n",
    "# Assuming 'df' is your loaded DataFrame and 'model' is your configured Gemini model\n",
    "try:\n",
    "    # Example PI IDs known to have multiple projects/connections\n",
    "    # Replace with IDs relevant to your analysis\n",
    "    influencer_candidate_ids = ['000025762', '269811881', '269807623', '270021884'] # Example set\n",
    "\n",
    "    # --- Run the Influencer Identification Process ---\n",
    "    influencer_ranking_result = identify_influencer_llm(df, model, influencer_candidate_ids)\n",
    "\n",
    "    # Optional: Print the final result again if not fully captured by streaming print\n",
    "    if influencer_ranking_result:\n",
    "        print(\"\\n--- Final Influencer Ranking Text ---\")\n",
    "        print(influencer_ranking_result)\n",
    "    else:\n",
    "        print(\"\\nInfluencer ranking could not be generated.\")\n",
    "\n",
    "except NameError as e:\n",
    "    print(f\"Error: Required variable not defined (e.g., 'df' or 'model'). Details: {e}\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred during the influencer identification process: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Embading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from datetime import datetime\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Combine relevant text columns into one (you may adjust columns as needed)\n",
    "text_columns = [\n",
    "    \"award_type\", \"award_title\", \"abstract\", \n",
    "    \"org_name\", \"org_name2\", \"perf_inst_name\", \n",
    "    \"program_element\", \"program_reference\"\n",
    "]\n",
    "df[\"combined_text\"] = df[text_columns].astype(str).agg(\" \".join, axis=1)\n",
    "\n",
    "# a. Leadership indicator: 1 if role suggests prior leadership (e.g., contains \"Principal Investigator\")\n",
    "df[\"leadership\"] = df[\"role\"].apply(lambda x: 1 if \"Principal Investigator\" in str(x) else 0)\n",
    "\n",
    "# b. Experience in years: use start_date and a reference date (here we use today)\n",
    "df[\"start_date\"] = pd.to_datetime(df[\"start_date\"], errors='coerce')\n",
    "reference_date = datetime.now()  # or use a fixed project date\n",
    "df[\"experience_years\"] = (reference_date - df[\"start_date\"]).dt.days / 365.25\n",
    "\n",
    "# Load a pre-trained sentence transformer\n",
    "embedder = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "# Compute embedding for each award's combined text\n",
    "df[\"text_embedding\"] = df[\"combined_text\"].apply(lambda x: embedder.encode(x))\n",
    "\n",
    "# We assume each row has a researcher ID (\"pi_id\"). If a researcher has multiple rows, we aggregate.\n",
    "# For aggregated text, we average the embeddings; for numeric features, we use appropriate aggregation.\n",
    "award_counts = df.groupby(\"pi_id\").size().reset_index(name=\"award_count\")\n",
    "df_grouped = df.groupby(\"pi_id\").agg({\n",
    "    \"experience_years\": \"mean\",       # average experience across awards\n",
    "    \"leadership\": \"max\",              # if they have ever been a PI, mark as leadership\n",
    "    \"text_embedding\": lambda embs: np.mean(np.stack(embs), axis=0)\n",
    "}).reset_index()\n",
    "df_grouped = df_grouped.merge(award_counts, on=\"pi_id\", how=\"left\")\n",
    "\n",
    "# For later scoring, normalize the numeric features (experience and award_count)\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "df_grouped[[\"exp_norm\", \"award_norm\"]] = scaler.fit_transform(df_grouped[[\"experience_years\", \"award_count\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Influencer by TOPIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "# Assuming SentenceTransformer 'embedder' and DataFrames 'df', 'df_grouped'\n",
    "# are already loaded and computed as in your notebook (cells 17 & 18)\n",
    "\n",
    "# --- New Function 1: Select Candidate PIs by Criterion ---\n",
    "def select_candidate_pis(\n",
    "    df: pd.DataFrame,\n",
    "    df_grouped: pd.DataFrame,\n",
    "    embedder, # Your SentenceTransformer model\n",
    "    criterion_type: str, # \"topic\" or \"department\"\n",
    "    criterion_value: str, # The actual topic or department name\n",
    "    top_k: int = 10 # Number of top candidates to select\n",
    ") -> List[str]:\n",
    "    \"\"\"\n",
    "    Selects a list of candidate PI IDs based on a research topic or department.\n",
    "\n",
    "    Args:\n",
    "        df: The main DataFrame.\n",
    "        df_grouped: DataFrame grouped by pi_id, containing aggregated info\n",
    "                    and 'text_embedding'.\n",
    "        embedder: The initialized SentenceTransformer model.\n",
    "        criterion_type: Either 'topic' or 'department'.\n",
    "        criterion_value: The specific topic string or department name.\n",
    "        top_k: The maximum number of candidate IDs to return.\n",
    "\n",
    "    Returns:\n",
    "        A list of candidate PI IDs.\n",
    "    \"\"\"\n",
    "    print(f\"Selecting top {top_k} candidates based on {criterion_type}: '{criterion_value}'...\")\n",
    "    candidate_ids = []\n",
    "\n",
    "    if criterion_type == \"topic\":\n",
    "        if 'text_embedding' not in df_grouped.columns or embedder is None:\n",
    "            print(\"Error: df_grouped with 'text_embedding' and embedder are required for topic search.\")\n",
    "            return []\n",
    "\n",
    "        # Compute embedding for the research topic\n",
    "        topic_emb = embedder.encode(criterion_value)\n",
    "\n",
    "        # Calculate similarity between topic and all PIs in df_grouped\n",
    "        all_embeddings = np.stack(df_grouped['text_embedding'].values)\n",
    "        similarities = cosine_similarity([topic_emb], all_embeddings)[0]\n",
    "\n",
    "        # Get indices of top k PIs sorted by similarity\n",
    "        top_indices = np.argsort(similarities)[::-1][:top_k]\n",
    "\n",
    "        # Get the corresponding PI IDs\n",
    "        candidate_ids = df_grouped.iloc[top_indices]['pi_id'].tolist()\n",
    "\n",
    "    elif criterion_type == \"department\":\n",
    "        # Filter the main df by department (case-insensitive partial match)\n",
    "        # You might want to refine this matching logic (e.g., exact match)\n",
    "        dept_match_df = df[df['department'].str.contains(criterion_value, case=False, na=False)]\n",
    "\n",
    "        if dept_match_df.empty:\n",
    "            print(f\"No PIs found matching department: '{criterion_value}'\")\n",
    "            return []\n",
    "\n",
    "        # Get unique PI IDs from the matching departments\n",
    "        unique_dept_pi_ids = dept_match_df['pi_id'].unique()\n",
    "\n",
    "        # If more than top_k PIs, we can optionally rank them (e.g., by award count)\n",
    "        # Here, we'll take the top_k based on award count from df_grouped\n",
    "        if len(unique_dept_pi_ids) > top_k:\n",
    "            candidate_subset = df_grouped[df_grouped['pi_id'].isin(unique_dept_pi_ids)]\n",
    "            # Sort by 'award_count' (requires 'award_count' column in df_grouped)\n",
    "            if 'award_count' in candidate_subset.columns:\n",
    "                 ranked_candidates = candidate_subset.sort_values(by='award_count', ascending=False)\n",
    "                 candidate_ids = ranked_candidates.head(top_k)['pi_id'].tolist()\n",
    "            else: # Fallback if award_count isn't available\n",
    "                 candidate_ids = list(unique_dept_pi_ids)[:top_k]\n",
    "            print(f\"  (Found {len(unique_dept_pi_ids)} PIs, selecting top {top_k} based on award count)\")\n",
    "        else:\n",
    "            candidate_ids = list(unique_dept_pi_ids)\n",
    "\n",
    "    else:\n",
    "        print(f\"Error: Invalid criterion_type '{criterion_type}'. Use 'topic' or 'department'.\")\n",
    "        return []\n",
    "\n",
    "    print(f\"Selected candidate PI IDs: {candidate_ids}\")\n",
    "    return candidate_ids\n",
    "\n",
    "# --- New Function 2: Orchestrator for Criterion-Based Search ---\n",
    "def find_influencers_by_criterion(\n",
    "    df: pd.DataFrame,\n",
    "    df_grouped: pd.DataFrame,\n",
    "    embedder, # Your SentenceTransformer model\n",
    "    model: genai.GenerativeModel, # Your Gemini model\n",
    "    criterion_type: str,\n",
    "    criterion_value: str,\n",
    "    top_k_candidates: int = 10 # How many initial candidates to select\n",
    ") -> Optional[str]:\n",
    "    \"\"\"\n",
    "    Finds and ranks influencers based on a topic or department criterion.\n",
    "\n",
    "    Args:\n",
    "        df: Main DataFrame.\n",
    "        df_grouped: Grouped DataFrame with embeddings and counts.\n",
    "        embedder: SentenceTransformer model.\n",
    "        model: Gemini model object.\n",
    "        criterion_type: 'topic' or 'department'.\n",
    "        criterion_value: The topic string or department name.\n",
    "        top_k_candidates: Max number of candidates to select initially.\n",
    "\n",
    "    Returns:\n",
    "        The influencer ranking text from the model, or None/error message.\n",
    "    \"\"\"\n",
    "    print(f\"\\n--- Starting Influencer Search by {criterion_type.capitalize()}: '{criterion_value}' ---\")\n",
    "\n",
    "    # 1. Select Candidate PIs based on the criterion\n",
    "    candidate_pi_ids = select_candidate_pis(\n",
    "        df, df_grouped, embedder, criterion_type, criterion_value, top_k=top_k_candidates\n",
    "    )\n",
    "\n",
    "    if not candidate_pi_ids:\n",
    "        print(\"No candidates found for the specified criterion.\")\n",
    "        return f\"Could not find potential influencers matching {criterion_type}: '{criterion_value}'.\"\n",
    "\n",
    "    # 2. Proceed with the LLM analysis using the selected candidates\n",
    "    # Reuse the 'identify_influencer_llm' logic (formatting, prompt, API call)\n",
    "    # We pass the dynamically selected candidate_pi_ids\n",
    "    print(f\"\\n--- Analyzing Selected Candidates for Influence ---\")\n",
    "    # (Assuming identify_influencer_llm structure remains similar)\n",
    "    # This reuses the formatting, prompt generation and LLM call logic from before\n",
    "    influencer_ranking_result = identify_influencer_llm(df, model, candidate_pi_ids)\n",
    "\n",
    "\n",
    "    return influencer_ranking_result\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Starting Influencer Search by Topic: 'AI Circuits design' ---\n",
      "Selecting top 5 candidates based on topic: 'AI Circuits design'...\n",
      "Selected candidate PI IDs: ['269757420', '000166285', '269951871', '269674418', '269738150']\n",
      "\n",
      "--- Analyzing Selected Candidates for Influence ---\n",
      "\n",
      "--- Starting Influencer Identification Process for PI IDs: ['269757420', '000166285', '269951871', '269674418', '269738150'] ---\n",
      "Formatting influencer data for PI IDs: ['269757420', '000166285', '269951871', '269674418', '269738150']...\n",
      "  Processing data for Peng   Li (269757420)...\n",
      "  Processing data for Andreas G Andreou (000166285)...\n",
      "  Processing data for Dorit S Hochbaum (269951871)...\n",
      "  Processing data for Alper   Atamturk (269674418)...\n",
      "  Processing data for Charles B Pierre (269738150)...\n",
      "Influencer data formatting complete.\n",
      "Generating influencer prompt...\n",
      "Influencer prompt generated.\n",
      "--- Sending Request to Gemini for Influencer Ranking ---\n",
      "\n",
      "PI: **In summary:** Andreas G Andreou and Peng Li stand out as more influential due to their higher project involvement and/or broader field diversity. Dorit S Hochbaum, Alper Atamturk, and Charles B Pierre exhibit similar, and comparatively lower, levels of influence based on the metrics provided, with their rankings within this group differentiated primarily by alphabetical order due to identical metric values.\n",
      "\n",
      "Response generated in 10.73 seconds.\n",
      "--- Influencer Identification Complete (10.73s) ---\n",
      "\n",
      "--- Final Influencer Ranking for Topic 'AI Circuits design' ---\n",
      "## Researcher Influence Ranking and Justification:\n",
      "\n",
      "Based on the provided data and the definition of an 'influencer', here is the ranking of the researchers from most to least influential:\n",
      "\n",
      "**Ranking (Most to Least Influential):**\n",
      "\n",
      "1.  **Andreas G Andreou**\n",
      "2.  **Peng Li**\n",
      "3.  **Dorit S Hochbaum**\n",
      "4.  **Alper Atamturk**\n",
      "5.  **Charles B Pierre**\n",
      "\n",
      "**Justification:**\n",
      "\n",
      "*   **1. Andreas G Andreou:** Andreas G Andreou demonstrates the strongest influence based on the criteria. He has the **highest number of unique collaborators (8)**, significantly more than any other researcher.  While his **project count (3)** is second to Peng Li, it's still substantial. He also has experience across a diverse range of **research fields (6)**, only slightly less than Peng Li. His strong collaboration network and involvement in multiple projects across various fields position him as the most influential in this group.\n",
      "\n",
      "*   **2. Peng Li:** Peng Li is ranked second due to his strong performance in project involvement and field diversity. He is involved in the **highest number of projects (4)** and has experience in the **most diverse research fields (7)**. However, his **number of unique collaborators is significantly low (only 1)** compared to others. This lower collaboration count, despite his strengths in projects and fields, places him slightly below Andreas G Andreou in overall influence.\n",
      "\n",
      "*   **3. Dorit S Hochbaum:** Dorit S Hochbaum, Alper Atamturk, and Charles B Pierre show very similar metrics, indicating a comparable level of influence among themselves, but less than Andreas G Andreou and Peng Li. Dorit S Hochbaum is placed slightly higher in this group due to alphabetical order as their metrics are identical.  She has a moderate **number of unique collaborators (4)**, but a lower **project count (1)** and limited **field diversity (2)** compared to the top two researchers.\n",
      "\n",
      "*   **4. Alper Atamturk:** Alper Atamturk has the same metrics as Dorit S Hochbaum and Charles B Pierre across all categories: **1 project**, **4 unique collaborators**, and **2 research fields**.  He is ranked here due to alphabetical ordering amongst this group with identical metrics. His influence is limited by his lower project count and field diversity in comparison to the top two researchers, and similar to the other researchers in this bottom group.\n",
      "\n",
      "*   **5. Charles B Pierre:** Charles B Pierre, similar to Dorit S Hochbaum and Alper Atamturk, has **1 project**, **4 unique collaborators**, and **2 research fields**. He is ranked last in this group due to alphabetical ordering as his metrics are identical to Dorit S Hochbaum and Alper Atamturk. His profile suggests the least influence among the five researchers based on the provided data, primarily due to his lower project involvement and field diversity compared to Andreas G Andreou and Peng Li.\n",
      "\n",
      "\n",
      "**In summary:** Andreas G Andreou and Peng Li stand out as more influential due to their higher project involvement and/or broader field diversity. Dorit S Hochbaum, Alper Atamturk, and Charles B Pierre exhibit similar, and comparatively lower, levels of influence based on the metrics provided, with their rankings within this group differentiated primarily by alphabetical order due to identical metric values.\n"
     ]
    }
   ],
   "source": [
    "# --- Example Usage ---\n",
    "try:\n",
    "    # --- Find Influencers by TOPIC ---\n",
    "    topic_to_search = \"AI Circuits design\"\n",
    "    topic_ranking = find_influencers_by_criterion(\n",
    "        df, df_grouped, embedder, model,\n",
    "        criterion_type=\"topic\",\n",
    "        criterion_value=topic_to_search,\n",
    "        top_k_candidates=5 # Select top 5 PIs based on topic similarity first\n",
    "    )\n",
    "    if topic_ranking:\n",
    "        print(f\"\\n--- Final Influencer Ranking for Topic '{topic_to_search}' ---\")\n",
    "        print(topic_ranking)\n",
    "\n",
    "except NameError as e:\n",
    "     print(f\"Error: Required variable not defined (e.g., 'df', 'df_grouped', 'embedder', 'model'). Details: {e}\")\n",
    "except Exception as e:\n",
    "     print(f\"An error occurred during the influencer search process: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Influencers by DEPARTMENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Starting Influencer Search by Department: 'Computer Science' ---\n",
      "Selecting top 10 candidates based on department: 'Computer Science'...\n",
      "  (Found 2938 PIs, selecting top 10 based on award count)\n",
      "Selected candidate PI IDs: ['269935164', '269779708', '269765937', '000235919', '270031750', '000207040', '270018850', '269779084', '269985475', '269680242']\n",
      "\n",
      "--- Analyzing Selected Candidates for Influence ---\n",
      "\n",
      "--- Starting Influencer Identification Process for PI IDs: ['269935164', '269779708', '269765937', '000235919', '270031750', '000207040', '270018850', '269779084', '269985475', '269680242'] ---\n",
      "Formatting influencer data for PI IDs: ['269935164', '269779708', '269765937', '000235919', '270031750', '000207040', '270018850', '269779084', '269985475', '269680242']...\n",
      "  Processing data for Yanfang   Ye (269935164)...\n",
      "  Processing data for Prasad   Calyam (269779708)...\n",
      "  Processing data for Tiffany M Barnes (269765937)...\n",
      "  Processing data for Sharad   Mehrotra (000235919)...\n",
      "  Processing data for Ferdinando   Fioretto (270031750)...\n",
      "  Processing data for Dhabaleswar K Panda (000207040)...\n",
      "  Processing data for Ravi Netravali (270018850)...\n",
      "  Processing data for Aditya   Akella (269779084)...\n",
      "  Processing data for Jiliang   Tang (269985475)...\n",
      "  Processing data for Mahmut T Kandemir (269680242)...\n",
      "Influencer data formatting complete.\n",
      "Generating influencer prompt...\n",
      "Influencer prompt generated.\n",
      "--- Sending Request to Gemini for Influencer Ranking ---\n",
      "\n",
      "PI: This ranking is based solely on the quantitative data provided for projects, collaborators, and research fields. Other factors not included in this summary could influence a more comprehensive assessment of research influence.\n",
      "\n",
      "Response generated in 13.73 seconds.\n",
      "--- Influencer Identification Complete (13.73s) ---\n",
      "\n",
      "--- Final Influencer Ranking for Department 'Computer Science' ---\n",
      "Based on the provided data and the 'influencer' criteria, here is the ranking of the researchers from most to least influential:\n",
      "\n",
      "**Ranking of Researchers (Most to Least Influential):**\n",
      "\n",
      "1.  **Prasad Calyam (ID: 269779708)**\n",
      "    *Justification:* Prasad Calyam ranks highest due to his strong performance across all criteria. He has the highest number of projects (14) and the highest number of unique research fields (22), and the second-highest number of unique collaborators (25). His consistent high scores across all metrics make him the most influential based on this data.\n",
      "\n",
      "2.  **Tiffany M Barnes (ID: 269765937)**\n",
      "    *Justification:* Tiffany Barnes is ranked second due to having the highest number of unique collaborators (30) and a relatively high number of unique research fields (13) and projects (11). While not leading in projects or fields, her exceptional collaborator count positions her as highly influential.\n",
      "\n",
      "3.  **Dhabaleswar K Panda (ID: 000207040)**\n",
      "    *Justification:* Dhabaleswar K Panda is third, demonstrating strong metrics in all areas. He has a high number of unique collaborators (20) and unique research fields (15), and a decent number of projects (9). His balanced profile across all three criteria places him in the top tier.\n",
      "\n",
      "4.  **Jiliang Tang (ID: 269985475)**\n",
      "    *Justification:* Jiliang Tang is fourth, with a high number of unique collaborators (21) and a good number of projects (9) and unique research fields (12). His collaborator count and field diversity contribute to his ranking as a significant influencer.\n",
      "\n",
      "5.  **Yanfang Ye (ID: 269935164)**\n",
      "    *Justification:* Yanfang Ye ranks fifth, with a strong number of projects (13) and a good number of unique research fields (12). However, her collaborator count (11) is relatively lower compared to the top three, placing her slightly lower in the overall ranking.\n",
      "\n",
      "6.  **Sharad Mehrotra (ID: 000235919)**\n",
      "    *Justification:* Sharad Mehrotra is sixth, with a decent number of unique collaborators (18) and projects (10) and unique research fields (11). While his metrics are solid, they are slightly lower than those ranked above him, leading to a mid-range influencer position.\n",
      "\n",
      "7.  **Mahmut T Kandemir (ID: 269680242)**\n",
      "    *Justification:* Mahmut T Kandemir is seventh, with a good number of unique collaborators (17) and projects (9) and unique research fields (11). Similar to Sharad Mehrotra, his metrics are respectable but not as high as the top influencers in this list.\n",
      "\n",
      "8.  **Aditya Akella (ID: 269779084) & Ferdinando Fioretto (ID: 270031750) - Tie**\n",
      "    *Justification:* Aditya Akella and Ferdinando Fioretto are tied for eighth place. Aditya Akella has a slightly higher number of collaborators (13) and projects (8) compared to Ferdinando Fioretto (6 collaborators, 7 projects), but both have the same number of unique research fields (8 and 11 respectively).  Ferdinando Fioretto's lower metrics in projects and collaborators place him lower despite a slightly higher field count. Aditya Akella's slightly better project and collaborator counts, while still not very high, result in a tie for this position.\n",
      "\n",
      "10. **Ravi Netravali (ID: 270018850)**\n",
      "    *Justification:* Ravi Netravali is ranked last as he has the lowest metrics across all three criteria: fewest projects (5), fewest unique collaborators (2), and fewer unique research fields (8). His profile suggests a more focused or less broadly connected research portfolio compared to the others in this list.\n",
      "\n",
      "This ranking is based solely on the quantitative data provided for projects, collaborators, and research fields. Other factors not included in this summary could influence a more comprehensive assessment of research influence.\n"
     ]
    }
   ],
   "source": [
    "# --- Example Usage ---\n",
    "try:\n",
    "    # --- Find Influencers by DEPARTMENT ---\n",
    "    dept_to_search = \"Computer Science\"\n",
    "    dept_ranking = find_influencers_by_criterion(\n",
    "        df, df_grouped, embedder, model,\n",
    "        criterion_type=\"department\",\n",
    "        criterion_value=dept_to_search,\n",
    "        top_k_candidates=10 # Select top 10 PIs from this department (ranked by awards)\n",
    "    )\n",
    "    if dept_ranking:\n",
    "        print(f\"\\n--- Final Influencer Ranking for Department '{dept_to_search}' ---\")\n",
    "        print(dept_ranking)\n",
    "\n",
    "except NameError as e:\n",
    "     print(f\"Error: Required variable not defined (e.g., 'df', 'df_grouped', 'embedder', 'model'). Details: {e}\")\n",
    "except Exception as e:\n",
    "     print(f\"An error occurred during the influencer search process: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[df['pi_id'].isin(pi_ids_to_analyze)][['pi_full_name', 'pi_id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Prerequisite Imports and Setup ---\n",
    "# Make sure you have these imports and objects loaded from your notebook\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import google.generativeai as genai # Assuming 'model' is configured\n",
    "# from sentence_transformers import SentenceTransformer # Assuming 'embedder' is loaded\n",
    "import networkx as nx # For Method 7\n",
    "from typing import List, Dict, Tuple, Optional\n",
    "import collections # For Method 4 helper\n",
    "\n",
    "# Assuming 'df', 'df_grouped', 'embedder', 'model' are loaded and preprocessed\n",
    "# Assuming 'get_collaborators_for_awards', 'format_influencer_data',\n",
    "# 'generate_influencer_prompt', 'identify_influencer_llm',\n",
    "# 'select_candidate_pis', 'find_influencers_by_criterion',\n",
    "# 'get_gemini_response' functions exist as defined previously.\n",
    "\n",
    "# --- Method 4: Inter-Institutional Collaboration ---\n",
    "\n",
    "# Helper function to get collaborator institutions\n",
    "def get_collaborator_institutions(df: pd.DataFrame, pi_id: str, collaborators_names: List[str]) -> collections.Counter:\n",
    "    \"\"\"\n",
    "    Finds the institutions of a given list of collaborators.\n",
    "\n",
    "    Args:\n",
    "        df: The main DataFrame.\n",
    "        pi_id: The ID of the main PI (to exclude their own institution if needed).\n",
    "        collaborators_names: A list of full names of the collaborators.\n",
    "\n",
    "    Returns:\n",
    "        A Counter object mapping institution names to their frequency.\n",
    "    \"\"\"\n",
    "    if not collaborators_names:\n",
    "        return collections.Counter()\n",
    "\n",
    "    # Find entries for the collaborators\n",
    "    collaborator_df = df[df['pi_full_name'].isin(collaborators_names)]\n",
    "\n",
    "    # Get institutions, excluding NaNs and potentially the main PI's primary institution\n",
    "    # For simplicity here, we count all unique institutions associated with collaborators\n",
    "    institutions = collaborator_df['perf_inst_name'].dropna().unique()\n",
    "\n",
    "    # We can return a Counter of unique institutions found for collaborators\n",
    "    # For influence, we mostly care about the *number* of unique institutions\n",
    "    return collections.Counter(institutions)\n",
    "\n",
    "\n",
    "# Modify format_influencer_data to include institutional diversity\n",
    "def format_influencer_data_v2(df: pd.DataFrame, pi_ids: List[str]) -> Tuple[str, Dict[str, str]]:\n",
    "    \"\"\"\n",
    "    V2: Formats data including project/collaborator counts, field diversity,\n",
    "        AND inter-institutional collaboration breadth.\n",
    "    \"\"\"\n",
    "    print(f\"Formatting influencer data (v2) for PI IDs: {pi_ids}...\")\n",
    "    formatted_data = \"\"\n",
    "    pi_names = {}\n",
    "    filtered_df = df[df['pi_id'].isin(pi_ids)].copy()\n",
    "\n",
    "    if filtered_df.empty:\n",
    "         # (Same empty handling as before)\n",
    "         print(\"Warning: No data found for any specified PI IDs.\")\n",
    "         formatted_data = \"No data could be retrieved for the specified potential influencers.\\n\"\n",
    "         for pi_id in pi_ids:\n",
    "             pi_names[pi_id] = f\"PI ID {pi_id}\"\n",
    "         return formatted_data, pi_names\n",
    "\n",
    "    for pi_id in pi_ids:\n",
    "        pi_specific_data = filtered_df[filtered_df['pi_id'] == pi_id]\n",
    "\n",
    "        if not pi_specific_data.empty:\n",
    "            full_name = pi_specific_data['pi_full_name'].iloc[0]\n",
    "            pi_names[pi_id] = full_name\n",
    "            print(f\"  Processing data for {full_name} ({pi_id})...\")\n",
    "            formatted_data += f\"--- Potential Influencer: {full_name} (ID: {pi_id}) ---\\n\"\n",
    "\n",
    "            # --- Project & Connection Analysis ---\n",
    "            unique_award_titles = pi_specific_data['award_title'].unique()\n",
    "            num_projects = len(unique_award_titles)\n",
    "            formatted_data += f\"Total Projects Involved In: {num_projects}\\n\"\n",
    "            collaborators_by_award = get_collaborators_for_awards(df, list(unique_award_titles))\n",
    "            all_collaborators = set(name for names in collaborators_by_award.values() for name in names if name != full_name)\n",
    "            num_unique_collaborators = len(all_collaborators)\n",
    "            formatted_data += f\"Total Unique Collaborators: {num_unique_collaborators}\\n\"\n",
    "\n",
    "            # --- Field Diversity Analysis ---\n",
    "            unique_elements = pi_specific_data['program_element'].dropna().unique()\n",
    "            unique_references = pi_specific_data['program_reference'].dropna().unique()\n",
    "            all_fields = set(unique_elements) | set(unique_references)\n",
    "            num_unique_fields = len(all_fields)\n",
    "            formatted_data += f\"Number of Unique Research Fields: {num_unique_fields}\\n\"\n",
    "\n",
    "            # --- NEW: Inter-Institutional Collaboration ---\n",
    "            collaborator_institutions = get_collaborator_institutions(df, pi_id, list(all_collaborators))\n",
    "            num_unique_collab_institutions = len(collaborator_institutions)\n",
    "            formatted_data += f\"Number of Unique Collaborating Institutions: {num_unique_collab_institutions}\\n\"\n",
    "            # Optionally list some institutions\n",
    "            inst_preview = \", \".join(list(collaborator_institutions.keys())[:3])\n",
    "            formatted_data += f\"  Collaborating Institutions Sample: {inst_preview}{'...' if num_unique_collab_institutions > 3 else ''}\\n\\n\"\n",
    "\n",
    "        else:\n",
    "             # (Same handling for missing PI as before)\n",
    "             formatted_data += f\"--- Potential Influencer ID: {pi_id} ---\\n\"\n",
    "             formatted_data += \"No award data found...\\n\\n\"\n",
    "             pi_names[pi_id] = f\"PI ID {pi_id}\"\n",
    "\n",
    "    print(\"Influencer data formatting (v2) complete.\")\n",
    "    return formatted_data, pi_names\n",
    "\n",
    "# Modify generate_influencer_prompt to include the new criterion\n",
    "def generate_influencer_prompt_v2(formatted_data_string: str, pi_names_dict: Dict[str, str]) -> str:\n",
    "    \"\"\"\n",
    "    V2: Generates prompt asking LLM to consider projects, collaborators,\n",
    "        field diversity, AND institutional diversity.\n",
    "    \"\"\"\n",
    "    print(\"Generating influencer prompt (v2)...\")\n",
    "    candidate_names_list = \", \".join(pi_names_dict.values())\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "Context:\n",
    "You are an AI assistant analyzing research collaboration data to identify 'influencers'. An influencer is defined as a researcher who has significant connections and reach, demonstrated by:\n",
    "1.  High number of distinct projects/awards involved in.\n",
    "2.  High number of unique collaborators worked with.\n",
    "3.  Experience across a diverse range of research fields.\n",
    "4.  Collaboration with individuals from a wide range of different institutions.\n",
    "\n",
    "Below is summarized data for potential influencers ({candidate_names_list}):\n",
    "\n",
    "{formatted_data_string}\n",
    "\n",
    "Task:\n",
    "Based *only* on the summarized information provided above, please analyze each researcher's profile according to the 'influencer' criteria (project count, collaborator count, field count, AND collaborating institution count).\n",
    "\n",
    "Rank these individuals ({candidate_names_list}) from most influential to least influential based on this definition.\n",
    "\n",
    "Provide a clear ranking and a concise justification for your ranking, referencing the specific metrics provided for each researcher.\n",
    "\"\"\"\n",
    "    print(\"Influencer prompt (v2) generated.\")\n",
    "    return prompt\n",
    "\n",
    "# New Orchestrator using V2 functions\n",
    "def identify_influencer_llm_v2(df: pd.DataFrame, model: genai.GenerativeModel, pi_ids: List[str]) -> Optional[str]:\n",
    "    \"\"\" V2: Orchestrator using formatting and prompt that include institutional diversity. \"\"\"\n",
    "    print(f\"\\n--- Starting Influencer Identification Process (V2 - Incl. Institutions) for PI IDs: {pi_ids} ---\")\n",
    "    formatted_text, pi_names = format_influencer_data_v2(df, pi_ids) # Use V2 format\n",
    "    if not pi_names or all(name.startswith(\"PI ID\") for name in pi_names.values()):\n",
    "         # (Same error handling)\n",
    "         return \"Could not generate influencer ranking due to lack of data.\"\n",
    "\n",
    "    prompt_text = generate_influencer_prompt_v2(formatted_text, pi_names) # Use V2 prompt\n",
    "    print(\"--- Sending Request to Gemini for Influencer Ranking (V2) ---\")\n",
    "    ranking_result, duration = get_gemini_response(model, prompt_text)\n",
    "\n",
    "    if ranking_result:\n",
    "        print(f\"--- Influencer Identification (V2) Complete ({duration:.2f}s) ---\")\n",
    "        return ranking_result\n",
    "    else:\n",
    "        print(\"--- Influencer Identification (V2) Failed ---\")\n",
    "        return \"Failed to get influencer ranking (V2) from the model.\"\n",
    "\n",
    "# --- Method 5: Specific Award Types ---\n",
    "\n",
    "# Modify select_candidate_pis to handle 'award_type'\n",
    "def select_candidate_pis_v2(\n",
    "    df: pd.DataFrame,\n",
    "    df_grouped: pd.DataFrame,\n",
    "    embedder,\n",
    "    criterion_type: str, # topic, department, award_type\n",
    "    criterion_value: str,\n",
    "    top_k: int = 10\n",
    ") -> List[str]:\n",
    "    \"\"\" V2: Selects candidates based on topic, department, OR award_type. \"\"\"\n",
    "    print(f\"Selecting top {top_k} candidates based on {criterion_type}: '{criterion_value}'...\")\n",
    "    candidate_ids = []\n",
    "\n",
    "    if criterion_type == \"topic\":\n",
    "        # (Same logic as before)\n",
    "        if 'text_embedding' not in df_grouped.columns or embedder is None: return []\n",
    "        topic_emb = embedder.encode(criterion_value)\n",
    "        all_embeddings = np.stack(df_grouped['text_embedding'].values)\n",
    "        similarities = cosine_similarity([topic_emb], all_embeddings)[0]\n",
    "        top_indices = np.argsort(similarities)[::-1][:top_k]\n",
    "        candidate_ids = df_grouped.iloc[top_indices]['pi_id'].tolist()\n",
    "\n",
    "    elif criterion_type == \"department\":\n",
    "        # (Same logic as before)\n",
    "        dept_match_df = df[df['department'].str.contains(criterion_value, case=False, na=False)]\n",
    "        if dept_match_df.empty: return []\n",
    "        unique_dept_pi_ids = dept_match_df['pi_id'].unique()\n",
    "        if len(unique_dept_pi_ids) > top_k:\n",
    "            candidate_subset = df_grouped[df_grouped['pi_id'].isin(unique_dept_pi_ids)]\n",
    "            if 'award_count' in candidate_subset.columns:\n",
    "                 ranked_candidates = candidate_subset.sort_values(by='award_count', ascending=False)\n",
    "                 candidate_ids = ranked_candidates.head(top_k)['pi_id'].tolist()\n",
    "            else: candidate_ids = list(unique_dept_pi_ids)[:top_k]\n",
    "        else: candidate_ids = list(unique_dept_pi_ids)\n",
    "\n",
    "    # --- NEW: Award Type Logic ---\n",
    "    elif criterion_type == \"award_title\":\n",
    "        # Filter main df by the specific award type (case-insensitive partial match)\n",
    "        award_match_df = df[df['award_title'].str.contains(criterion_value, case=False, na=False)]\n",
    "        if award_match_df.empty:\n",
    "            print(f\"No PIs found associated with award type: '{criterion_value}'\")\n",
    "            return []\n",
    "        unique_award_pi_ids = award_match_df['pi_id'].unique()\n",
    "\n",
    "        # Rank by award count within this group if needed\n",
    "        if len(unique_award_pi_ids) > top_k:\n",
    "            candidate_subset = df_grouped[df_grouped['pi_id'].isin(unique_award_pi_ids)]\n",
    "            if 'award_count' in candidate_subset.columns:\n",
    "                 ranked_candidates = candidate_subset.sort_values(by='award_count', ascending=False)\n",
    "                 candidate_ids = ranked_candidates.head(top_k)['pi_id'].tolist()\n",
    "            else: candidate_ids = list(unique_award_pi_ids)[:top_k]\n",
    "            print(f\"  (Found {len(unique_award_pi_ids)} PIs, selecting top {top_k} based on award count)\")\n",
    "        else:\n",
    "            candidate_ids = list(unique_award_pi_ids)\n",
    "    # --- End New Logic ---\n",
    "\n",
    "    else:\n",
    "        print(f\"Error: Invalid criterion_type '{criterion_type}'. Use 'topic', 'department', or 'award_title'.\")\n",
    "        return []\n",
    "\n",
    "    print(f\"Selected candidate PI IDs: {candidate_ids}\")\n",
    "    return candidate_ids\n",
    "\n",
    "# Modify the main orchestrator to use the updated selector\n",
    "def find_influencers_by_criterion_v2(\n",
    "    df: pd.DataFrame,\n",
    "    df_grouped: pd.DataFrame,\n",
    "    embedder,\n",
    "    model: genai.GenerativeModel,\n",
    "    criterion_type: str, # topic, department, award_type\n",
    "    criterion_value: str,\n",
    "    top_k_candidates: int = 10\n",
    ") -> Optional[str]:\n",
    "    \"\"\" V2: Finds influencers based on topic, department, OR award_type criterion. \"\"\"\n",
    "    print(f\"\\n--- Starting Influencer Search (V2 Selector) by {criterion_type.capitalize()}: '{criterion_value}' ---\")\n",
    "\n",
    "    # 1. Select Candidate PIs using the V2 selector\n",
    "    candidate_pi_ids = select_candidate_pis_v2( # Use V2 selector\n",
    "        df, df_grouped, embedder, criterion_type, criterion_value, top_k=top_k_candidates\n",
    "    )\n",
    "\n",
    "    if not candidate_pi_ids:\n",
    "        # (Same error handling)\n",
    "        return f\"Could not find candidates matching {criterion_type}: '{criterion_value}'.\"\n",
    "\n",
    "    # 2. Proceed with LLM analysis (using V1 or V2 formatting/prompting as desired)\n",
    "    # Using V2 here to include institutional diversity analysis as well\n",
    "    print(f\"\\n--- Analyzing Selected Candidates for Influence (V2 - Incl. Institutions) ---\")\n",
    "    influencer_ranking_result = identify_influencer_llm_v2(df, model, candidate_pi_ids)\n",
    "\n",
    "    return influencer_ranking_result\n",
    "\n",
    "\n",
    "# --- Method 6: Hybrid Approach (Example: Topic + Institutions in Prompt) ---\n",
    "\n",
    "# We can reuse `find_influencers_by_criterion_v2` but need a modified prompt generator\n",
    "# that explicitly tells the LLM to weigh two factors.\n",
    "\n",
    "def generate_influencer_prompt_hybrid(\n",
    "    formatted_data_string: str,\n",
    "    pi_names_dict: Dict[str, str],\n",
    "    primary_criterion: str, # e.g., \"Topic Relevance to 'AI'\"\n",
    "    secondary_criterion: str # e.g., \"Breadth of Institutional Collaboration\"\n",
    "    ) -> str:\n",
    "    \"\"\" Hybrid: Asks LLM to rank based on two weighted criteria. \"\"\"\n",
    "    print(\"Generating influencer prompt (Hybrid)...\")\n",
    "    candidate_names_list = \", \".join(pi_names_dict.values())\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "Context:\n",
    "You are an AI assistant identifying 'influencers' based on multiple factors.\n",
    "Primary Factor: {primary_criterion}\n",
    "Secondary Factor: {secondary_criterion}\n",
    "\n",
    "Below is data for potential influencers ({candidate_names_list}), including metrics for projects, collaborators, fields, and collaborating institutions:\n",
    "\n",
    "{formatted_data_string}\n",
    "\n",
    "Task:\n",
    "Based *only* on the summarized information provided, please rank these individuals ({candidate_names_list}) from most influential to least influential.\n",
    "\n",
    "Your ranking should primarily consider the **Primary Factor ({primary_criterion})**. Then, among those who rank highly on the primary factor, give preference based on the **Secondary Factor ({secondary_criterion})**.\n",
    "\n",
    "Provide a clear ranking and justify your reasoning by referencing the specific metrics and how they relate to both factors.\n",
    "\"\"\"\n",
    "    print(\"Influencer prompt (Hybrid) generated.\")\n",
    "    return prompt\n",
    "\n",
    "# Orchestrator for Hybrid approach\n",
    "def find_influencers_hybrid(\n",
    "    df: pd.DataFrame,\n",
    "    df_grouped: pd.DataFrame,\n",
    "    embedder,\n",
    "    model: genai.GenerativeModel,\n",
    "    primary_criterion_type: str, # e.g., \"topic\"\n",
    "    primary_criterion_value: str, # e.g., \"STATISTICS\"\n",
    "    secondary_criterion_desc: str, # e.g., \"Breadth of Institutional Collaboration\"\n",
    "    top_k_candidates: int = 10\n",
    ") -> Optional[str]:\n",
    "    \"\"\" Hybrid: Selects on primary, then asks LLM to rank using primary+secondary factors. \"\"\"\n",
    "\n",
    "    primary_criterion_desc = f\"{primary_criterion_type.capitalize()} related to '{primary_criterion_value}'\"\n",
    "    print(f\"\\n--- Starting Hybrid Influencer Search ({primary_criterion_desc} + {secondary_criterion_desc}) ---\")\n",
    "\n",
    "    # 1. Select candidates based on the PRIMARY criterion\n",
    "    candidate_pi_ids = select_candidate_pis_v2(\n",
    "        df, df_grouped, embedder, primary_criterion_type, primary_criterion_value, top_k=top_k_candidates\n",
    "    )\n",
    "    if not candidate_pi_ids:\n",
    "        return f\"Could not find candidates matching primary criterion: {primary_criterion_desc}.\"\n",
    "\n",
    "    # 2. Format data (use V2 to ensure institutional data is included)\n",
    "    formatted_text, pi_names = format_influencer_data_v2(df, candidate_pi_ids)\n",
    "    if not pi_names or all(name.startswith(\"PI ID\") for name in pi_names.values()):\n",
    "         return \"Could not generate ranking due to lack of data for selected candidates.\"\n",
    "\n",
    "    # 3. Generate the HYBRID prompt\n",
    "    prompt_text = generate_influencer_prompt_hybrid(\n",
    "        formatted_text, pi_names, primary_criterion_desc, secondary_criterion_desc\n",
    "    )\n",
    "\n",
    "    # 4. Get LLM Response\n",
    "    print(\"--- Sending Request to Gemini for Influencer Ranking (Hybrid) ---\")\n",
    "    ranking_result, duration = get_gemini_response(model, prompt_text)\n",
    "\n",
    "    if ranking_result:\n",
    "        print(f\"--- Influencer Identification (Hybrid) Complete ({duration:.2f}s) ---\")\n",
    "        return ranking_result\n",
    "    else:\n",
    "        print(\"--- Influencer Identification (Hybrid) Failed ---\")\n",
    "        return \"Failed to get influencer ranking (Hybrid) from the model.\"\n",
    "\n",
    "\n",
    "# --- Method 7: Network Centrality (Requires NetworkX) ---\n",
    "\n",
    "def calculate_network_centrality(df: pd.DataFrame, top_n: int = 20) -> Optional[pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Calculates Degree and Betweenness Centrality for PIs based on co-awards.\n",
    "\n",
    "    Args:\n",
    "        df: The main DataFrame with 'award_title' and 'pi_id'.\n",
    "        top_n: Number of top influencers to return based on centrality.\n",
    "\n",
    "    Returns:\n",
    "        A DataFrame with PI IDs, names, degree, and betweenness centrality,\n",
    "        ranked by betweenness, then degree. Returns None if networkx is not installed.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        import networkx as nx\n",
    "    except ImportError:\n",
    "        print(\"Error: networkx library is required for network centrality analysis. Install using 'pip install networkx'\")\n",
    "        return None\n",
    "\n",
    "    print(\"\\n--- Calculating Network Centrality ---\")\n",
    "    # Create graph\n",
    "    G = nx.Graph()\n",
    "\n",
    "    # Group by award to find collaborators\n",
    "    awards = df.groupby('award_title')['pi_id'].apply(list)\n",
    "\n",
    "    # Add edges between collaborators on the same award\n",
    "    for award_id, collaborators in awards.items():\n",
    "        # Remove duplicates just in case\n",
    "        unique_collaborators = list(set(collaborators))\n",
    "        if len(unique_collaborators) > 1:\n",
    "            # Add edges between all pairs in this award group\n",
    "            import itertools\n",
    "            for pi1, pi2 in itertools.combinations(unique_collaborators, 2):\n",
    "                if G.has_edge(pi1, pi2):\n",
    "                    G[pi1][pi2]['weight'] = G[pi1][pi2].get('weight', 0) + 1\n",
    "                else:\n",
    "                    G.add_edge(pi1, pi2, weight=1)\n",
    "\n",
    "    if not G.nodes():\n",
    "        print(\"Graph contains no nodes. Cannot calculate centrality.\")\n",
    "        return pd.DataFrame(columns=['pi_id', 'pi_full_name', 'degree_centrality', 'betweenness_centrality'])\n",
    "\n",
    "\n",
    "    # Calculate centrality measures\n",
    "    print(\"Calculating Degree Centrality...\")\n",
    "    degree_centrality = nx.degree_centrality(G)\n",
    "    print(\"Calculating Betweenness Centrality (may take time)...\")\n",
    "    betweenness_centrality = nx.betweenness_centrality(G, normalized=True, weight='weight') # Consider edge weights\n",
    "\n",
    "    # Combine results into a DataFrame\n",
    "    pi_ids = list(G.nodes())\n",
    "    centrality_df = pd.DataFrame({\n",
    "        'pi_id': pi_ids,\n",
    "        'degree_centrality': [degree_centrality.get(pi, 0) for pi in pi_ids],\n",
    "        'betweenness_centrality': [betweenness_centrality.get(pi, 0) for pi in pi_ids]\n",
    "    })\n",
    "\n",
    "    # Merge with PI names (get the first name found for each PI ID)\n",
    "    pi_names_map = df[['pi_id', 'pi_full_name']].drop_duplicates(subset='pi_id').set_index('pi_id')\n",
    "    centrality_df = centrality_df.join(pi_names_map, on='pi_id')\n",
    "\n",
    "    # Rank: Prioritize betweenness, then degree\n",
    "    ranked_df = centrality_df.sort_values(\n",
    "        by=['betweenness_centrality', 'degree_centrality'],\n",
    "        ascending=[False, False]\n",
    "    ).reset_index(drop=True)\n",
    "\n",
    "    print(\"--- Network Centrality Calculation Complete ---\")\n",
    "    return ranked_df[['pi_id', 'pi_full_name', 'degree_centrality', 'betweenness_centrality']].head(top_n)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Influencers BASED ON range of institutional connections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== EXAMPLE: Influencers by Institutional Breadth ===\n",
      "\n",
      "--- Starting Influencer Identification Process (V2 - Incl. Institutions) for PI IDs: ['000025762', '269811881', '269807623', '270021884'] ---\n",
      "Formatting influencer data (v2) for PI IDs: ['000025762', '269811881', '269807623', '270021884']...\n",
      "  Processing data for Steven N MacEachern (000025762)...\n",
      "  Processing data for Jianlin   Cheng (269811881)...\n",
      "  Processing data for Dirk J Colbry (269807623)...\n",
      "  Processing data for Guido F Montufar Cuartas (270021884)...\n",
      "Influencer data formatting (v2) complete.\n",
      "Generating influencer prompt (v2)...\n",
      "Influencer prompt (v2) generated.\n",
      "--- Sending Request to Gemini for Influencer Ranking (V2) ---\n",
      "\n",
      "PI: **In summary, Dirk J Colbry stands out as the most influential, followed by Steven N MacEachern, then Guido F Montufar Cuartas, and finally Jianlin Cheng, based on the provided metrics for project involvement, collaborator count, field diversity, and institutional diversity.**\n",
      "\n",
      "Response generated in 7.95 seconds.\n",
      "--- Influencer Identification (V2) Complete (7.95s) ---\n",
      "## Ranking of Potential Influencers:\n",
      "\n",
      "Based on the provided data and the definition of an 'influencer', here is the ranking from most to least influential:\n",
      "\n",
      "**1. Dirk J Colbry**\n",
      "\n",
      "*   **Justification:** Dirk J Colbry demonstrates the strongest profile across all influencer criteria. He is involved in the highest number of projects (3), has the most unique collaborators (11), the most diverse research fields (5), and the most unique collaborating institutions (7).  He consistently outperforms all other researchers in every measured metric, making him the clear top influencer based on this data.\n",
      "\n",
      "**2. Steven N MacEachern**\n",
      "\n",
      "*   **Justification:** Steven N MacEachern is the second most influential researcher. While he is involved in fewer projects than Dirk, he still participates in a respectable number (2). He also has a good number of unique collaborators (4) and collaborates with a moderate number of unique institutions (3).  However, his experience is limited to a single research field, which is his main weakness compared to Dirk.\n",
      "\n",
      "**3. Guido F Montufar Cuartas**\n",
      "\n",
      "*   **Justification:** Guido F Montufar Cuartas ranks third. He is involved in 2 projects, similar to Steven and Jianlin. He has a slightly higher number of unique collaborators (2) than Jianlin, and exhibits experience across a good number of research fields (4), similar to Jianlin. However, his collaboration network is limited to a single institution, which significantly reduces his overall influence compared to Dirk and Steven, and slightly compared to Jianlin in terms of institutional diversity.\n",
      "\n",
      "**4. Jianlin Cheng**\n",
      "\n",
      "*   **Justification:** Jianlin Cheng is ranked as the least influential among the four. While he has experience across a diverse range of research fields (4), comparable to Guido, he falls short in other areas. He is involved in 2 projects, but has the lowest number of unique collaborators (1) and collaborates with the fewest unique institutions (1). His limited network of collaborators and institutions suggests a narrower reach and influence compared to the other researchers.\n",
      "\n",
      "**In summary, Dirk J Colbry stands out as the most influential, followed by Steven N MacEachern, then Guido F Montufar Cuartas, and finally Jianlin Cheng, based on the provided metrics for project involvement, collaborator count, field diversity, and institutional diversity.**\n"
     ]
    }
   ],
   "source": [
    "# Example 1: Find influencers based on institutional breadth (using V2)\n",
    "print(\"\\n=== EXAMPLE: Influencers by Institutional Breadth ===\")\n",
    "candidate_ids_for_inst = ['000025762', '269811881', '269807623', '270021884'] # Example list\n",
    "inst_ranking = identify_influencer_llm_v2(df, model, candidate_ids_for_inst)\n",
    "if inst_ranking: print(inst_ranking)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Influencers BASED ON Department"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== EXAMPLE: Influencers by Department (Computer Science) ===\n",
      "\n",
      "--- Starting Influencer Search (V2 Selector) by Department: 'Computer Science' ---\n",
      "Selecting top 10 candidates based on department: 'Computer Science'...\n",
      "Selected candidate PI IDs: ['269935164', '269779708', '269765937', '000235919', '270031750', '000207040', '270018850', '269779084', '269985475', '269680242']\n",
      "\n",
      "--- Analyzing Selected Candidates for Influence (V2 - Incl. Institutions) ---\n",
      "\n",
      "--- Starting Influencer Identification Process (V2 - Incl. Institutions) for PI IDs: ['269935164', '269779708', '269765937', '000235919', '270031750', '000207040', '270018850', '269779084', '269985475', '269680242'] ---\n",
      "Formatting influencer data (v2) for PI IDs: ['269935164', '269779708', '269765937', '000235919', '270031750', '000207040', '270018850', '269779084', '269985475', '269680242']...\n",
      "  Processing data for Yanfang   Ye (269935164)...\n",
      "  Processing data for Prasad   Calyam (269779708)...\n",
      "  Processing data for Tiffany M Barnes (269765937)...\n",
      "  Processing data for Sharad   Mehrotra (000235919)...\n",
      "  Processing data for Ferdinando   Fioretto (270031750)...\n",
      "  Processing data for Dhabaleswar K Panda (000207040)...\n",
      "  Processing data for Ravi Netravali (270018850)...\n",
      "  Processing data for Aditya   Akella (269779084)...\n",
      "  Processing data for Jiliang   Tang (269985475)...\n",
      "  Processing data for Mahmut T Kandemir (269680242)...\n",
      "Influencer data formatting (v2) complete.\n",
      "Generating influencer prompt (v2)...\n",
      "Influencer prompt (v2) generated.\n",
      "--- Sending Request to Gemini for Influencer Ranking (V2) ---\n",
      "\n",
      "PI: 10. **Ravi Netravali**: Ravi Netravali ranks last, showing the least influence among the listed researchers based on the provided data. He has the lowest number of projects (5), unique collaborators (2), and relatively low numbers for unique research fields (8) and unique collaborating institutions (6). These metrics combined indicate a comparatively limited reach and connection network.\n",
      "\n",
      "Response generated in 10.12 seconds.\n",
      "--- Influencer Identification (V2) Complete (10.12s) ---\n",
      "Based on the provided data and the criteria for influence, here is the ranking of the researchers from most to least influential:\n",
      "\n",
      "**Ranking of Influencers (Most to Least Influential):**\n",
      "\n",
      "1.  **Tiffany M Barnes**: Tiffany M Barnes demonstrates the strongest profile as an influencer. She ranks highest in unique collaborators (30) and unique collaborating institutions (22), and second highest in unique research fields (13). While her project count (11) is not the highest, her exceptional breadth in collaborations and institutional reach firmly places her at the top.\n",
      "\n",
      "2.  **Prasad Calyam**: Prasad Calyam is a close second, showing strong influence. He leads in total projects involved (14) and unique research fields (22), and is second highest in unique collaborators (25). His number of unique collaborating institutions (12) is also substantial, indicating a wide network and diverse engagement.\n",
      "\n",
      "3.  **Jiliang Tang**: Jiliang Tang ranks third due to a balanced profile across all criteria. He has a high number of unique collaborators (21, third highest) and a good number of unique collaborating institutions (11). His project count (9) and research fields (12) are also solid, placing him consistently high across metrics.\n",
      "\n",
      "4.  **Sharad Mehrotra**: Sharad Mehrotra is in the middle of the ranking, showing moderate influence. He has a good number of unique collaborating institutions (15) and unique collaborators (18). However, his project count (10) and unique research fields (11) are not as high as the top three, placing him slightly lower in overall influence compared to them.\n",
      "\n",
      "5.  **Dhabaleswar K Panda**: Dhabaleswar K Panda is fifth, with a decent profile. He has a good number of unique collaborators (20) and unique research fields (15). His unique collaborating institutions (10) and project count (9) are moderate, indicating a solid but not top-tier influence based on these metrics.\n",
      "\n",
      "6.  **Yanfang Ye**: Yanfang Ye ranks sixth. She has a high number of projects (13) and unique research fields (12), but her significantly lower number of unique collaborators (11) and especially unique collaborating institutions (2) limits her overall influence score compared to others higher in the ranking.\n",
      "\n",
      "7.  **Mahmut T Kandemir**: Mahmut T Kandemir is seventh. He has a moderate number of unique collaborators (17) and projects (9). However, his number of unique collaborating institutions (7) and research fields (11) are relatively lower, resulting in a lower influence ranking.\n",
      "\n",
      "8.  **Aditya Akella**: Aditya Akella is eighth in the ranking. He has a moderate number of unique collaborating institutions (10) and collaborators (13), but his project count (8) and unique research fields (8) are on the lower side compared to many others, indicating a less pronounced influence based on these metrics.\n",
      "\n",
      "9.  **Ferdinando Fioretto**: Ferdinando Fioretto ranks ninth. While he has a reasonable number of unique collaborating institutions (8) and research fields (11), his significantly lower numbers in projects (7) and unique collaborators (6) place him low in terms of influence as defined by these criteria.\n",
      "\n",
      "10. **Ravi Netravali**: Ravi Netravali ranks last, showing the least influence among the listed researchers based on the provided data. He has the lowest number of projects (5), unique collaborators (2), and relatively low numbers for unique research fields (8) and unique collaborating institutions (6). These metrics combined indicate a comparatively limited reach and connection network.\n"
     ]
    }
   ],
   "source": [
    "# Example 2: Find influencers from 'Computer Science' dept (using V2 selector & V2 analysis)\n",
    "print(\"\\n=== EXAMPLE: Influencers by Department (Computer Science) ===\")\n",
    "cs_ranking = find_influencers_by_criterion_v2(\n",
    "    df, df_grouped, embedder, model,\n",
    "    criterion_type=\"department\",\n",
    "    criterion_value=\"Computer Science\",\n",
    "    top_k_candidates=10\n",
    ")\n",
    "if cs_ranking: print(cs_ranking)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Influencers BASED ON award title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== EXAMPLE: Influencers by Award Type (MRI) ===\n",
      "\n",
      "--- Starting Influencer Search (V2 Selector) by Award_title: 'NSF' ---\n",
      "Selecting top 5 candidates based on award_title: 'NSF'...\n",
      "  (Found 4235 PIs, selecting top 5 based on award count)\n",
      "Selected candidate PI IDs: ['269959504', '269935164', '270041430', '269772812', '269999971']\n",
      "\n",
      "--- Analyzing Selected Candidates for Influence (V2 - Incl. Institutions) ---\n",
      "\n",
      "--- Starting Influencer Identification Process (V2 - Incl. Institutions) for PI IDs: ['269959504', '269935164', '270041430', '269772812', '269999971'] ---\n",
      "Formatting influencer data (v2) for PI IDs: ['269959504', '269935164', '270041430', '269772812', '269999971']...\n",
      "  Processing data for Jerene   Shaheed (269959504)...\n",
      "  Processing data for Yanfang   Ye (269935164)...\n",
      "  Processing data for Jacqueline   El-Sayed (270041430)...\n",
      "  Processing data for Nicholas G Feamster (269772812)...\n",
      "  Processing data for Josiah D Hester (269999971)...\n",
      "Influencer data formatting (v2) complete.\n",
      "Generating influencer prompt (v2)...\n",
      "Influencer prompt (v2) generated.\n",
      "--- Sending Request to Gemini for Influencer Ranking (V2) ---\n",
      "\n",
      "PI: Jacqueline El-Sayed and Josiah D Hester emerge as the top influencers due to their strong performance across collaborator count, field diversity, and institutional diversity. Nicholas G Feamster shows a moderate and balanced influence. Yanfang Ye has a more limited reach, and Jerene Shaheed, despite a high project count, appears to be the least influential based on the criteria due to a lack of collaboration and institutional diversity.\n",
      "\n",
      "Response generated in 9.12 seconds.\n",
      "--- Influencer Identification (V2) Complete (9.12s) ---\n",
      "Based on the provided data, here is the ranking of the researchers from most to least influential, along with a justification:\n",
      "\n",
      "**Ranking (Most to Least Influential):**\n",
      "\n",
      "1.  **Jacqueline El-Sayed**\n",
      "2.  **Josiah D Hester**\n",
      "3.  **Nicholas G Feamster**\n",
      "4.  **Yanfang Ye**\n",
      "5.  **Jerene Shaheed**\n",
      "\n",
      "**Justification:**\n",
      "\n",
      "**1. Jacqueline El-Sayed:**  Jacqueline El-Sayed demonstrates the strongest profile for an influencer based on the criteria. She excels in three out of the four metrics: having the **highest number of unique research fields (19)**, **highest number of unique collaborating institutions (19)**, and a **high number of unique collaborators (25)**, second only to Josiah Hester. While her project count (16) is not the highest, her breadth of collaboration and field diversity strongly indicate influence across different research areas and institutions.\n",
      "\n",
      "**2. Josiah D Hester:** Josiah D Hester is a close second, primarily driven by having the **highest number of unique collaborators (26)**. He also shows strong performance in **unique research fields (18)** and **unique collaborating institutions (15)**, both metrics being in the higher range compared to the other researchers. His project count (12) is the lowest among the group, but his exceptional collaborator count and broad field/institutional reach position him as highly influential.\n",
      "\n",
      "**3. Nicholas G Feamster:** Nicholas G Feamster shows a balanced profile. He has a decent number of **projects (13)**, a good number of **unique collaborators (15)**, a solid number of **unique research fields (16)**, and a significant number of **unique collaborating institutions (15)**. He consistently ranks in the middle to upper range across all metrics, indicating a moderate level of influence across different areas.\n",
      "\n",
      "**4. Yanfang Ye:** Yanfang Ye shows a moderate level of influence. While she has a reasonable number of **projects (13)** and **unique research fields (12)**, her number of **unique collaborators (11)** and **unique collaborating institutions (2)** are comparatively lower than the top three.  Her lower institutional diversity, in particular, suggests a more limited reach compared to Jacqueline, Josiah, and Nicholas.\n",
      "\n",
      "**5. Jerene Shaheed:** Jerene Shaheed ranks as the least influential based on the provided data. Despite having the **highest number of projects (30)**, she has **zero unique collaborators** and **zero unique collaborating institutions**. Her number of **unique research fields (2)** is also the lowest. The lack of collaborators and institutional diversity, despite a high project count, strongly suggests a limited sphere of influence and reach as defined by the criteria. Her profile indicates a focus perhaps on internal projects or a very specialized area without broad collaboration.\n",
      "\n",
      "**In Summary:**\n",
      "\n",
      "Jacqueline El-Sayed and Josiah D Hester emerge as the top influencers due to their strong performance across collaborator count, field diversity, and institutional diversity. Nicholas G Feamster shows a moderate and balanced influence. Yanfang Ye has a more limited reach, and Jerene Shaheed, despite a high project count, appears to be the least influential based on the criteria due to a lack of collaboration and institutional diversity.\n"
     ]
    }
   ],
   "source": [
    "# Example 3: Find influencers associated with 'MRI' award type (using V2 selector & V2 analysis)\n",
    "print(\"\\n=== EXAMPLE: Influencers by Award Type (MRI) ===\")\n",
    "mri_ranking = find_influencers_by_criterion_v2(\n",
    "    df, df_grouped, embedder, model,\n",
    "    criterion_type=\"award_title\",\n",
    "    criterion_value=\"NSF\", # Major Research Instrumentation\n",
    "    top_k_candidates=5\n",
    ")\n",
    "if mri_ranking: print(mri_ranking)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topic & Institutional Breadth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== EXAMPLE: Hybrid Search (Topic: Robotics + Institutions) ===\n",
      "\n",
      "--- Starting Hybrid Influencer Search (Topic related to 'Robotics' + Breadth of Institutional Collaboration) ---\n",
      "Selecting top 10 candidates based on topic: 'Robotics'...\n",
      "Selected candidate PI IDs: ['269818291', '270031608', '269982422', '269693864', '270019686', '270057330', '270019331', '269999999', '269948584', '000182004']\n",
      "Formatting influencer data (v2) for PI IDs: ['269818291', '270031608', '269982422', '269693864', '270019686', '270057330', '270019331', '269999999', '269948584', '000182004']...\n",
      "  Processing data for Jason O'Kane (269818291)...\n",
      "  Processing data for Naomi T Fitter (270031608)...\n",
      "  Processing data for Aaron M Johnson (269982422)...\n",
      "  Processing data for William D Smart (269693864)...\n",
      "  Processing data for Berk   Calli (270019686)...\n",
      "  Processing data for Kaiyu Hang (270057330)...\n",
      "  Processing data for Stefanos   Nikolaidis (270019331)...\n",
      "  Processing data for Philip M Dames (269999999)...\n",
      "  Processing data for Ioannis   Rekleitis (269948584)...\n",
      "  Processing data for Seth   Hutchinson (000182004)...\n",
      "Influencer data formatting (v2) complete.\n",
      "Generating influencer prompt (Hybrid)...\n",
      "Influencer prompt (Hybrid) generated.\n",
      "--- Sending Request to Gemini for Influencer Ranking (Hybrid) ---\n",
      "\n",
      "PI: The ranking is primarily determined by the \"Number of Unique Collaborating Institutions\" (Secondary Factor).  Individuals with higher numbers are ranked higher.  In cases of ties in this primary metric within the secondary factor, the \"Total Unique Collaborators\" and alphabetical order were used as tie-breakers to provide a definitive ranking based *only* on the provided data. We assume all individuals are relevant to the Primary Factor (Robotics) as they are presented as potential influencers in this domain.\n",
      "\n",
      "Response generated in 10.06 seconds.\n",
      "--- Influencer Identification (Hybrid) Complete (10.06s) ---\n",
      "Ranking of Potential Influencers (Most to Least Influential):\n",
      "\n",
      "1.  **Ioannis Rekleitis**\n",
      "    *   **Justification:** Ioannis Rekleitis demonstrates the broadest institutional collaboration with **5 Unique Collaborating Institutions**. This is the highest number among all listed individuals, making him rank highest based on the secondary factor, assuming equal relevance to the primary factor (Robotics).\n",
      "\n",
      "2.  **William D Smart**\n",
      "    *   **Justification:** William D Smart is tied for the second highest number of Unique Collaborating Institutions with **4**.  As we prioritize institutional breadth, he ranks highly.\n",
      "\n",
      "3.  **Stefanos Nikolaidis**\n",
      "    *   **Justification:** Stefanos Nikolaidis also has **4 Unique Collaborating Institutions**, tying with William D Smart for the second highest count. However, William D Smart has a higher number of Unique Collaborators (7 vs 5), which, while secondary to institutional breadth, further supports William D Smart being ranked slightly higher within this tier.\n",
      "\n",
      "4.  **Berk Calli**\n",
      "    *   **Justification:** Berk Calli has **3 Unique Collaborating Institutions**, placing him next in line after those with 4 or more.\n",
      "\n",
      "5.  **Naomi T Fitter**\n",
      "    *   **Justification:** Naomi T Fitter has **2 Unique Collaborating Institutions**. This places her in a group with several others. To differentiate within this group, we consider other metrics. Naomi T Fitter has a relatively high number of Unique Collaborators at 5 within this group of individuals with 2 Unique Collaborating Institutions.\n",
      "\n",
      "6.  **Seth Hutchinson**\n",
      "    *   **Justification:** Seth Hutchinson also has **2 Unique Collaborating Institutions**.  He has 3 Unique Collaborators, which is less than Naomi T Fitter but more than Kaiyu Hang and Philip M Dames within this group.\n",
      "\n",
      "7.  **Philip M Dames**\n",
      "    *   **Justification:** Philip M Dames has **2 Unique Collaborating Institutions** and **2 Unique Collaborators**.  While tied with Kaiyu Hang on these metrics, alphabetically 'Dames' comes before 'Hang', providing a tie-breaker for consistent ordering in case of complete metric parity.\n",
      "\n",
      "8.  **Kaiyu Hang**\n",
      "    *   **Justification:** Kaiyu Hang has **2 Unique Collaborating Institutions** and **2 Unique Collaborators**, the same as Philip M Dames. Alphabetically 'Hang' comes after 'Dames'.\n",
      "\n",
      "9.  **Jason O'Kane**\n",
      "    *   **Justification:** Jason O'Kane has only **1 Unique Collaborating Institution**. This is less than the majority of the listed individuals, placing him lower in the ranking based on institutional breadth.\n",
      "\n",
      "10. **Aaron M Johnson**\n",
      "    *   **Justification:** Aaron M Johnson has **0 Unique Collaborating Institutions**. This is the lowest possible value and indicates the least breadth of institutional collaboration among the listed individuals, resulting in the lowest ranking.\n",
      "\n",
      "\n",
      "**Summary of Ranking Rationale:**\n",
      "\n",
      "The ranking is primarily determined by the \"Number of Unique Collaborating Institutions\" (Secondary Factor).  Individuals with higher numbers are ranked higher.  In cases of ties in this primary metric within the secondary factor, the \"Total Unique Collaborators\" and alphabetical order were used as tie-breakers to provide a definitive ranking based *only* on the provided data. We assume all individuals are relevant to the Primary Factor (Robotics) as they are presented as potential influencers in this domain.\n"
     ]
    }
   ],
   "source": [
    "# Example 4: Hybrid search - Topic: \"Robotics\" + Secondary: Institutional Breadth\n",
    "print(\"\\n=== EXAMPLE: Hybrid Search (Topic: Robotics + Institutions) ===\")\n",
    "hybrid_ranking = find_influencers_hybrid(\n",
    "    df, df_grouped, embedder, model,\n",
    "    primary_criterion_type=\"topic\",\n",
    "    primary_criterion_value=\"Robotics\",\n",
    "    secondary_criterion_desc=\"Breadth of Institutional Collaboration\",\n",
    "    top_k_candidates=10\n",
    ")\n",
    "if hybrid_ranking: print(hybrid_ranking)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network Centrality Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 5: Network Centrality Analysis\n",
    "print(\"\\n=== EXAMPLE: Network Centrality Analysis ===\")\n",
    "centrality_results = calculate_network_centrality(df, top_n=15)\n",
    "if centrality_results is not None:\n",
    "    print(centrality_results.to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PI classification rule based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from datetime import datetime\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Combine relevant text columns into one (you may adjust columns as needed)\n",
    "text_columns = [\n",
    "    \"award_type\", \"award_title\", \"abstract\", \n",
    "    \"org_name\", \"org_name2\", \"perf_inst_name\", \n",
    "    \"program_element\", \"program_reference\"\n",
    "]\n",
    "df[\"combined_text\"] = df[text_columns].astype(str).agg(\" \".join, axis=1)\n",
    "\n",
    "# a. Leadership indicator: 1 if role suggests prior leadership (e.g., contains \"Principal Investigator\")\n",
    "df[\"leadership\"] = df[\"role\"].apply(lambda x: 1 if \"Principal Investigator\" in str(x) else 0)\n",
    "\n",
    "# b. Experience in years: use start_date and a reference date (here we use today)\n",
    "df[\"start_date\"] = pd.to_datetime(df[\"start_date\"], errors='coerce')\n",
    "reference_date = datetime.now()  # or use a fixed project date\n",
    "df[\"experience_years\"] = (reference_date - df[\"start_date\"]).dt.days / 365.25\n",
    "\n",
    "# Load a pre-trained sentence transformer\n",
    "embedder = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "# Compute embedding for each award's combined text\n",
    "df[\"text_embedding\"] = df[\"combined_text\"].apply(lambda x: embedder.encode(x))\n",
    "\n",
    "# We assume each row has a researcher ID (\"pi_id\"). If a researcher has multiple rows, we aggregate.\n",
    "# For aggregated text, we average the embeddings; for numeric features, we use appropriate aggregation.\n",
    "award_counts = df.groupby(\"pi_id\").size().reset_index(name=\"award_count\")\n",
    "df_grouped = df.groupby(\"pi_id\").agg({\n",
    "    \"experience_years\": \"mean\",       # average experience across awards\n",
    "    \"leadership\": \"max\",              # if they have ever been a PI, mark as leadership\n",
    "    \"text_embedding\": lambda embs: np.mean(np.stack(embs), axis=0)\n",
    "}).reset_index()\n",
    "df_grouped = df_grouped.merge(award_counts, on=\"pi_id\", how=\"left\")\n",
    "\n",
    "# For later scoring, normalize the numeric features (experience and award_count)\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "df_grouped[[\"exp_norm\", \"award_norm\"]] = scaler.fit_transform(df_grouped[[\"experience_years\", \"award_count\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rank_candidates(research_topic, candidate_ids, base_weight=0.5, topic_weight=0.5):\n",
    "    # Compute embedding for the research topic\n",
    "    topic_emb = embedder.encode(research_topic)\n",
    "    \n",
    "    candidate_scores = []\n",
    "    for cid in candidate_ids:\n",
    "        candidate = df_grouped[df_grouped[\"pi_id\"] == cid].iloc[0]\n",
    "        \n",
    "        # Topic relevance score: cosine similarity between candidate's aggregated embedding and the topic\n",
    "        candidate_emb = candidate[\"text_embedding\"]\n",
    "        relevance_score = cosine_similarity([candidate_emb], [topic_emb])[0][0]\n",
    "        \n",
    "        # Base score: a simple weighted sum of normalized features plus a bonus for leadership\n",
    "        # Adjust weights as needed. Here, leadership gets a bonus of 1 if present.\n",
    "        base_score = candidate[\"exp_norm\"] + candidate[\"award_norm\"] + (1 if candidate[\"leadership\"] == 1 else 0)\n",
    "        \n",
    "        # Combined score: weighted combination of base score and topic relevance\n",
    "        combined_score = base_weight * base_score + topic_weight * relevance_score\n",
    "        candidate_scores.append(combined_score)\n",
    "    \n",
    "    candidate_scores = np.array(candidate_scores)\n",
    "    best_index = np.argmax(candidate_scores)\n",
    "    pi_candidate = candidate_ids[best_index]\n",
    "    co_pi_candidates = [cid for i, cid in enumerate(candidate_ids) if i != best_index]\n",
    "    \n",
    "    return pi_candidate, co_pi_candidates, candidate_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with various topics dynamically.\n",
    "for test_topic in [\"knowledge graph\", \"AI\", \"Neuroscience\", \"STATISTICS\"]:\n",
    "    print(\"Testing with topic:\", test_topic)\n",
    "    pi_candidate, co_pi_candidates, scores = rank_candidates(test_topic, pi_ids_to_analyze)\n",
    "    print(\"Predicted PI:\", pi_candidate)\n",
    "    print(\"Predicted Co-PIs:\", co_pi_candidates)\n",
    "    print(\"Candidate Combined Scores:\", scores)\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[df.pi_id.isin(pi_ids_to_analyze)][['pi_id', 'pi_full_name', 'role', 'department', 'leadership', 'experience_years', 'program_element']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define the list of keywords for departments of interest,\n",
    "# # including alternative spellings (e.g., math and mathmatics, stat and statistics)\n",
    "# allowed_keywords = ['computer', 'electrical', 'biomedical', 'bioinformatics', 'math', 'mathmatics', 'stat', 'statistics']\n",
    "\n",
    "# # Filter the DataFrame to only include rows where the 'department' field contains one of the keywords (case insensitive)\n",
    "# qualified_df = df[df['department'].fillna('').str.lower().str.contains('|'.join(allowed_keywords))]\n",
    "\n",
    "# # Get unique PI IDs from the filtered DataFrame\n",
    "# unique_pi_ids = qualified_df['pi_id'].unique()\n",
    "\n",
    "# # Generate 15 sets, each containing 3 distinct PI IDs sampled without replacement\n",
    "# pi_id_sets = [list(np.random.choice(unique_pi_ids, 3, replace=False)) for _ in range(15)]\n",
    "\n",
    "# # Output the sets with department and program_element information\n",
    "# for idx, pi_set in enumerate(pi_id_sets, start=1):\n",
    "#     print(f\"Set {idx}:\")\n",
    "#     for pi in pi_set:\n",
    "#         info = qualified_df[qualified_df['pi_id'] == pi].iloc[0]\n",
    "#         print(f\"  PI: {pi} | Department: {info['department']} | Program Element: {info['program_element']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "candidate_sets = [\n",
    "    (['269948909', '000173003', '269886945'], 'STATISTICS'),\n",
    "    (['269807623', '269794080', '269879497'], 'AI Circuits design'),\n",
    "    (['269807623', '269794080', '269879497'], 'hardware software co-design'),\n",
    "    (['269677663', '269988546', '270021884'], 'Trustworthy AI'),\n",
    "    (['269677663', '269988546', '269814599'], 'Networking safety'),\n",
    "    (['269811881', '269958535', '270083608'], 'Bioinformatics'),\n",
    "    (['270082637', '269726900', '269963435'], 'Robotics'),\n",
    "    (['270082637', '269726900', '270021884'], 'AI in Robotics'),\n",
    "    (['269934201', '269769382', '269911544'], 'Algorithm'),\n",
    "    (['269721983', '269928133', '000171581'], 'Data Science')\n",
    "]\n",
    "\n",
    "for pi_ids, topic in candidate_sets:\n",
    "    print(f\"Topic: {topic}\")\n",
    "    pi_candidate, co_pi_candidates, scores = rank_candidates(topic, pi_ids)\n",
    "    print(\"Predicted PI:\", pi_candidate)\n",
    "    print(\"Predicted Co-PIs:\", co_pi_candidates)\n",
    "    print(\"Candidate Combined Scores:\", scores)\n",
    "    # display(df[df.pi_id.isin(pi_ids)][['pi_id', 'pi_full_name', 'role', 'department', 'leadership', 'experience_years', 'program_element']])\n",
    "    # display(df_grouped[df_grouped.pi_id.isin(pi_ids)][['pi_id', 'award_count', 'experience_years', 'leadership']])\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import random\n",
    "\n",
    "# for i in range(20):\n",
    "#     pi_ids = candidate_sets[random.randint(1, 10) - 1][0]\n",
    "#     topic = candidate_sets[random.randint(1, 10) - 1][1]\n",
    "#     print(f\"Topic: {topic}\")\n",
    "#     pi_candidate, co_pi_candidates, scores = rank_candidates(topic, pi_ids)\n",
    "#     print(\"Predicted PI:\", pi_candidate)\n",
    "#     print(\"Predicted Co-PIs:\", co_pi_candidates)\n",
    "#     print(\"Candidate Combined Scores:\", scores)\n",
    "#     print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# pi = [269948909, 000173003, 269886945], topic = 'STATISTICS'\n",
    "# pi = [269807623, 269794080, 269879497], topic = 'AI Circuits design'\n",
    "# pi = [269807623, 269794080, 269879497], topic = 'hardware software co-design'\n",
    "# pi = [269677663, 269988546, 270021884], topic = 'Trustworthy AI'\n",
    "# pi = [269677663, 269988546, 269814599], topic = 'Networking safety'\n",
    "# pi = [269811881, 269958535, 270083608], topic = 'Bioinformatics'\n",
    "# pi = [270082637, 269726900, 269963435], topic = 'Robotics'\n",
    "# pi = [270082637, 269726900, 270021884], topic = 'AI in Robotics'\n",
    "# pi = [269934201, 269769382, 269911544], topic = 'Algorithm'\n",
    "# pi = [269721983, 269928133, 000171581], topic = 'Data Science'\n",
    "# rank_candidates(research_topic, candidate_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[df['pi_id'] == '000173003'][['pi_full_name', 'pi_id', 'role', 'department', 'leadership', 'experience_years', 'program_element']]\n",
    "df[df.pi_id == '269769382']['pi_full_name'].to_list()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.pi_full_name == 'Xin Zhang']['pi_id'].to_list()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pi_ids_to_analyze = ['270082637', '269726900', '270021884']\n",
    "df[df.pi_id.isin(pi_ids_to_analyze)][['pi_id', 'pi_full_name', 'role', 'department', 'leadership', 'experience_years', 'program_element']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_r = [1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = [1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1]  # predicted\n",
    "y_true = [1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1]  # actual/ground truth\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "\n",
    "precision = precision_score(y_true, y_pred)\n",
    "recall = recall_score(y_true, y_pred)\n",
    "f1 = f1_score(y_true, y_pred)\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1 Score: {f1}\")\n",
    "print(f\"Accuracy: {accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation metrics:\n",
      "-------------------\n",
      "Total samples: 14\n",
      "Correct (TP): 12\n",
      "Wrong (FP): 2\n",
      "Waiting (FN): 2\n",
      "Precision: 0.8571\n",
      "Recall:    0.8571\n",
      "F1 score:  0.8571\n",
      "Accuracy:  0.8571\n"
     ]
    }
   ],
   "source": [
    "# Sample raw results (each as a string).\n",
    "raw_results = [\n",
    "    \"['269948909', '000173003', '269886945'] - STATISTICS - Xin Zhang - 269948909 - correct\",\n",
    "    \"['269807623', '269794080', '269879497'] - AI Circuits design - Azadeh Davoodi - 269794080 - correct\",\n",
    "    \"['269807623', '269794080', '269879497'] - hardware software co-design - Azadeh Davoodi - 269794080 - correct\",\n",
    "    \"['269677663', '269988546', '270021884'] - Trustworthy AI - Benjamin Fuller - 269988546 - wrong\",\n",
    "    \"['269677663', '269988546', '269814599'] - Networking safety - Benjamin Fuller - 269988546 - correct\",\n",
    "    \"['269811881', '269958535', '270083608'] - Bioinformatics - Jianlin Cheng - 269811881 - correct\",\n",
    "    \"['270082637', '269726900', '269963435'] - Robotics - Rodrigo O Spinola - 270082637 - correct\",\n",
    "    \"['270082637', '269726900', '270021884'] - AI in Robotics - Guido F Montufar Cuartas - 270021884 - wrong\",\n",
    "    \"['269934201', '269769382', '269911544'] - Algorithm - Michael Dinitz - 269934201 - correct\",\n",
    "    \"['269721983', '269928133', '000171581'] - Data Science - Sofya Raskhodnikova - 269721983 - correct\",\n",
    "    \"\",\n",
    "    \"['000025017', '000025762', '000030655'] - knowledge graph - Steven N MacEachern - 000025762 - correct\",\n",
    "    \"['000025017', '000025762', '000030655'] - AI - Steven N MacEachern - 000025762 - correct\",\n",
    "    \"['000025017', '000025762', '000030655'] - Neuroscience - Steven N MacEachern - 000025762 - correct\",\n",
    "    \"['000025017', '000025762', '000030655'] - STATISTICS - Steven N MacEachern - 000025762 - correct\"\n",
    "]\n",
    "\n",
    "# Initialize counters.\n",
    "tp = 0  # true positives\n",
    "fp = 0  # false positives\n",
    "fn = 0  # false negatives\n",
    "total = 0  # total evaluated samples\n",
    "\n",
    "# Loop through each line in the results.\n",
    "for line in raw_results:\n",
    "    # Skip empty lines (if any)\n",
    "    if not line.strip():\n",
    "        continue\n",
    "\n",
    "    total += 1\n",
    "    \n",
    "    # The label is the last token when splitting by ' - '\n",
    "    # We assume that the parts are separated by \" - \" and the last part is the status.\n",
    "    parts = line.split(\" - \")\n",
    "    status = parts[-1].strip().lower()  # e.g., 'correct', 'wrong', 'waiting'\n",
    "    \n",
    "    if status == \"correct\":\n",
    "        tp += 1\n",
    "    elif status == \"wrong\":\n",
    "        # A wrong prediction means the algorithm made a prediction but it did not match\n",
    "        # the true answer. This counts as a false positive and a missed correct answer (FN).\n",
    "        fp += 1\n",
    "        fn += 1\n",
    "    else:\n",
    "        print(f\"Unrecognized status: {status}\")\n",
    "\n",
    "# Calculate precision, recall, F1 and accuracy rate.\n",
    "if (tp + fp) > 0:\n",
    "    precision = tp / (tp + fp)\n",
    "else:\n",
    "    precision = 0\n",
    "\n",
    "if (tp + fn) > 0:\n",
    "    recall = tp / (tp + fn)\n",
    "else:\n",
    "    recall = 0\n",
    "\n",
    "if (precision + recall) > 0:\n",
    "    f1 = 2 * (precision * recall) / (precision + recall)\n",
    "else:\n",
    "    f1 = 0\n",
    "\n",
    "accuracy = tp / total if total > 0 else 0\n",
    "\n",
    "# Display the results.\n",
    "print(\"Evaluation metrics:\")\n",
    "print(\"-------------------\")\n",
    "print(f\"Total samples: {total}\")\n",
    "print(f\"Correct (TP): {tp}\")\n",
    "print(f\"Wrong (FP): {fp}\")\n",
    "print(f\"Waiting (FN): {fn}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall:    {recall:.4f}\")\n",
    "print(f\"F1 score:  {f1:.4f}\")\n",
    "print(f\"Accuracy:  {accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation metrics:\n",
      "-------------------\n",
      "Total samples: 14\n",
      "Correct (TP): 9\n",
      "Wrong (FP): 5\n",
      "False Negatives (FN): 5\n",
      "Precision: 0.6429\n",
      "Recall:    0.6429\n",
      "F1 score:  0.6429\n",
      "Accuracy:  0.6429\n"
     ]
    }
   ],
   "source": [
    "# Updated raw results list.\n",
    "raw_results = [\n",
    "    \"['269948909', '000173003', '269886945'] - STATISTICS - 000173003 - Peter D Hislop - 2nd most optimal option\",\n",
    "    \"['269807623', '269794080', '269879497'] - AI Circuits design - 269794080 - Azadeh Davoodi - correct\",\n",
    "    \"['269807623', '269794080', '269879497'] - hardware software co-design - 269794080 - Azadeh Davoodi - correct\",\n",
    "    \"['269677663', '269988546', '270021884'] - Trustworthy AI - 270021884 - Guido F Montufar Cuartas - correct\",\n",
    "    \"['269677663', '269988546', '269814599'] - Networking safety - 269814599 - Srinivas Shakkottai - wrong\",\n",
    "    \"['269811881', '269958535', '270083608'] - Bioinformatics - 269958535 - HaiYing   Wang - wrong\",\n",
    "    \"['270082637', '269726900', '269963435'] - Robotics - 270082637 - Rodrigo O Spinola - correct\",\n",
    "    \"['270082637', '269726900', '270021884'] - AI in Robotics - 270021884 - Guido F Montufar Cuartas - wrong\",\n",
    "    \"['269934201', '269769382', '269911544'] - Algorithm - 269769382 - Susan D Nickerson - wrong\",\n",
    "    \"['269721983', '269928133', '000171581'] - Data Science - 269721983 - Sofya Raskhodnikova - correct\",\n",
    "    \"['000025017', '000025762', '000030655'] - knowledge graph - 000025762 - Steven N MacEachern - correct\",\n",
    "    \"['000025017', '000025762', '000030655'] - AI - 000025762 - Steven N MacEachern - correct\",\n",
    "    \"['000025017', '000025762', '000030655'] - Neuroscience - 000025762 - Steven N MacEachern - correct\",\n",
    "    \"['000025017', '000025762', '000030655'] - STATISTICS - 000025762 - Steven N MacEachern - correct\"\n",
    "]\n",
    "\n",
    "# Initialize counters.\n",
    "tp = 0  # true positives\n",
    "fp = 0  # false positives\n",
    "fn = 0  # false negatives\n",
    "total = 0  # total valid samples\n",
    "\n",
    "# Process each line in the results.\n",
    "for line in raw_results:\n",
    "    if not line.strip():\n",
    "        continue  # Skip empty lines.\n",
    "    \n",
    "    total += 1\n",
    "    parts = line.split(\" - \")\n",
    "    # The final token is the prediction label.\n",
    "    outcome = parts[-1].strip().lower()\n",
    "    \n",
    "    # Count outcomes; only exactly 'correct' is TP.\n",
    "    if outcome == \"correct\":\n",
    "        tp += 1\n",
    "    elif outcome in [\"wrong\", \"2nd most optimal option\"]:\n",
    "        fp += 1\n",
    "        fn += 1\n",
    "    else:\n",
    "        print(f\"Unrecognized status: {outcome}\")\n",
    "\n",
    "# Compute metrics.\n",
    "precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "recall    = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "f1        = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "accuracy  = tp / total if total > 0 else 0\n",
    "\n",
    "# Output the results.\n",
    "print(\"Evaluation metrics:\")\n",
    "print(\"-------------------\")\n",
    "print(f\"Total samples: {total}\")\n",
    "print(f\"Correct (TP): {tp}\")\n",
    "print(f\"Wrong (FP): {fp}\")\n",
    "print(f\"False Negatives (FN): {fn}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall:    {recall:.4f}\")\n",
    "print(f\"F1 score:  {f1:.4f}\")\n",
    "print(f\"Accuracy:  {accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agent",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
